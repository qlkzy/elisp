This is Info file perl.info, produced by Makeinfo version 1.68 from the
input file bigperl.texi.

   settitle perl


File: perl.info,  Node: perlguts,  Next: perlcall,  Prev: perlxstut,  Up: Top

Introduction to the Perl API
****************************

NAME
====

   perlguts - Introduction to the Perl API

DESCRIPTION
===========

   This document attempts to describe how to use the Perl API, as well as
containing some info on the basic workings of the Perl core. It is far
from complete and probably contains many errors. Please refer any
questions or comments to the author below.

Variables
=========

Datatypes
---------

   Perl has three typedefs that handle Perl's three main data types:

     SV  Scalar Value
     AV  Array Value
     HV  Hash Value

   Each typedef has specific routines that manipulate the various data
types.

What is an "IV"?
----------------

   Perl uses a special typedef IV which is a simple signed integer type
that is guaranteed to be large enough to hold a pointer (as well as an
integer).  Additionally, there is the UV, which is simply an unsigned IV.

   Perl also uses two special typedefs, I32 and I16, which will always be
at least 32-bits and 16-bits long, respectively. (Again, there are U32 and
U16, as well.)

Working with SVs
----------------

   An SV can be created and loaded with one command.  There are four types
of values that can be loaded: an integer value (IV), a double (NV), a
string, (PV), and another scalar (SV).

   The six routines are:

     SV*  newSViv(IV);
     SV*  newSVnv(double);
     SV*  newSVpv(const char*, int);
     SV*  newSVpvn(const char*, int);
     SV*  newSVpvf(const char*, ...);
     SV*  newSVsv(SV*);

   To change the value of an *already-existing* SV, there are seven
routines:

     void  sv_setiv(SV*, IV);
     void  sv_setuv(SV*, UV);
     void  sv_setnv(SV*, double);
     void  sv_setpv(SV*, const char*);
     void  sv_setpvn(SV*, const char*, int)
     void  sv_setpvf(SV*, const char*, ...);
     void  sv_setpvfn(SV*, const char*, STRLEN, va_list *, SV **, I32, bool);
     void  sv_setsv(SV*, SV*);

   Notice that you can choose to specify the length of the string to be
assigned by using sv_setpvn, newSVpvn, or newSVpv, or you may allow Perl
to calculate the length by using sv_setpv or by specifying 0 as the second
argument to newSVpv.  Be warned, though, that Perl will determine the
string's length by using strlen, which depends on the string terminating
with a NUL character.

   The arguments of sv_setpvf are processed like sprintf, and the
formatted output becomes the value.

   `sv_setpvfn' is an analogue of vsprintf, but it allows you to specify
either a pointer to a variable argument list or the address and length of
an array of SVs.  The last argument points to a boolean; on return, if that
boolean is true, then locale-specific information has been used to format
the string, and the string's contents are therefore untrustworthy (see
*Note Perlsec: perlsec,).  This pointer may be NULL if that information is
not important.  Note that this function requires you to specify the length
of the format.

   The `sv_set*()' functions are not generic enough to operate on values
that have "magic".  See `Magic Virtual Tables' in this node later in this
document.

   All SVs that contain strings should be terminated with a NUL character.
If it is not NUL-terminated there is a risk of core dumps and corruptions
from code which passes the string to C functions or system calls which
expect a NUL-terminated string.  Perl's own functions typically add a
trailing NUL for this reason.  Nevertheless, you should be very careful
when you pass a string stored in an SV to a C function or system call.

   To access the actual value that an SV points to, you can use the macros:

     SvIV(SV*)
     SvUV(SV*)
     SvNV(SV*)
     SvPV(SV*, STRLEN len)
     SvPV_nolen(SV*)

   which will automatically coerce the actual scalar type into an IV, UV,
double, or string.

   In the SvPV macro, the length of the string returned is placed into the
variable len (this is a macro, so you do not use `&len').  If you do not
care what the length of the data is, use the SvPV_nolen macro.
Historically the SvPV macro with the global variable PL_na has been used
in this case.  But that can be quite inefficient because PL_na must be
accessed in thread-local storage in threaded Perl.  In any case, remember
that Perl allows arbitrary strings of data that may both contain NULs and
might not be terminated by a NUL.

   Also remember that C doesn't allow you to safely say `foo(SvPV(s, len),
len);'. It might work with your compiler, but it won't work for everyone.
Break this sort of statement up into separate assignments:

     SV *s;
     STRLEN len;
     char * ptr;
     ptr = SvPV(s, len);
     foo(ptr, len);

   If you want to know if the scalar value is TRUE, you can use:

     SvTRUE(SV*)

   Although Perl will automatically grow strings for you, if you need to
force Perl to allocate more memory for your SV, you can use the macro

     SvGROW(SV*, STRLEN newlen)

   which will determine if more memory needs to be allocated.  If so, it
will call the function sv_grow.  Note that SvGROW can only increase, not
decrease, the allocated memory of an SV and that it does not automatically
add a byte for the a trailing NUL (perl's own string functions typically do
`SvGROW(sv, len + 1)').

   If you have an SV and want to know what kind of data Perl thinks is
stored in it, you can use the following macros to check the type of SV you
have.

     SvIOK(SV*)
     SvNOK(SV*)
     SvPOK(SV*)

   You can get and set the current length of the string stored in an SV
with the following macros:

     SvCUR(SV*)
     SvCUR_set(SV*, I32 val)

   You can also get a pointer to the end of the string stored in the SV
with the macro:

     SvEND(SV*)

   But note that these last three macros are valid only if `SvPOK()' is
true.

   If you want to append something to the end of string stored in an `SV*',
you can use the following functions:

     void  sv_catpv(SV*, const char*);
     void  sv_catpvn(SV*, const char*, STRLEN);
     void  sv_catpvf(SV*, const char*, ...);
     void  sv_catpvfn(SV*, const char*, STRLEN, va_list *, SV **, I32, bool);
     void  sv_catsv(SV*, SV*);

   The first function calculates the length of the string to be appended by
using strlen.  In the second, you specify the length of the string
yourself.  The third function processes its arguments like sprintf and
appends the formatted output.  The fourth function works like vsprintf.
You can specify the address and length of an array of SVs instead of the
va_list argument. The fifth function extends the string stored in the first
SV with the string stored in the second SV.  It also forces the second SV
to be interpreted as a string.

   The `sv_cat*()' functions are not generic enough to operate on values
that have "magic".  See `Magic Virtual Tables' in this node later in this
document.

   If you know the name of a scalar variable, you can get a pointer to its
SV by using the following:

     SV*  get_sv("package::varname", FALSE);

   This returns NULL if the variable does not exist.

   If you want to know if this variable (or any other SV) is actually
defined, you can call:

     SvOK(SV*)

   The scalar undef value is stored in an SV instance called PL_sv_undef.
Its address can be used whenever an `SV*' is needed.

   There are also the two values PL_sv_yes and PL_sv_no, which contain
Boolean TRUE and FALSE values, respectively.  Like PL_sv_undef, their
addresses can be used whenever an `SV*' is needed.

   Do not be fooled into thinking that `(SV *) 0' is the same as
`&PL_sv_undef'.  Take this code:

     SV* sv = (SV*) 0;
     if (I-am-to-return-a-real-value) {
             sv = sv_2mortal(newSViv(42));
     }
     sv_setsv(ST(0), sv);

   This code tries to return a new SV (which contains the value 42) if it
should return a real value, or undef otherwise.  Instead it has returned a
NULL pointer which, somewhere down the line, will cause a segmentation
violation, bus error, or just weird results.  Change the zero to
`&PL_sv_undef' in the first line and all will be well.

   To free an SV that you've created, call `SvREFCNT_dec(SV*)'.  Normally
this call is not necessary (see `Reference Counts and Mortality' in this
node).

What's Really Stored in an SV?
------------------------------

   Recall that the usual method of determining the type of scalar you have
is to use `Sv*OK' macros.  Because a scalar can be both a number and a
string, usually these macros will always return TRUE and calling the `Sv*V'
macros will do the appropriate conversion of string to integer/double or
integer/double to string.

   If you *really* need to know if you have an integer, double, or string
pointer in an SV, you can use the following three macros instead:

     SvIOKp(SV*)
     SvNOKp(SV*)
     SvPOKp(SV*)

   These will tell you if you truly have an integer, double, or string
pointer stored in your SV.  The "p" stands for private.

   In general, though, it's best to use the `Sv*V' macros.

Working with AVs
----------------

   There are two ways to create and load an AV.  The first method creates
an empty AV:

     AV*  newAV();

   The second method both creates the AV and initially populates it with
SVs:

     AV*  av_make(I32 num, SV **ptr);

   The second argument points to an array containing num `SV*''s.  Once the
AV has been created, the SVs can be destroyed, if so desired.

   Once the AV has been created, the following operations are possible on
AVs:

     void  av_push(AV*, SV*);
     SV*   av_pop(AV*);
     SV*   av_shift(AV*);
     void  av_unshift(AV*, I32 num);

   These should be familiar operations, with the exception of av_unshift.
This routine adds num elements at the front of the array with the undef
value.  You must then use av_store (described below) to assign values to
these new elements.

   Here are some other functions:

     I32   av_len(AV*);
     SV**  av_fetch(AV*, I32 key, I32 lval);
     SV**  av_store(AV*, I32 key, SV* val);

   The av_len function returns the highest index value in array (just like
$#array in Perl).  If the array is empty, -1 is returned.  The av_fetch
function returns the value at index key, but if `lval' is non-zero, then
av_fetch will store an undef value at that index.  The av_store function
stores the value val at index key, and does not increment the reference
count of val.  Thus the caller is responsible for taking care of that, and
if av_store returns NULL, the caller will have to decrement the reference
count to avoid a memory leak.  Note that av_fetch and av_store both return
`SV**''s, not `SV*''s as their return value.

     void  av_clear(AV*);
     void  av_undef(AV*);
     void  av_extend(AV*, I32 key);

   The av_clear function deletes all the elements in the AV* array, but
does not actually delete the array itself.  The av_undef function will
delete all the elements in the array plus the array itself.  The av_extend
function extends the array so that it contains at least `key+1' elements.
If `key+1' is less than the currently allocated length of the array, then
nothing is done.

   If you know the name of an array variable, you can get a pointer to its
AV by using the following:

     AV*  get_av("package::varname", FALSE);

   This returns NULL if the variable does not exist.

   See `Understanding the Magic of Tied Hashes and Arrays' in this node
for more information on how to use the array access functions on tied
arrays.

Working with HVs
----------------

   To create an HV, you use the following routine:

     HV*  newHV();

   Once the HV has been created, the following operations are possible on
HVs:

     SV**  hv_store(HV*, const char* key, U32 klen, SV* val, U32 hash);
     SV**  hv_fetch(HV*, const char* key, U32 klen, I32 lval);

   The `klen' parameter is the length of the key being passed in (Note that
you cannot pass 0 in as a value of `klen' to tell Perl to measure the
length of the key).  The val argument contains the SV pointer to the
scalar being stored, and hash is the precomputed hash value (zero if you
want hv_store to calculate it for you).  The `lval' parameter indicates
whether this fetch is actually a part of a store operation, in which case
a new undefined value will be added to the HV with the supplied key and
hv_fetch will return as if the value had already existed.

   Remember that hv_store and hv_fetch return `SV**''s and not just `SV*'.
To access the scalar value, you must first dereference the return value.
However, you should check to make sure that the return value is not NULL
before dereferencing it.

   These two functions check if a hash table entry exists, and deletes it.

     bool  hv_exists(HV*, const char* key, U32 klen);
     SV*   hv_delete(HV*, const char* key, U32 klen, I32 flags);

   If flags does not include the G_DISCARD flag then hv_delete will create
and return a mortal copy of the deleted value.

   And more miscellaneous functions:

     void   hv_clear(HV*);
     void   hv_undef(HV*);

   Like their AV counterparts, hv_clear deletes all the entries in the hash
table but does not actually delete the hash table.  The hv_undef deletes
both the entries and the hash table itself.

   Perl keeps the actual data in linked list of structures with a typedef
of HE.  These contain the actual key and value pointers (plus extra
administrative overhead).  The key is a string pointer; the value is an
`SV*'.  However, once you have an `HE*', to get the actual key and value,
use the routines specified below.

     I32    hv_iterinit(HV*);
             /* Prepares starting point to traverse hash table */
     HE*    hv_iternext(HV*);
             /* Get the next entry, and return a pointer to a
                structure that has both the key and value */
     char*  hv_iterkey(HE* entry, I32* retlen);
             /* Get the key from an HE structure and also return
                the length of the key string */
     SV*    hv_iterval(HV*, HE* entry);
             /* Return a SV pointer to the value of the HE
                structure */
     SV*    hv_iternextsv(HV*, char** key, I32* retlen);
             /* This convenience routine combines hv_iternext,
     	       hv_iterkey, and hv_iterval.  The key and retlen
     	       arguments are return values for the key and its
     	       length.  The value is returned in the SV* argument */

   If you know the name of a hash variable, you can get a pointer to its HV
by using the following:

     HV*  get_hv("package::varname", FALSE);

   This returns NULL if the variable does not exist.

   The hash algorithm is defined in the `PERL_HASH(hash, key, klen)' macro:

     hash = 0;
     while (klen--)
     	hash = (hash * 33) + *key++;
     hash = hash + (hash >> 5);			/* after 5.6 */

   The last step was added in version 5.6 to improve distribution of lower
bits in the resulting hash value.

   See `Understanding the Magic of Tied Hashes and Arrays' in this node
for more information on how to use the hash access functions on tied
hashes.

Hash API Extensions
-------------------

   Beginning with version 5.004, the following functions are also
supported:

     HE*     hv_fetch_ent  (HV* tb, SV* key, I32 lval, U32 hash);
     HE*     hv_store_ent  (HV* tb, SV* key, SV* val, U32 hash);

     bool    hv_exists_ent (HV* tb, SV* key, U32 hash);
     SV*     hv_delete_ent (HV* tb, SV* key, I32 flags, U32 hash);

     SV*     hv_iterkeysv  (HE* entry);

   Note that these functions take `SV*' keys, which simplifies writing of
extension code that deals with hash structures.  These functions also
allow passing of `SV*' keys to tie functions without forcing you to
stringify the keys (unlike the previous set of functions).

   They also return and accept whole hash entries (`HE*'), making their
use more efficient (since the hash number for a particular string doesn't
have to be recomputed every time).  See *Note Perlapi: perlapi, for
detailed descriptions.

   The following macros must always be used to access the contents of hash
entries.  Note that the arguments to these macros must be simple
variables, since they may get evaluated more than once.  See *Note
Perlapi: perlapi, for detailed descriptions of these macros.

     HePV(HE* he, STRLEN len)
     HeVAL(HE* he)
     HeHASH(HE* he)
     HeSVKEY(HE* he)
     HeSVKEY_force(HE* he)
     HeSVKEY_set(HE* he, SV* sv)

   These two lower level macros are defined, but must only be used when
dealing with keys that are not `SV*'s:

     HeKEY(HE* he)
     HeKLEN(HE* he)

   Note that both hv_store and hv_store_ent do not increment the reference
count of the stored val, which is the caller's responsibility.  If these
functions return a NULL value, the caller will usually have to decrement
the reference count of val to avoid a memory leak.

References
----------

   References are a special type of scalar that point to other data types
(including references).

   To create a reference, use either of the following functions:

     SV* newRV_inc((SV*) thing);
     SV* newRV_noinc((SV*) thing);

   The `thing' argument can be any of an `SV*', `AV*', or `HV*'.  The
functions are identical except that newRV_inc increments the reference
count of the `thing', while newRV_noinc does not.  For historical reasons,
`newRV' is a synonym for newRV_inc.

   Once you have a reference, you can use the following macro to
dereference the reference:

     SvRV(SV*)

   then call the appropriate routines, casting the returned `SV*' to
either an `AV*' or `HV*', if required.

   To determine if an SV is a reference, you can use the following macro:

     SvROK(SV*)

   To discover what type of value the reference refers to, use the
following macro and then check the return value.

     SvTYPE(SvRV(SV*))

   The most useful types that will be returned are:

     SVt_IV    Scalar
     SVt_NV    Scalar
     SVt_PV    Scalar
     SVt_RV    Scalar
     SVt_PVAV  Array
     SVt_PVHV  Hash
     SVt_PVCV  Code
     SVt_PVGV  Glob (possible a file handle)
     SVt_PVMG  Blessed or Magical Scalar

     See the sv.h header file for more details.

Blessed References and Class Objects
------------------------------------

   References are also used to support object-oriented programming.  In the
OO lexicon, an object is simply a reference that has been blessed into a
package (or class).  Once blessed, the programmer may now use the reference
to access the various methods in the class.

   A reference can be blessed into a package with the following function:

     SV* sv_bless(SV* sv, HV* stash);

   The sv argument must be a reference.  The stash argument specifies
which class the reference will belong to.  See `Stashes and Globs' in this
node for information on converting class names into stashes.

   /* Still under construction */

   Upgrades rv to reference if not already one.  Creates new SV for rv to
point to.  If `classname' is non-null, the SV is blessed into the specified
class.  SV is returned.

     SV* newSVrv(SV* rv, const char* classname);

   Copies integer or double into an SV whose reference is rv.  SV is
blessed if `classname' is non-null.

     SV* sv_setref_iv(SV* rv, const char* classname, IV iv);
     SV* sv_setref_nv(SV* rv, const char* classname, NV iv);

   Copies the pointer value (*the address, not the string!*) into an SV
whose reference is rv.  SV is blessed if `classname' is non-null.

     SV* sv_setref_pv(SV* rv, const char* classname, PV iv);

   Copies string into an SV whose reference is rv.  Set length to 0 to let
Perl calculate the string length.  SV is blessed if `classname' is
non-null.

     SV* sv_setref_pvn(SV* rv, const char* classname, PV iv, STRLEN length);

   Tests whether the SV is blessed into the specified class.  It does not
check inheritance relationships.

     int  sv_isa(SV* sv, const char* name);

   Tests whether the SV is a reference to a blessed object.

     int  sv_isobject(SV* sv);

   Tests whether the SV is derived from the specified class. SV can be
either a reference to a blessed object or a string containing a class
name. This is the function implementing the UNIVERSAL::isa functionality.

     bool sv_derived_from(SV* sv, const char* name);

   To check if you've got an object derived from a specific class you have
to write:

     if (sv_isobject(sv) && sv_derived_from(sv, class)) { ... }

Creating New Variables
----------------------

   To create a new Perl variable with an undef value which can be accessed
from your Perl script, use the following routines, depending on the
variable type.

     SV*  get_sv("package::varname", TRUE);
     AV*  get_av("package::varname", TRUE);
     HV*  get_hv("package::varname", TRUE);

   Notice the use of TRUE as the second parameter.  The new variable can
now be set, using the routines appropriate to the data type.

   There are additional macros whose values may be bitwise OR'ed with the
TRUE argument to enable certain extra features.  Those bits are:

     GV_ADDMULTI	Marks the variable as multiply defined, thus preventing the
     		"Name <varname> used only once: possible typo" warning.
     GV_ADDWARN	Issues the warning "Had to create <varname> unexpectedly" if
     		the variable did not exist before the function was called.

   If you do not specify a package name, the variable is created in the
current package.

Reference Counts and Mortality
------------------------------

   Perl uses an reference count-driven garbage collection mechanism. SVs,
AVs, or HVs (xV for short in the following) start their life with a
reference count of 1.  If the reference count of an xV ever drops to 0,
then it will be destroyed and its memory made available for reuse.

   This normally doesn't happen at the Perl level unless a variable is
undef'ed or the last variable holding a reference to it is changed or
overwritten.  At the internal level, however, reference counts can be
manipulated with the following macros:

     int SvREFCNT(SV* sv);
     SV* SvREFCNT_inc(SV* sv);
     void SvREFCNT_dec(SV* sv);

   However, there is one other function which manipulates the reference
count of its argument.  The newRV_inc function, you will recall, creates a
reference to the specified argument.  As a side effect, it increments the
argument's reference count.  If this is not what you want, use newRV_noinc
instead.

   For example, imagine you want to return a reference from an XSUB
function.  Inside the XSUB routine, you create an SV which initially has a
reference count of one.  Then you call newRV_inc, passing it the
just-created SV.  This returns the reference as a new SV, but the
reference count of the SV you passed to newRV_inc has been incremented to
two.  Now you return the reference from the XSUB routine and forget about
the SV.  But Perl hasn't!  Whenever the returned reference is destroyed,
the reference count of the original SV is decreased to one and nothing
happens.  The SV will hang around without any way to access it until Perl
itself terminates.  This is a memory leak.

   The correct procedure, then, is to use newRV_noinc instead of
newRV_inc.  Then, if and when the last reference is destroyed, the
reference count of the SV will go to zero and it will be destroyed,
stopping any memory leak.

   There are some convenience functions available that can help with the
destruction of xVs.  These functions introduce the concept of "mortality".
An xV that is mortal has had its reference count marked to be decremented,
but not actually decremented, until "a short time later".  Generally the
term "short time later" means a single Perl statement, such as a call to
an XSUB function.  The actual determinant for when mortal xVs have their
reference count decremented depends on two macros, SAVETMPS and FREETMPS.
See *Note Perlcall: perlcall, and *Note Perlxs: perlxs, for more details
on these macros.

   "Mortalization" then is at its simplest a deferred SvREFCNT_dec.
However, if you mortalize a variable twice, the reference count will later
be decremented twice.

   You should be careful about creating mortal variables.  Strange things
can happen if you make the same value mortal within multiple contexts, or
if you make a variable mortal multiple times.

   To create a mortal variable, use the functions:

     SV*  sv_newmortal()
     SV*  sv_2mortal(SV*)
     SV*  sv_mortalcopy(SV*)

   The first call creates a mortal SV, the second converts an existing SV
to a mortal SV (and thus defers a call to SvREFCNT_dec), and the third
creates a mortal copy of an existing SV.

   The mortal routines are not just for SVs - AVs and HVs can be made
mortal by passing their address (type-casted to `SV*') to the sv_2mortal
or sv_mortalcopy routines.

Stashes and Globs
-----------------

   A "stash" is a hash that contains all of the different objects that are
contained within a package.  Each key of the stash is a symbol name
(shared by all the different types of objects that have the same name),
and each value in the hash table is a GV (Glob Value).  This GV in turn
contains references to the various objects of that name, including (but
not limited to) the following:

     Scalar Value
     Array Value
     Hash Value
     I/O Handle
     Format
     Subroutine

   There is a single stash called "PL_defstash" that holds the items that
exist in the "main" package.  To get at the items in other packages,
append the string "::" to the package name.  The items in the "Foo"
package are in the stash "Foo::" in PL_defstash.  The items in the
"Bar::Baz" package are in the stash "Baz::" in "Bar::"'s stash.

   To get the stash pointer for a particular package, use the function:

     HV*  gv_stashpv(const char* name, I32 create)
     HV*  gv_stashsv(SV*, I32 create)

   The first function takes a literal string, the second uses the string
stored in the SV.  Remember that a stash is just a hash table, so you get
back an `HV*'.  The create flag will create a new package if it is set.

   The name that `gv_stash*v' wants is the name of the package whose
symbol table you want.  The default package is called main.  If you have
multiply nested packages, pass their names to `gv_stash*v', separated by
`::' as in the Perl language itself.

   Alternately, if you have an SV that is a blessed reference, you can find
out the stash pointer by using:

     HV*  SvSTASH(SvRV(SV*));

   then use the following to get the package name itself:

     char*  HvNAME(HV* stash);

   If you need to bless or re-bless an object you can use the following
function:

     SV*  sv_bless(SV*, HV* stash)

   where the first argument, an `SV*', must be a reference, and the second
argument is a stash.  The returned `SV*' can now be used in the same way
as any other SV.

   For more information on references and blessings, consult *Note
Perlref: perlref,.

Double-Typed SVs
----------------

   Scalar variables normally contain only one type of value, an integer,
double, pointer, or reference.  Perl will automatically convert the actual
scalar data from the stored type into the requested type.

   Some scalar variables contain more than one type of scalar data.  For
example, the variable $! contains either the numeric value of errno or its
string equivalent from either strerror or `sys_errlist[]'.

   To force multiple data values into an SV, you must do two things: use
the `sv_set*v' routines to add the additional scalar type, then set a flag
so that Perl will believe it contains more than one type of data.  The
four macros to set the flags are:

     SvIOK_on
     SvNOK_on
     SvPOK_on
     SvROK_on

   The particular macro you must use depends on which `sv_set*v' routine
you called first.  This is because every `sv_set*v' routine turns on only
the bit for the particular type of data being set, and turns off all the
rest.

   For example, to create a new Perl variable called "dberror" that
contains both the numeric and descriptive string error values, you could
use the following code:

     extern int  dberror;
     extern char *dberror_list;

     SV* sv = get_sv("dberror", TRUE);
     sv_setiv(sv, (IV) dberror);
     sv_setpv(sv, dberror_list[dberror]);
     SvIOK_on(sv);

   If the order of sv_setiv and sv_setpv had been reversed, then the macro
SvPOK_on would need to be called instead of SvIOK_on.

Magic Variables
---------------

   [This section still under construction.  Ignore everything here.  Post
no bills.  Everything not permitted is forbidden.]

   Any SV may be magical, that is, it has special features that a normal
SV does not have.  These features are stored in the SV structure in a
linked list of `struct magic''s, typedef'ed to MAGIC.

     struct magic {
         MAGIC*      mg_moremagic;
         MGVTBL*     mg_virtual;
         U16         mg_private;
         char        mg_type;
         U8          mg_flags;
         SV*         mg_obj;
         char*       mg_ptr;
         I32         mg_len;
     };

   Note this is current as of patchlevel 0, and could change at any time.

Assigning Magic
---------------

   Perl adds magic to an SV using the sv_magic function:

     void sv_magic(SV* sv, SV* obj, int how, const char* name, I32 namlen);

   The sv argument is a pointer to the SV that is to acquire a new magical
feature.

   If sv is not already magical, Perl uses the SvUPGRADE macro to set the
SVt_PVMG flag for the sv.  Perl then continues by adding it to the
beginning of the linked list of magical features.  Any prior entry of the
same type of magic is deleted.  Note that this can be overridden, and
multiple instances of the same type of magic can be associated with an SV.

   The name and `namlen' arguments are used to associate a string with the
magic, typically the name of a variable. `namlen' is stored in the
`mg_len' field and if name is non-null and `namlen' >= 0 a malloc'd copy
of the name is stored in `mg_ptr' field.

   The sv_magic function uses how to determine which, if any, predefined
"Magic Virtual Table" should be assigned to the `mg_virtual' field.  See
the "Magic Virtual Table" section below.  The how argument is also stored
in the `mg_type' field.

   The `obj' argument is stored in the `mg_obj' field of the MAGIC
structure.  If it is not the same as the sv argument, the reference count
of the `obj' object is incremented.  If it is the same, or if the how
argument is "#", or if it is a NULL pointer, then `obj' is merely stored,
without the reference count being incremented.

   There is also a function to add magic to an HV:

     void hv_magic(HV *hv, GV *gv, int how);

   This simply calls sv_magic and coerces the gv argument into an SV.

   To remove the magic from an SV, call the function sv_unmagic:

     void sv_unmagic(SV *sv, int type);

   The type argument should be equal to the how value when the SV was
initially made magical.

Magic Virtual Tables
--------------------

   The `mg_virtual' field in the MAGIC structure is a pointer to a
`MGVTBL', which is a structure of function pointers and stands for "Magic
Virtual Table" to handle the various operations that might be applied to
that variable.

   The `MGVTBL' has five pointers to the following routine types:

     int  (*svt_get)(SV* sv, MAGIC* mg);
     int  (*svt_set)(SV* sv, MAGIC* mg);
     U32  (*svt_len)(SV* sv, MAGIC* mg);
     int  (*svt_clear)(SV* sv, MAGIC* mg);
     int  (*svt_free)(SV* sv, MAGIC* mg);

   This MGVTBL structure is set at compile-time in `perl.h' and there are
currently 19 types (or 21 with overloading turned on).  These different
structures contain pointers to various routines that perform additional
actions depending on which function is being called.

     Function pointer    Action taken
     ----------------    ------------
     svt_get             Do something after the value of the SV is retrieved.
     svt_set             Do something after the SV is assigned a value.
     svt_len             Report on the SV's length.
     svt_clear		Clear something the SV represents.
     svt_free            Free any extra storage associated with the SV.

   For instance, the MGVTBL structure called `vtbl_sv' (which corresponds
to an `mg_type' of '\0') contains:

     { magic_get, magic_set, magic_len, 0, 0 }

   Thus, when an SV is determined to be magical and of type '\0', if a get
operation is being performed, the routine `magic_get' is called.  All the
various routines for the various magical types begin with `magic_'.  NOTE:
the magic routines are not considered part of the Perl API, and may not be
exported by the Perl library.

   The current kinds of Magic Virtual Tables are:

     mg_type  MGVTBL              Type of magic
     -------  ------              ----------------------------
     \0       vtbl_sv             Special scalar variable
     A        vtbl_amagic         %OVERLOAD hash
     a        vtbl_amagicelem     %OVERLOAD hash element
     c        (none)              Holds overload table (AMT) on stash
     B        vtbl_bm             Boyer-Moore (fast string search)
     E        vtbl_env            %ENV hash
     e        vtbl_envelem        %ENV hash element
     f        vtbl_fm             Formline ('compiled' format)
     g        vtbl_mglob          m//g target / study()ed string
     I        vtbl_isa            @ISA array
     i        vtbl_isaelem        @ISA array element
     k        vtbl_nkeys          scalar(keys()) lvalue
     L        (none)              Debugger %_<filename
     l        vtbl_dbline         Debugger %_<filename element
     o        vtbl_collxfrm       Locale transformation
     P        vtbl_pack           Tied array or hash
     p        vtbl_packelem       Tied array or hash element
     q        vtbl_packelem       Tied scalar or handle
     S        vtbl_sig            %SIG hash
     s        vtbl_sigelem        %SIG hash element
     t        vtbl_taint          Taintedness
     U        vtbl_uvar           Available for use by extensions
     v        vtbl_vec            vec() lvalue
     x        vtbl_substr         substr() lvalue
     y        vtbl_defelem        Shadow "foreach" iterator variable /
                                   smart parameter vivification
     *        vtbl_glob           GV (typeglob)
     #        vtbl_arylen         Array length ($#ary)
     .        vtbl_pos            pos() lvalue
     ~        (none)              Available for use by extensions

   When an uppercase and lowercase letter both exist in the table, then the
uppercase letter is used to represent some kind of composite type (a list
or a hash), and the lowercase letter is used to represent an element of
that composite type.

   The '~' and 'U' magic types are defined specifically for use by
extensions and will not be used by perl itself.  Extensions can use '~'
magic to 'attach' private information to variables (typically objects).
This is especially useful because there is no way for normal perl code to
corrupt this private information (unlike using extra elements of a hash
object).

   Similarly, 'U' magic can be used much like tie() to call a C function
any time a scalar's value is used or changed.  The MAGIC's `mg_ptr' field
points to a `ufuncs' structure:

     struct ufuncs {
         I32 (*uf_val)(IV, SV*);
         I32 (*uf_set)(IV, SV*);
         IV uf_index;
     };

   When the SV is read from or written to, the `uf_val' or `uf_set'
function will be called with `uf_index' as the first arg and a pointer to
the SV as the second.  A simple example of how to add 'U' magic is shown
below.  Note that the ufuncs structure is copied by sv_magic, so you can
safely allocate it on the stack.

     void
     Umagic(sv)
         SV *sv;
     PREINIT:
         struct ufuncs uf;
     CODE:
         uf.uf_val   = &my_get_fn;
         uf.uf_set   = &my_set_fn;
         uf.uf_index = 0;
         sv_magic(sv, 0, 'U', (char*)&uf, sizeof(uf));

   Note that because multiple extensions may be using '~' or 'U' magic, it
is important for extensions to take extra care to avoid conflict.
Typically only using the magic on objects blessed into the same class as
the extension is sufficient.  For '~' magic, it may also be appropriate to
add an I32 'signature' at the top of the private data area and check that.

   Also note that the `sv_set*()' and `sv_cat*()' functions described
earlier do not invoke 'set' magic on their targets.  This must be done by
the user either by calling the `SvSETMAGIC()' macro after calling these
functions, or by using one of the `sv_set*_mg()' or `sv_cat*_mg()'
functions.  Similarly, generic C code must call the `SvGETMAGIC()' macro
to invoke any 'get' magic if they use an SV obtained from external sources
in functions that don't handle magic.  See *Note Perlapi: perlapi, for a
description of these functions.  For example, calls to the `sv_cat*()'
functions typically need to be followed by `SvSETMAGIC()', but they don't
need a prior `SvGETMAGIC()' since their implementation handles 'get' magic.

Finding Magic
-------------

     MAGIC* mg_find(SV*, int type); /* Finds the magic pointer of that type */

   This routine returns a pointer to the MAGIC structure stored in the SV.
If the SV does not have that magical feature, NULL is returned.  Also, if
the SV is not of type SVt_PVMG, Perl may core dump.

     int mg_copy(SV* sv, SV* nsv, const char* key, STRLEN klen);

   This routine checks to see what types of magic sv has.  If the mg_type
field is an uppercase letter, then the mg_obj is copied to `nsv', but the
mg_type field is changed to be the lowercase letter.

Understanding the Magic of Tied Hashes and Arrays
-------------------------------------------------

   Tied hashes and arrays are magical beasts of the 'P' magic type.

   WARNING: As of the 5.004 release, proper usage of the array and hash
access functions requires understanding a few caveats.  Some of these
caveats are actually considered bugs in the API, to be fixed in later
releases, and are bracketed with [MAYCHANGE] below. If you find yourself
actually applying such information in this section, be aware that the
behavior may change in the future, umm, without warning.

   The perl tie function associates a variable with an object that
implements the various GET, SET etc methods.  To perform the equivalent of
the perl tie function from an XSUB, you must mimic this behaviour.  The
code below carries out the necessary steps - firstly it creates a new
hash, and then creates a second hash which it blesses into the class which
will implement the tie methods. Lastly it ties the two hashes together,
and returns a reference to the new tied hash.  Note that the code below
does NOT call the TIEHASH method in the MyTie class - see `Calling Perl
Routines from within C Programs' in this node for details on how to do
this.

     SV*
     mytie()
     PREINIT:
         HV *hash;
         HV *stash;
         SV *tie;
     CODE:
         hash = newHV();
         tie = newRV_noinc((SV*)newHV());
         stash = gv_stashpv("MyTie", TRUE);
         sv_bless(tie, stash);
         hv_magic(hash, tie, 'P');
         RETVAL = newRV_noinc(hash);
     OUTPUT:
         RETVAL

   The av_store function, when given a tied array argument, merely copies
the magic of the array onto the value to be "stored", using mg_copy.  It
may also return NULL, indicating that the value did not actually need to
be stored in the array.  [MAYCHANGE] After a call to av_store on a tied
array, the caller will usually need to call `mg_set(val)' to actually
invoke the perl level "STORE" method on the TIEARRAY object.  If av_store
did return NULL, a call to `SvREFCNT_dec(val)' will also be usually
necessary to avoid a memory leak. [/MAYCHANGE]

   The previous paragraph is applicable verbatim to tied hash access using
the hv_store and hv_store_ent functions as well.

   av_fetch and the corresponding hash functions hv_fetch and hv_fetch_ent
actually return an undefined mortal value whose magic has been initialized
using mg_copy.  Note the value so returned does not need to be
deallocated, as it is already mortal.  [MAYCHANGE] But you will need to
call `mg_get()' on the returned value in order to actually invoke the perl
level "FETCH" method on the underlying TIE object.  Similarly, you may
also call `mg_set()' on the return value after possibly assigning a
suitable value to it using sv_setsv,  which will invoke the "STORE" method
on the TIE object. [/MAYCHANGE]

   [MAYCHANGE] In other words, the array or hash fetch/store functions
don't really fetch and store actual values in the case of tied arrays and
hashes.  They merely call mg_copy to attach magic to the values that were
meant to be "stored" or "fetched".  Later calls to mg_get and mg_set
actually do the job of invoking the TIE methods on the underlying objects.
Thus the magic mechanism currently implements a kind of lazy access to
arrays and hashes.

   Currently (as of perl version 5.004), use of the hash and array access
functions requires the user to be aware of whether they are operating on
"normal" hashes and arrays, or on their tied variants.  The API may be
changed to provide more transparent access to both tied and normal data
types in future versions.  [/MAYCHANGE]

   You would do well to understand that the TIEARRAY and TIEHASH interfaces
are mere sugar to invoke some perl method calls while using the uniform
hash and array syntax.  The use of this sugar imposes some overhead
(typically about two to four extra opcodes per FETCH/STORE operation, in
addition to the creation of all the mortal variables required to invoke
the methods).  This overhead will be comparatively small if the TIE
methods are themselves substantial, but if they are only a few statements
long, the overhead will not be insignificant.

Localizing changes
------------------

   Perl has a very handy construction

     {
       local $var = 2;
       ...
     }

   This construction is *approximately* equivalent to

     {
       my $oldvar = $var;
       $var = 2;
       ...
       $var = $oldvar;
     }

   The biggest difference is that the first construction would reinstate
the initial value of $var, irrespective of how control exits the block:
goto, return, die/eval etc. It is a little bit more efficient as well.

   There is a way to achieve a similar task from C via Perl API: create a
*pseudo-block*, and arrange for some changes to be automatically undone at
the end of it, either explicit, or via a non-local exit (via die()). A
block-like construct is created by a pair of ENTER/LEAVE macros (see
`"Returning a Scalar"', *Note Perlcall: perlcall,).  Such a construct may
be created specially for some important localized task, or an existing one
(like boundaries of enclosing Perl subroutine/block, or an existing pair
for freeing TMPs) may be used. (In the second case the overhead of
additional localization must be almost negligible.) Note that any XSUB is
automatically enclosed in an ENTER/LEAVE pair.

   Inside such a *pseudo-block* the following service is available:

`SAVEINT(int i)'
`SAVEIV(IV i)'

`SAVEI32(I32 i)'
`SAVELONG(long i)'
     These macros arrange things to restore the value of integer variable
     i at the end of enclosing *pseudo-block*.

`SAVESPTR(s)'
`SAVEPPTR(p)'
     These macros arrange things to restore the value of pointers s and p.
     s must be a pointer of a type which survives conversion to `SV*' and
     back, p should be able to survive conversion to `char*' and back.

`SAVEFREESV(SV *sv)'
     The refcount of sv would be decremented at the end of *pseudo-block*.
     This is similar to sv_2mortal, which should (?) be used instead.

`SAVEFREEOP(OP *op)'
     The `OP *' is op_free()ed at the end of *pseudo-block*.

`SAVEFREEPV(p)'
     The chunk of memory which is pointed to by p is Safefree()ed at the
     end of *pseudo-block*.

`SAVECLEARSV(SV *sv)'
     Clears a slot in the current scratchpad which corresponds to sv at
     the end of *pseudo-block*.

`SAVEDELETE(HV *hv, char *key, I32 length)'
     The key key of hv is deleted at the end of *pseudo-block*. The string
     pointed to by key is Safefree()ed.  If one has a key in short-lived
     storage, the corresponding string may be reallocated like this:

          SAVEDELETE(PL_defstash, savepv(tmpbuf), strlen(tmpbuf));

`SAVEDESTRUCTOR(DESTRUCTORFUNC_NOCONTEXT_t f, void *p)'
     At the end of *pseudo-block* the function f is called with the only
     argument p.

`SAVEDESTRUCTOR_X(DESTRUCTORFUNC_t f, void *p)'
     At the end of *pseudo-block* the function f is called with the
     implicit context argument (if any), and p.

`SAVESTACK_POS()'
     The current offset on the Perl internal stack (cf. SP) is restored at
     the end of *pseudo-block*.

   The following API list contains functions, thus one needs to provide
pointers to the modifiable data explicitly (either C pointers, or Perlish
`GV *'s).  Where the above macros take int, a similar function takes `int
*'.

   * save_scalar(GV *gv)

     Equivalent to Perl code `local $gv'.

   * save_ary(GV *gv)

   * save_hash(GV *gv)

     Similar to `save_scalar', but localize `@gv' and `%gv'.

   * `void save_item(SV *item)' Duplicates the current value of SV, on the
     exit from the current ENTER/LEAVE *pseudo-block* will restore the
     value of SV using the stored value.

   * `void save_list(SV **sarg, I32 maxsarg)' A variant of `save_item'
     which takes multiple arguments via an array `sarg' of `SV*' of length
     `maxsarg'.

   * save_svref(SV **sptr)

     Similar to `save_scalar', but will reinstate a `SV *'.

   * `void save_aptr(AV **aptr)' Similar to `save_svref', but localize `AV
     *' and `HV *'.

   The Alias module implements localization of the basic types within the
*caller's scope*.  People who are interested in how to localize things in
the containing scope should take a look there too.

Subroutines
===========

XSUBs and the Argument Stack
----------------------------

   The XSUB mechanism is a simple way for Perl programs to access C
subroutines.  An XSUB routine will have a stack that contains the
arguments from the Perl program, and a way to map from the Perl data
structures to a C equivalent.

   The stack arguments are accessible through the `ST(n)' macro, which
returns the n'th stack argument.  Argument 0 is the first argument passed
in the Perl subroutine call.  These arguments are `SV*', and can be used
anywhere an `SV*' is used.

   Most of the time, output from the C routine can be handled through use
of the RETVAL and OUTPUT directives.  However, there are some cases where
the argument stack is not already long enough to handle all the return
values.  An example is the POSIX tzname() call, which takes no arguments,
but returns two, the local time zone's standard and summer time
abbreviations.

   To handle this situation, the PPCODE directive is used and the stack is
extended using the macro:

     EXTEND(SP, num);

   where SP is the macro that represents the local copy of the stack
pointer, and num is the number of elements the stack should be extended by.

   Now that there is room on the stack, values can be pushed on it using
the macros to push IVs, doubles, strings, and SV pointers respectively:

     PUSHi(IV)
     PUSHn(double)
     PUSHp(char*, I32)
     PUSHs(SV*)

   And now the Perl program calling tzname, the two values will be assigned
as in:

     ($standard_abbrev, $summer_abbrev) = POSIX::tzname;

   An alternate (and possibly simpler) method to pushing values on the
stack is to use the macros:

     XPUSHi(IV)
     XPUSHn(double)
     XPUSHp(char*, I32)
     XPUSHs(SV*)

   These macros automatically adjust the stack for you, if needed.  Thus,
you do not need to call EXTEND to extend the stack.

   For more information, consult *Note Perlxs: perlxs, and *Note
Perlxstut: perlxstut,.

Calling Perl Routines from within C Programs
--------------------------------------------

   There are four routines that can be used to call a Perl subroutine from
within a C program.  These four are:

     I32  call_sv(SV*, I32);
     I32  call_pv(const char*, I32);
     I32  call_method(const char*, I32);
     I32  call_argv(const char*, I32, register char**);

   The routine most often used is call_sv.  The `SV*' argument contains
either the name of the Perl subroutine to be called, or a reference to the
subroutine.  The second argument consists of flags that control the
context in which the subroutine is called, whether or not the subroutine
is being passed arguments, how errors should be trapped, and how to treat
return values.

   All four routines return the number of arguments that the subroutine
returned on the Perl stack.

   These routines used to be called `perl_call_sv' etc., before Perl
v5.6.0, but those names are now deprecated; macros of the same name are
provided for compatibility.

   When using any of these routines (except call_argv), the programmer
must manipulate the Perl stack.  These include the following macros and
functions:

     dSP
     SP
     PUSHMARK()
     PUTBACK
     SPAGAIN
     ENTER
     SAVETMPS
     FREETMPS
     LEAVE
     XPUSH*()
     POP*()

   For a detailed description of calling conventions from C to Perl,
consult *Note Perlcall: perlcall,.

Memory Allocation
-----------------

   All memory meant to be used with the Perl API functions should be
manipulated using the macros described in this section.  The macros
provide the necessary transparency between differences in the actual
malloc implementation that is used within perl.

   It is suggested that you enable the version of malloc that is
distributed with Perl.  It keeps pools of various sizes of unallocated
memory in order to satisfy allocation requests more quickly.  However, on
some platforms, it may cause spurious malloc or free errors.

     New(x, pointer, number, type);
     Newc(x, pointer, number, type, cast);
     Newz(x, pointer, number, type);

   These three macros are used to initially allocate memory.

   The first argument x was a "magic cookie" that was used to keep track
of who called the macro, to help when debugging memory problems.  However,
the current code makes no use of this feature (most Perl developers now
use run-time memory checkers), so this argument can be any number.

   The second argument pointer should be the name of a variable that will
point to the newly allocated memory.

   The third and fourth arguments number and type specify how many of the
specified type of data structure should be allocated.  The argument type
is passed to `sizeof'.  The final argument to Newc, `cast', should be used
if the pointer argument is different from the type argument.

   Unlike the New and Newc macros, the Newz macro calls `memzero' to zero
out all the newly allocated memory.

     Renew(pointer, number, type);
     Renewc(pointer, number, type, cast);
     Safefree(pointer)

   These three macros are used to change a memory buffer size or to free a
piece of memory no longer needed.  The arguments to Renew and Renewc match
those of New and Newc with the exception of not needing the "magic cookie"
argument.

     Move(source, dest, number, type);
     Copy(source, dest, number, type);
     Zero(dest, number, type);

   These three macros are used to move, copy, or zero out previously
allocated memory.  The source and dest arguments point to the source and
destination starting points.  Perl will move, copy, or zero out number
instances of the size of the type data structure (using the `sizeof'
function).

PerlIO
------

   The most recent development releases of Perl has been experimenting with
removing Perl's dependency on the "normal" standard I/O suite and allowing
other stdio implementations to be used.  This involves creating a new
abstraction layer that then calls whichever implementation of stdio Perl
was compiled with.  All XSUBs should now use the functions in the PerlIO
abstraction layer and not make any assumptions about what kind of stdio is
being used.

   For a complete description of the PerlIO abstraction, consult *Note
Perlapio: perlapio,.

Putting a C value on Perl stack
-------------------------------

   A lot of opcodes (this is an elementary operation in the internal perl
stack machine) put an SV* on the stack. However, as an optimization the
corresponding SV is (usually) not recreated each time. The opcodes reuse
specially assigned SVs (targets) which are (as a corollary) not constantly
freed/created.

   Each of the targets is created only once (but see `Scratchpads and
recursion' in this node below), and when an opcode needs to put an
integer, a double, or a string on stack, it just sets the corresponding
parts of its target and puts the target on stack.

   The macro to put this target on stack is `PUSHTARG', and it is directly
used in some opcodes, as well as indirectly in zillions of others, which
use it via `(X)PUSH[pni]'.

Scratchpads
-----------

   The question remains on when the SVs which are targets for opcodes are
created. The answer is that they are created when the current unit - a
subroutine or a file (for opcodes for statements outside of subroutines) -
is compiled. During this time a special anonymous Perl array is created,
which is called a scratchpad for the current unit.

   A scratchpad keeps SVs which are lexicals for the current unit and are
targets for opcodes. One can deduce that an SV lives on a scratchpad by
looking on its flags: lexicals have `SVs_PADMY' set, and targets have
`SVs_PADTMP' set.

   The correspondence between OPs and targets is not 1-to-1. Different OPs
in the compile tree of the unit can use the same target, if this would not
conflict with the expected life of the temporary.

Scratchpads and recursion
-------------------------

   In fact it is not 100% true that a compiled unit contains a pointer to
the scratchpad AV. In fact it contains a pointer to an AV of (initially)
one element, and this element is the scratchpad AV. Why do we need an
extra level of indirection?

   The answer is *recursion*, and maybe (sometime soon) threads. Both
these can create several execution pointers going into the same
subroutine. For the subroutine-child not write over the temporaries for
the subroutine-parent (lifespan of which covers the call to the child),
the parent and the child should have different scratchpads. (And the
lexicals should be separate anyway!)

   So each subroutine is born with an array of scratchpads (of length 1).
On each entry to the subroutine it is checked that the current depth of
the recursion is not more than the length of this array, and if it is, new
scratchpad is created and pushed into the array.

   The targets on this scratchpad are undefs, but they are already marked
with correct flags.

Compiled code
=============

Code tree
---------

   Here we describe the internal form your code is converted to by Perl.
Start with a simple example:

     $a = $b + $c;

   This is converted to a tree similar to this one:

     assign-to
                /           \
               +             $a
             /   \
           $b     $c

   (but slightly more complicated).  This tree reflects the way Perl
parsed your code, but has nothing to do with the execution order.  There
is an additional "thread" going through the nodes of the tree which shows
the order of execution of the nodes.  In our simplified example above it
looks like:

     $b ---> $c ---> + ---> $a ---> assign-to

   But with the actual compile tree for `$a = $b + $c' it is different:
some nodes *optimized away*.  As a corollary, though the actual tree
contains more nodes than our simplified example, the execution order is
the same as in our example.

Examining the tree
------------------

   If you have your perl compiled for debugging (usually done with `-D
optimize=-g' on Configure command line), you may examine the compiled tree
by specifying `-Dx' on the Perl command line.  The output takes several
lines per node, and for `$b+$c' it looks like this:

     5           TYPE = add  ===> 6
                 TARG = 1
                 FLAGS = (SCALAR,KIDS)
                 {
                     TYPE = null  ===> (4)
                       (was rv2sv)
                     FLAGS = (SCALAR,KIDS)
                     {
     3                   TYPE = gvsv  ===> 4
                         FLAGS = (SCALAR)
                         GV = main::b
                     }
                 }
                 {
                     TYPE = null  ===> (5)
                       (was rv2sv)
                     FLAGS = (SCALAR,KIDS)
                     {
     4                   TYPE = gvsv  ===> 5
                         FLAGS = (SCALAR)
                         GV = main::c
                     }
                 }

   This tree has 5 nodes (one per TYPE specifier), only 3 of them are not
optimized away (one per number in the left column).  The immediate
children of the given node correspond to `{}' pairs on the same level of
indentation, thus this listing corresponds to the tree:

     add
                      /     \
                    null    null
                     |       |
                    gvsv    gvsv

   The execution order is indicated by `===>' marks, thus it is `3 4 5 6'
(node 6 is not included into above listing), i.e., `gvsv gvsv add
whatever'.

Compile pass 1: check routines
------------------------------

   The tree is created by the *pseudo-compiler* while yacc code feeds it
the constructions it recognizes. Since yacc works bottom-up, so does the
first pass of perl compilation.

   What makes this pass interesting for perl developers is that some
optimization may be performed on this pass.  This is optimization by
so-called *check routines*.  The correspondence between node names and
corresponding check routines is described in `opcode.pl' (do not forget to
run `make regen_headers' if you modify this file).

   A check routine is called when the node is fully constructed except for
the execution-order thread.  Since at this time there are no back-links to
the currently constructed node, one can do most any operation to the
top-level node, including freeing it and/or creating new nodes above/below
it.

   The check routine returns the node which should be inserted into the
tree (if the top-level node was not modified, check routine returns its
argument).

   By convention, check routines have names `ck_*'. They are usually
called from `new*OP' subroutines (or convert) (which in turn are called
from `perly.y').

Compile pass 1a: constant folding
---------------------------------

   Immediately after the check routine is called the returned node is
checked for being compile-time executable.  If it is (the value is judged
to be constant) it is immediately executed, and a constant node with the
"return value" of the corresponding subtree is substituted instead.  The
subtree is deleted.

   If constant folding was not performed, the execution-order thread is
created.

Compile pass 2: context propagation
-----------------------------------

   When a context for a part of compile tree is known, it is propagated
down through the tree.  At this time the context can have 5 values
(instead of 2 for runtime context): void, boolean, scalar, list, and
lvalue.  In contrast with the pass 1 this pass is processed from top to
bottom: a node's context determines the context for its children.

   Additional context-dependent optimizations are performed at this time.
Since at this moment the compile tree contains back-references (via
"thread" pointers), nodes cannot be free()d now.  To allow optimized-away
nodes at this stage, such nodes are null()ified instead of free()ing (i.e.
their type is changed to OP_NULL).

Compile pass 3: peephole optimization
-------------------------------------

   After the compile tree for a subroutine (or for an eval or a file) is
created, an additional pass over the code is performed. This pass is
neither top-down or bottom-up, but in the execution order (with additional
complications for conditionals).  These optimizations are done in the
subroutine peep().  Optimizations performed at this stage are subject to
the same restrictions as in the pass 2.

How multiple interpreters and concurrency are supported
=======================================================

   WARNING: This information is subject to radical changes prior to the
Perl 5.6 release.  Use with caution.

Background and PERL_IMPLICIT_CONTEXT
------------------------------------

   The Perl interpreter can be regarded as a closed box: it has an API for
feeding it code or otherwise making it do things, but it also has
functions for its own use.  This smells a lot like an object, and there
are ways for you to build Perl so that you can have multiple interpreters,
with one interpreter represented either as a C++ object, a C structure, or
inside a thread.  The thread, the C structure, or the C++ object will
contain all the context, the state of that interpreter.

   Three macros control the major Perl build flavors: MULTIPLICITY,
USE_THREADS and PERL_OBJECT.  The MULTIPLICITY build has a C structure
that packages all the interpreter state, there is a similar thread-specific
data structure under USE_THREADS, and the PERL_OBJECT build has a C++
class to maintain interpreter state.  In all three cases,
PERL_IMPLICIT_CONTEXT is also normally defined, and enables the support
for passing in a "hidden" first argument that represents all three data
structures.

   All this obviously requires a way for the Perl internal functions to be
C++ methods, subroutines taking some kind of structure as the first
argument, or subroutines taking nothing as the first argument.  To enable
these three very different ways of building the interpreter, the Perl
source (as it does in so many other situations) makes heavy use of macros
and subroutine naming conventions.

   First problem: deciding which functions will be public API functions and
which will be private.  All functions whose names begin `S_' are private
(think "S" for "secret" or "static").  All other functions begin with
"Perl_", but just because a function begins with "Perl_" does not mean it
is part of the API. The easiest way to be *sure* a function is part of the
API is to find its entry in *Note Perlapi: perlapi,.  If it exists in
*Note Perlapi: perlapi,, it's part of the API.  If it doesn't, and you
think it should be (i.e., you need it fo r your extension), send mail via
`perlbug' in this node explaining why you think it should be.

   (*Note Perlapi: perlapi, itself is generated by embed.pl, a Perl script
that generates significant portions of the Perl source code.  It has a
list of almost all the functions defined by the Perl interpreter along
with their calling characteristics and some flags.  Functions that are
part of the public API are marked with an 'A' in its flags.)

   Second problem: there must be a syntax so that the same subroutine
declarations and calls can pass a structure as their first argument, or
pass nothing.  To solve this, the subroutines are named and declared in a
particular way.  Here's a typical start of a static function used within
the Perl guts:

     STATIC void
     S_incline(pTHX_ char *s)

   STATIC becomes "static" in C, and is #define'd to nothing in C++.

   A public function (i.e. part of the internal API, but not necessarily
sanctioned for use in extensions) begins like this:

     void
     Perl_sv_setsv(pTHX_ SV* dsv, SV* ssv)

   `pTHX_' is one of a number of macros (in perl.h) that hide the details
of the interpreter's context.  THX stands for "thread", "this", or
"thingy", as the case may be.  (And no, George Lucas is not involved. :-)
The first character could be 'p' for a prototype, 'a' for argument, or 'd'
for declaration.

   When Perl is built without PERL_IMPLICIT_CONTEXT, there is no first
argument containing the interpreter's context.  The trailing underscore in
the pTHX_ macro indicates that the macro expansion needs a comma after the
context argument because other arguments follow it.  If
PERL_IMPLICIT_CONTEXT is not defined, pTHX_ will be ignored, and the
subroutine is not prototyped to take the extra argument.  The form of the
macro without the trailing underscore is used when there are no additional
explicit arguments.

   When a core function calls another, it must pass the context.  This is
normally hidden via macros.  Consider sv_setsv.  It expands something like
this:

     ifdef PERL_IMPLICIT_CONTEXT
       define sv_setsv(a,b)	Perl_sv_setsv(aTHX_ a, b)
       /* can't do this for vararg functions, see below */
     else
       define sv_setsv		Perl_sv_setsv
     endif

   This works well, and means that XS authors can gleefully write:

     sv_setsv(foo, bar);

   and still have it work under all the modes Perl could have been
compiled with.

   Under PERL_OBJECT in the core, that will translate to either:

     CPerlObj::Perl_sv_setsv(foo,bar);  # in CPerlObj functions,
                                        # C++ takes care of 'this'
       or

     pPerl->Perl_sv_setsv(foo,bar);     # in truly static functions,
                                        # see objXSUB.h

   Under PERL_OBJECT in extensions (aka PERL_CAPI), or under
MULTIPLICITY/USE_THREADS w/ PERL_IMPLICIT_CONTEXT in both core and
extensions, it will be:

     Perl_sv_setsv(aTHX_ foo, bar);     # the canonical Perl "API"
                                        # for all build flavors

   This doesn't work so cleanly for varargs functions, though, as macros
imply that the number of arguments is known in advance.  Instead we either
need to spell them out fully, passing `aTHX_' as the first argument (the
Perl core tends to do this with functions like Perl_warner), or use a
context-free version.

   The context-free version of Perl_warner is called
Perl_warner_nocontext, and does not take the extra argument.  Instead it
does dTHX; to get the context from thread-local storage.  We `#define
warner Perl_warner_nocontext' so that extensions get source compatibility
at the expense of performance.  (Passing an arg is cheaper than grabbing
it from thread-local storage.)

   You can ignore [pad]THX[xo] when browsing the Perl headers/sources.
Those are strictly for use within the core.  Extensions and embedders need
only be aware of [pad]THX.

How do I use all this in extensions?
------------------------------------

   When Perl is built with PERL_IMPLICIT_CONTEXT, extensions that call any
functions in the Perl API will need to pass the initial context argument
somehow.  The kicker is that you will need to write it in such a way that
the extension still compiles when Perl hasn't been built with
PERL_IMPLICIT_CONTEXT enabled.

   There are three ways to do this.  First, the easy but inefficient way,
which is also the default, in order to maintain source compatibility with
extensions: whenever XSUB.h is #included, it redefines the aTHX and aTHX_
macros to call a function that will return the context.  Thus, something
like:

     sv_setsv(asv, bsv);

   in your extesion will translate to this when PERL_IMPLICIT_CONTEXT is
in effect:

     Perl_sv_setsv(Perl_get_context(), asv, bsv);

   or to this otherwise:

     Perl_sv_setsv(asv, bsv);

   You have to do nothing new in your extension to get this; since the
Perl library provides Perl_get_context(), it will all just work.

   The second, more efficient way is to use the following template for
your Foo.xs:

     #define PERL_NO_GET_CONTEXT	/* we want efficiency */
     #include "EXTERN.h"
     #include "perl.h"
     #include "XSUB.h"

     static my_private_function(int arg1, int arg2);

     static SV *
     my_private_function(int arg1, int arg2)
     {
         dTHX;	/* fetch context */
         ... call many Perl API functions ...
     }

     [... etc ...]

     MODULE = Foo		PACKAGE = Foo

     /* typical XSUB */

     void
     my_xsub(arg)
     	int arg
         CODE:
     	my_private_function(arg, 10);

   Note that the only two changes from the normal way of writing an
extension is the addition of a `#define PERL_NO_GET_CONTEXT' before
including the Perl headers, followed by a `dTHX;' declaration at the start
of every function that will call the Perl API.  (You'll know which
functions need this, because the C compiler will complain that there's an
undeclared identifier in those functions.)  No changes are needed for the
XSUBs themselves, because the XS() macro is correctly defined to pass in
the implicit context if needed.

   The third, even more efficient way is to ape how it is done within the
Perl guts:

     #define PERL_NO_GET_CONTEXT	/* we want efficiency */
     #include "EXTERN.h"
     #include "perl.h"
     #include "XSUB.h"

     /* pTHX_ only needed for functions that call Perl API */
     static my_private_function(pTHX_ int arg1, int arg2);

     static SV *
     my_private_function(pTHX_ int arg1, int arg2)
     {
         /* dTHX; not needed here, because THX is an argument */
         ... call Perl API functions ...
     }

     [... etc ...]

     MODULE = Foo		PACKAGE = Foo

     /* typical XSUB */

     void
     my_xsub(arg)
     	int arg
         CODE:
     	my_private_function(aTHX_ arg, 10);

   This implementation never has to fetch the context using a function
call, since it is always passed as an extra argument.  Depending on your
needs for simplicity or efficiency, you may mix the previous two
approaches freely.

   Never add a comma after `pTHX' yourself-always use the form of the
macro with the underscore for functions that take explicit arguments, or
the form without the argument for functions with no explicit arguments.

Future Plans and PERL_IMPLICIT_SYS
----------------------------------

   Just as PERL_IMPLICIT_CONTEXT provides a way to bundle up everything
that the interpreter knows about itself and pass it around, so too are
there plans to allow the interpreter to bundle up everything it knows
about the environment it's running on.  This is enabled with the
PERL_IMPLICIT_SYS macro.  Currently it only works with PERL_OBJECT, but is
mostly there for MULTIPLICITY and USE_THREADS (see inside iperlsys.h).

   This allows the ability to provide an extra pointer (called the "host"
environment) for all the system calls.  This makes it possible for all the
system stuff to maintain their own state, broken down into seven C
structures.  These are thin wrappers around the usual system calls (see
win32/perllib.c) for the default perl executable, but for a more ambitious
host (like the one that would do fork() emulation) all the extra work
needed to pretend that different interpreters are actually different
"processes", would be done here.

   The Perl engine/interpreter and the host are orthogonal entities.
There could be one or more interpreters in a process, and one or more
"hosts", with free association between them.

AUTHORS
=======

   Until May 1997, this document was maintained by Jeff Okamoto
<okamoto@corp.hp.com>.  It is now maintained as part of Perl itself by the
Perl 5 Porters <perl5-porters@perl.org>.

   With lots of help and suggestions from Dean Roehrich, Malcolm Beattie,
Andreas Koenig, Paul Hudson, Ilya Zakharevich, Paul Marquess, Neil Bowers,
Matthew Green, Tim Bunce, Spider Boardman, Ulrich Pfeifer, Stephen
McCamant, and Gurusamy Sarathy.

   API Listing originally by Dean Roehrich <roehrich@cray.com>.

   Modifications to autogenerate the API listing (*Note Perlapi: perlapi,)
by Benjamin Stuhl.

SEE ALSO
========

   perlapi(1), perlintern(1), perlxs(1), perlembed(1)


File: perl.info,  Node: perlhack,  Next: perlhist,  Prev: perltodo,  Up: Top

How to hack at the Perl internals
*********************************

NAME
====

   perlhack - How to hack at the Perl internals

DESCRIPTION
===========

   This document attempts to explain how Perl development takes place, and
ends with some suggestions for people wanting to become bona fide porters.

   The perl5-porters mailing list is where the Perl standard distribution
is maintained and developed.  The list can get anywhere from 10 to 150
messages a day, depending on the heatedness of the debate.  Most days
there are two or three patches, extensions, features, or bugs being
discussed at a time.

   A searchable archive of the list is at:

     http://www.xray.mpe.mpg.de/mailing-lists/perl5-porters/

   The list is also archived under the usenet group name `perl.porters-gw'
at:

     http://www.deja.com/

   List subscribers (the porters themselves) come in several flavours.
Some are quiet curious lurkers, who rarely pitch in and instead watch the
ongoing development to ensure they're forewarned of new changes or
features in Perl.  Some are representatives of vendors, who are there to
make sure that Perl continues to compile and work on their platforms.
Some patch any reported bug that they know how to fix, some are actively
patching their pet area (threads, Win32, the regexp engine), while others
seem to do nothing but complain.  In other words, it's your usual mix of
technical people.

   Over this group of porters presides Larry Wall.  He has the final word
in what does and does not change in the Perl language.  Various releases
of Perl are shepherded by a "pumpking", a porter responsible for gathering
patches, deciding on a patch-by-patch feature-by-feature basis what will
and will not go into the release.  For instance, Gurusamy Sarathy is the
pumpking for the 5.6 release of Perl.

   In addition, various people are pumpkings for different things.  For
instance, Andy Dougherty and Jarkko Hietaniemi share the Configure
pumpkin, and Tom Christiansen is the documentation pumpking.

   Larry sees Perl development along the lines of the US government:
there's the Legislature (the porters), the Executive branch (the
pumpkings), and the Supreme Court (Larry).  The legislature can discuss
and submit patches to the executive branch all they like, but the
executive branch is free to veto them.  Rarely, the Supreme Court will
side with the executive branch over the legislature, or the legislature
over the executive branch.  Mostly, however, the legislature and the
executive branch are supposed to get along and work out their differences
without impeachment or court cases.

   You might sometimes see reference to Rule 1 and Rule 2.  Larry's power
as Supreme Court is expressed in The Rules:

  1. Larry is always by definition right about how Perl should behave.
     This means he has final veto power on the core functionality.

  2. Larry is allowed to change his mind about any matter at a later date,
     regardless of whether he previously invoked Rule 1.

        Got that?  Larry is always right, even when he was wrong.  It's
rare to see either Rule exercised, but they are often alluded to.

   New features and extensions to the language are contentious, because
the criteria used by the pumpkings, Larry, and other porters to decide
which features should be implemented and incorporated are not codified in
a few small design goals as with some other languages.  Instead, the
heuristics are flexible and often difficult to fathom.  Here is one
person's list, roughly in decreasing order of importance, of heuristics
that new features have to be weighed against:

Does concept match the general goals of Perl?
     These haven't been written anywhere in stone, but one approximation
     is:

          1. Keep it fast, simple, and useful.
          2. Keep features/concepts as orthogonal as possible.
          3. No arbitrary limits (platforms, data sizes, cultures).
          4. Keep it open and exciting to use/patch/advocate Perl everywhere.
          5. Either assimilate new technologies, or build bridges to them.

Where is the implementation?
     All the talk in the world is useless without an implementation.  In
     almost every case, the person or people who argue for a new feature
     will be expected to be the ones who implement it.  Porters capable of
     coding new features have their own agendas, and are not available to
     implement your (possibly good) idea.

Backwards compatibility
     It's a cardinal sin to break existing Perl programs.  New warnings are
     contentious-some say that a program that emits warnings is not
     broken, while others say it is.  Adding keywords has the potential to
     break programs, changing the meaning of existing token sequences or
     functions might break programs.

Could it be a module instead?
     Perl 5 has extension mechanisms, modules and XS, specifically to avoid
     the need to keep changing the Perl interpreter.  You can write modules
     that export functions, you can give those functions prototypes so they
     can be called like built-in functions, you can even write XS code to
     mess with the runtime data structures of the Perl interpreter if you
     want to implement really complicated things.  If it can be done in a
     module instead of in the core, it's highly unlikely to be added.

Is the feature generic enough?
     Is this something that only the submitter wants added to the language,
     or would it be broadly useful?  Sometimes, instead of adding a feature
     with a tight focus, the porters might decide to wait until someone
     implements the more generalized feature.  For instance, instead of
     implementing a "delayed evaluation" feature, the porters are waiting
     for a macro system that would permit delayed evaluation and much more.

Does it potentially introduce new bugs?
     Radical rewrites of large chunks of the Perl interpreter have the
     potential to introduce new bugs.  The smaller and more localized the
     change, the better.

Does it preclude other desirable features?
     A patch is likely to be rejected if it closes off future avenues of
     development.  For instance, a patch that placed a true and final
     interpretation on prototypes is likely to be rejected because there
     are still options for the future of prototypes that haven't been
     addressed.

Is the implementation robust?
     Good patches (tight code, complete, correct) stand more chance of
     going in.  Sloppy or incorrect patches might be placed on the back
     burner until the pumpking has time to fix, or might be discarded
     altogether without further notice.

Is the implementation generic enough to be portable?
     The worst patches make use of a system-specific features.  It's highly
     unlikely that nonportable additions to the Perl language will be
     accepted.

Is there enough documentation?
     Patches without documentation are probably ill-thought out or
     incomplete.  Nothing can be added without documentation, so submitting
     a patch for the appropriate manpages as well as the source code is
     always a good idea.  If appropriate, patches should add to the test
     suite as well.

Is there another way to do it?
     Larry said "Although the Perl Slogan is *There's More Than One Way to
     Do It*, I hesitate to make 10 ways to do something".  This is a
     tricky heuristic to navigate, though-one man's essential addition is
     another man's pointless cruft.

Does it create too much work?
     Work for the pumpking, work for Perl programmers, work for module
     authors, ...  Perl is supposed to be easy.

Patches speak louder than words
     Working code is always preferred to pie-in-the-sky ideas.  A patch to
     add a feature stands a much higher chance of making it to the language
     than does a random feature request, no matter how fervently argued the
     request might be.  This ties into "Will it be useful?", as the fact
     that someone took the time to make the patch demonstrates a strong
     desire for the feature.

   If you're on the list, you might hear the word "core" bandied around.
It refers to the standard distribution.  "Hacking on the core" means
you're changing the C source code to the Perl interpreter.  "A core
module" is one that ships with Perl.

   The source code to the Perl interpreter, in its different versions, is
kept in a repository managed by a revision control system (which is
currently the Perforce program, see http://perforce.com/).  The pumpkings
and a few others have access to the repository to check in changes.
Periodically the pumpking for the development version of Perl will release
a new version, so the rest of the porters can see what's changed.  The
current state of the main trunk of repository, and patches that describe
the individual changes that have happened since the last public release
are available at this location:

     ftp://ftp.linux.activestate.com/pub/staff/gsar/APC/

   Selective parts are also visible via the rsync protocol.  To get all
the individual changes to the mainline since the last development release,
use the following command:

     rsync -avuz rsync://ftp.linux.activestate.com/perl-diffs perl-diffs

   Use this to get the latest source tree in full:

     rsync -avuz rsync://ftp.linux.activestate.com/perl-current perl-current

   Needless to say, the source code in perl-current is usually in a
perpetual state of evolution.  You should expect it to be very buggy.  Do
not use it for any purpose other than testing and development.

   Always submit patches to *perl5-porters@perl.org*.  This lets other
porters review your patch, which catches a surprising number of errors in
patches.  Either use the diff program (available in source code form from
*ftp://ftp.gnu.org/pub/gnu/*), or use Johan Vromans' *makepatch*
(available from *CPAN/authors/id/JV/*).  Unified diffs are preferred, but
context diffs are accepted.  Do not send RCS-style diffs or diffs without
context lines.  More information is given in the *Porting/patching.pod*
file in the Perl source distribution.  Please patch against the latest
*development* version (e.g., if you're fixing a bug in the 5.005 track,
patch against the latest 5.005_5x version).  Only patches that survive the
heat of the development branch get applied to maintenance versions.

   Your patch should update the documentation and test suite.

   To report a bug in Perl, use the program *perlbug* which comes with
Perl (if you can't get Perl to work, send mail to the address
*perlbug@perl.com* or *perlbug@perl.org*).  Reporting bugs through
*perlbug* feeds into the automated bug-tracking system, access to which is
provided through the web at *http://bugs.perl.org/*.  It often pays to
check the archives of the perl5-porters mailing list to see whether the
bug you're reporting has been reported before, and if so whether it was
considered a bug.  See above for the location of the searchable archives.

   The CPAN testers (*http://testers.cpan.org/*) are a group of volunteers
who test CPAN modules on a variety of platforms.  Perl Labs
(*http://labs.perl.org/*) automatically tests Perl source releases on
platforms and gives feedback to the CPAN testers mailing list.  Both
efforts welcome volunteers.

   To become an active and patching Perl porter, you'll need to learn how
Perl works on the inside.  Chip Salzenberg, a pumpking, has written
articles on Perl internals for The Perl Journal (*http://www.tpj.com/*)
which explain how various parts of the Perl interpreter work.  The
`perlguts' manpage explains the internal data structures.  And, of course,
the C source code (sometimes sparsely commented, sometimes commented well)
is a great place to start (begin with `perl.c' and see where it goes from
there).  A lot of the style of the Perl source is explained in the
*Porting/pumpkin.pod* file in the source distribution.

   It is essential that you be comfortable using a good debugger (e.g.
gdb, dbx) before you can patch perl.  Stepping through perl as it executes
a script is perhaps the best (if sometimes tedious) way to gain a precise
understanding of the overall architecture of the language.

   If you build a version of the Perl interpreter with `-DDEBUGGING',
Perl's -D command line flag will cause copious debugging information to be
emitted (see the `perlrun' manpage).  If you build a version of Perl with
compiler debugging information (e.g. with the C compiler's -g option
instead of -O) then you can step through the execution of the interpreter
with your favourite C symbolic debugger, setting breakpoints on particular
functions.

   It's a good idea to read and lurk for a while before chipping in.  That
way you'll get to see the dynamic of the conversations, learn the
personalities of the players, and hopefully be better prepared to make a
useful contribution when do you speak up.

   If after all this you still think you want to join the perl5-porters
mailing list, send mail to *perl5-porters-subscribe@perl.org*.  To
unsubscribe, send mail to *perl5-porters-unsubscribe@perl.org*.

AUTHOR
======

   This document was written by Nathan Torkington, and is maintained by
the perl5-porters mailing list.


File: perl.info,  Node: perlhist,  Next: perlamiga,  Prev: perlhack,  Up: Top

the Perl history records
************************

NAME
====

   perlhist - the Perl history records

   # # $Id: perlhist.pod,v 1.2 2000/01/24 11:44:47 jhi Exp $ #

DESCRIPTION
===========

   This document aims to record the Perl source code releases.

INTRODUCTION
============

   Perl history in brief, by Larry Wall:

     Perl 0 introduced Perl to my officemates.
     Perl 1 introduced Perl to the world, and changed /\(...\|...\)/ to
         /(...|...)/.  \(Dan Faigin still hasn't forgiven me. :-\)
     Perl 2 introduced Henry Spencer's regular expression package.
     Perl 3 introduced the ability to handle binary data (embedded nulls).
     Perl 4 introduced the first Camel book.  Really.  We mostly just
         switched version numbers so the book could refer to 4.000.
     Perl 5 introduced everything else, including the ability to
         introduce everything else.

THE KEEPERS OF THE PUMPKIN
==========================

   Larry Wall, Andy Dougherty, Tom Christiansen, Charles Bailey, Nick
Ing-Simmons, Chip Salzenberg, Tim Bunce, Malcolm Beattie, Gurusamy
Sarathy, Graham Barr.

PUMPKIN?
--------

   [from Porting/pumpkin.pod in the Perl source code distribution]

   Chip Salzenberg gets credit for that, with a nod to his cow orker,
David Croy.  We had passed around various names (baton, token, hot potato)
but none caught on.  Then, Chip asked:

   [begin quote]

     Who has the patch pumpkin?

   To explain:  David Croy once told me once that at a previous job, there
was one tape drive and multiple systems that used it for backups.  But
instead of some high-tech exclusion software, they used a low-tech method
to prevent multiple simultaneous backups: a stuffed pumpkin.  No one was
allowed to make backups unless they had the "backup pumpkin".

   [end quote]

   The name has stuck.  The holder of the pumpkin is sometimes called the
pumpking (keeping the source afloat?) or the pumpkineer (pulling the
strings?).

THE RECORDS
===========

     Pump-  Release         Date            Notes
     king                                   (by no means
                                             comprehensive,
                                             see Changes*
                                             for details)
     ===========================================================================

     Larry   0              Classified.     Don't ask.

     Larry   1.000          1987-Dec-18

     1.001..10     1988-Jan-30
     1.011..14     1988-Feb-02

     Larry   2.000          1988-Jun-05

     2.001         1988-Jun-28

     Larry   3.000          1989-Oct-18

     3.001         1989-Oct-26
     3.002..4      1989-Nov-11
     3.005         1989-Nov-18
     3.006..8      1989-Dec-22
     3.009..13     1990-Mar-02
     3.014         1990-Mar-13
     3.015         1990-Mar-14
     3.016..18     1990-Mar-28
     3.019..27     1990-Aug-10     User subs.
     3.028         1990-Aug-14
     3.029..36     1990-Oct-17
     3.037         1990-Oct-20
     3.040         1990-Nov-10
     3.041         1990-Nov-13
     3.042..43     1990-Jan-??
     3.044         1991-Jan-12

     Larry   4.000          1991-Mar-21

     4.001..3      1991-Apr-12
     4.004..9      1991-Jun-07
     4.010         1991-Jun-10
     4.011..18     1991-Nov-05
     4.019         1991-Nov-11     Stable.
     4.020..33     1992-Jun-08
     4.034         1992-Jun-11
     4.035         1992-Jun-23
      Larry    4.036         1993-Feb-05     Very stable.

     5.000alpha1   1993-Jul-31
     5.000alpha2   1993-Aug-16
     5.000alpha3   1993-Oct-10
     5.000alpha4   1993-???-??
     5.000alpha5   1993-???-??
     5.000alpha6   1994-Mar-18
     5.000alpha7   1994-Mar-25
      Andy     5.000alpha8   1994-Apr-04
      Larry    5.000alpha9   1994-May-05     ext appears.
     5.000alpha10  1994-Jun-11
     5.000alpha11  1994-Jul-01
      Andy     5.000a11a     1994-Jul-07     To fit 14.
     5.000a11b     1994-Jul-14
     5.000a11c     1994-Jul-19
     5.000a11d     1994-Jul-22
      Larry    5.000alpha12  1994-Aug-04
      Andy     5.000a12a     1994-Aug-08
     5.000a12b     1994-Aug-15
     5.000a12c     1994-Aug-22
     5.000a12d     1994-Aug-22
     5.000a12e     1994-Aug-22
     5.000a12f     1994-Aug-24
     5.000a12g     1994-Aug-24
     5.000a12h     1994-Aug-24
      Larry    5.000beta1    1994-Aug-30
      Andy     5.000b1a      1994-Sep-06
      Larry    5.000beta2    1994-Sep-14     Core slushified.
      Andy     5.000b2a      1994-Sep-14
     5.000b2b      1994-Sep-17
     5.000b2c      1994-Sep-17
      Larry    5.000beta3    1994-Sep-??
      Andy     5.000b3a      1994-Sep-18
     5.000b3b      1994-Sep-22
     5.000b3c      1994-Sep-23
     5.000b3d      1994-Sep-27
     5.000b3e      1994-Sep-28
     5.000b3f      1994-Sep-30
     5.000b3g      1994-Oct-04
      Andy     5.000b3h      1994-Oct-07
      Larry?   5.000gamma    1994-Oct-13?

     Larry   5.000          1994-Oct-17

     Andy     5.000a        1994-Dec-19
              5.000b        1995-Jan-18
              5.000c        1995-Jan-18
              5.000d        1995-Jan-18
              5.000e        1995-Jan-18
              5.000f        1995-Jan-18
              5.000g        1995-Jan-18
              5.000h        1995-Jan-18
              5.000i        1995-Jan-26
              5.000j        1995-Feb-07
              5.000k        1995-Feb-11
              5.000l        1995-Feb-21
              5.000m        1995-Feb-28
              5.000n        1995-Mar-07
              5.000o        1995-Mar-13?

     Larry   5.001          1995-Mar-13

     Andy     5.001a        1995-Mar-15
              5.001b        1995-Mar-31
              5.001c        1995-Apr-07
              5.001d        1995-Apr-14
              5.001e        1995-Apr-18     Stable.
              5.001f        1995-May-31
              5.001g        1995-May-25
              5.001h        1995-May-25
              5.001i        1995-May-30
              5.001j        1995-Jun-05
              5.001k        1995-Jun-06
              5.001l        1995-Jun-06     Stable.
              5.001m        1995-Jul-02     Very stable.
              5.001n        1995-Oct-31     Very unstable.
              5.002beta1    1995-Nov-21
              5.002b1a      1995-Dec-04
              5.002b1b      1995-Dec-04
              5.002b1c      1995-Dec-04
              5.002b1d      1995-Dec-04
              5.002b1e      1995-Dec-08
              5.002b1f      1995-Dec-08
     Tom      5.002b1g      1995-Dec-21     Doc release.
     Andy     5.002b1h      1996-Jan-05
              5.002b2       1996-Jan-14
     Larry    5.002b3       1996-Feb-02
     Andy     5.002gamma    1996-Feb-11
     Larry    5.002delta    1996-Feb-27

     Larry   5.002          1996-Feb-29     Prototypes.

     Charles  5.002_01      1996-Mar-25

     5.003          1996-Jun-25     Security release.

     5.003_01      1996-Jul-31
      Nick     5.003_02      1996-Aug-10
      Andy     5.003_03      1996-Aug-28
     5.003_04      1996-Sep-02
     5.003_05      1996-Sep-12
     5.003_06      1996-Oct-07
     5.003_07      1996-Oct-10
      Chip     5.003_08      1996-Nov-19
     5.003_09      1996-Nov-26
     5.003_10      1996-Nov-29
     5.003_11      1996-Dec-06
     5.003_12      1996-Dec-19
     5.003_13      1996-Dec-20
     5.003_14      1996-Dec-23
     5.003_15      1996-Dec-23
     5.003_16      1996-Dec-24
     5.003_17      1996-Dec-27
     5.003_18      1996-Dec-31
     5.003_19      1997-Jan-04
     5.003_20      1997-Jan-07
     5.003_21      1997-Jan-15
     5.003_22      1997-Jan-16
     5.003_23      1997-Jan-25
     5.003_24      1997-Jan-29
     5.003_25      1997-Feb-04
     5.003_26      1997-Feb-10
     5.003_27      1997-Feb-18
     5.003_28      1997-Feb-21
     5.003_90      1997-Feb-25     Ramping up to the 5.004 release.
     5.003_91      1997-Mar-01
     5.003_92      1997-Mar-06
     5.003_93      1997-Mar-10
     5.003_94      1997-Mar-22
     5.003_95      1997-Mar-25
     5.003_96      1997-Apr-01
     5.003_97      1997-Apr-03     Fairly widely used.
     5.003_97a     1997-Apr-05
     5.003_97b     1997-Apr-08
     5.003_97c     1997-Apr-10
     5.003_97d     1997-Apr-13
     5.003_97e     1997-Apr-15
     5.003_97f     1997-Apr-17
     5.003_97g     1997-Apr-18
     5.003_97h     1997-Apr-24
     5.003_97i     1997-Apr-25
     5.003_97j     1997-Apr-28
     5.003_98      1997-Apr-30
     5.003_99      1997-May-01
     5.003_99a     1997-May-09
     p54rc1        1997-May-12     Release Candidates.
     p54rc2        1997-May-14

     Chip    5.004          1997-May-15     A major maintenance release.

     Tim      5.004_01      1997-Jun-13     The 5.004 maintenance track.
              5.004_02      1997-Aug-07
              5.004_03      1997-Sep-05
              5.004_04      1997-Oct-15
              5.004m5t1     1998-Mar-04     Maintenance Trials (for 5.004_05).
              5.004_04-m2   1997-May-01
              5.004_04-m3   1998-May-15
              5.004_04-m4   1998-May-19
              5.004_04-MT5  1998-Jul-21
              5.004_04-MT6  1998-Oct-09
              5.004_04-MT7  1998-Nov-22
              5.004_04-MT8  1998-Dec-03
     Chip     5.004_04-MT9  1999-Apr-26
              5.004_05	1999-Apr-29

     Malcolm  5.004_50      1997-Sep-09     The 5.005 development track.
              5.004_51      1997-Oct-02
              5.004_52      1997-Oct-15
              5.004_53      1997-Oct-16
              5.004_54      1997-Nov-14
              5.004_55      1997-Nov-25
              5.004_56      1997-Dec-18
              5.004_57      1998-Feb-03
              5.004_58      1998-Feb-06
              5.004_59      1998-Feb-13
              5.004_60      1998-Feb-20
              5.004_61      1998-Feb-27
              5.004_62      1998-Mar-06
              5.004_63      1998-Mar-17
              5.004_64      1998-Apr-03
              5.004_65      1998-May-15
              5.004_66      1998-May-29
     Sarathy  5.004_67      1998-Jun-15
              5.004_68      1998-Jun-23
              5.004_69      1998-Jun-29
              5.004_70      1998-Jul-06
              5.004_71      1998-Jul-09
              5.004_72      1998-Jul-12
              5.004_73      1998-Jul-13
              5.004_74      1998-Jul-14     5.005 beta candidate.
              5.004_75      1998-Jul-15     5.005 beta1.
              5.004_76      1998-Jul-21     5.005 beta2.
              5.005         1998-Jul-22     Oneperl.

     Sarathy  5.005_01      1998-Jul-27     The 5.005 maintenance track.
              5.005_02-T1   1998-Aug-02
              5.005_02-T2   1998-Aug-05
              5.005_02      1998-Aug-08
     Graham   5.005_03-MT1  1998-Nov-30
              5.005_03-MT2  1999-Jan-04
              5.005_03-MT3  1999-Jan-17
              5.005_03-MT4  1999-Jan-26
              5.005_03-MT5  1999-Jan-28
              5.005_03      1999-Mar-28
     Chip     5.005_04	2000-***-**

     Sarathy  5.005_50      1998-Jul-26     The 5.6 development track.
              5.005_51      1998-Aug-10
              5.005_52      1998-Sep-25
              5.005_53      1998-Oct-31
              5.005_54      1998-Nov-30
              5.005_55      1999-Feb-16
              5.005_56      1999-Mar-01
              5.005_57      1999-May-25
     	  5.005_58	1999-Jul-27
     	  5.005_59	1999-Aug-02
     	  5.005_60	1999-Aug-02
     	  5.005_61	1999-Aug-20
     	  5.005_62	1999-Oct-15
     	  5.005_63	1999-Dec-09
     	  5.5.640	2000-Feb-02
     	  5.5.650	2000-Feb-08	beta1
     	  5.5.660	2000-Feb-22	beta2
     	  5.5.670	2000-Feb-29	beta3
     	  5.6.0-RC1	2000-Mar-09	release candidate 1
     	  5.6.0-RC2	2000-Mar-14	release candidate 2
     	  5.6.0-RC3	2000-Mar-21	release candidate 3
     	  5.6.0		2000-Mar-22

SELECTED RELEASE SIZES
----------------------

   For example the notation "core: 212  29" in the release 1.000 means that
it had in the core 212 kilobytes, in 29 files.  The "core".."doc" are
explained below.

     release        core       lib         ext        t         doc
     ======================================================================

     1.000           212  29      -   -      -   -     38  51     62   3
     1.014           219  29      -   -      -   -     39  52     68   4
     2.000           309  31      2   3      -   -     55  57     92   4
     2.001           312  31      2   3      -   -     55  57     94   4
     3.000           508  36     24  11      -   -     79  73    156   5
     3.044           645  37     61  20      -   -     90  74    190   6
     4.000           635  37     59  20      -   -     91  75    198   4
     4.019           680  37     85  29      -   -     98  76    199   4
     4.036           709  37     89  30      -   -     98  76    208   5
     5.000alpha2     785  50    114  32      -   -    112  86    209   5
     5.000alpha3     801  50    117  33      -   -    121  87    209   5
     5.000alpha9    1022  56    149  43    116  29    125  90    217   6
     5.000a12h       978  49    140  49    205  46    152  97    228   9
     5.000b3h       1035  53    232  70    216  38    162  94    218  21
     5.000          1038  53    250  76    216  38    154  92    536  62
     5.001m         1071  54    388  82    240  38    159  95    544  29
     5.002          1121  54    661 101    287  43    155  94    847  35
     5.003          1129  54    680 102    291  43    166 100    853  35
     5.003_07       1231  60    748 106    396  53    213 137    976  39
     5.004          1351  60   1230 136    408  51    355 161   1587  55
     5.004_01       1356  60   1258 138    410  51    358 161   1587  55
     5.004_04       1375  60   1294 139    413  51    394 162   1629  55
     5.004_05       1463  60   1435 150    394  50    445 175   1855  59
     5.004_51       1401  61   1260 140    413  53    358 162   1594  56
     5.004_53       1422  62   1295 141    438  70    394 162   1637  56
     5.004_56       1501  66   1301 140    447  74    408 165   1648  57
     5.004_59       1555  72   1317 142    448  74    424 171   1678  58
     5.004_62       1602  77   1327 144    629  92    428 173   1674  58
     5.004_65       1626  77   1358 146    615  92    446 179   1698  60
     5.004_68       1856  74   1382 152    619  92    463 187   1784  60
     5.004_70       1863  75   1456 154    675  92    494 194   1809  60
     5.004_73       1874  76   1467 152    762 102    506 196   1883  61
     5.004_75       1877  76   1467 152    770 103    508 196   1896  62
     5.005          1896  76   1469 152    795 103    509 197   1945  63
     5.005_03	1936  77   1541 153    813 104    551 201   2176  72
     5.005_50	1969  78   1842 301    795 103    514 198   1948  63
     5.005_53	1999  79   1885 303    806 104    602 224   2002  67
     5.005_56       2086  79   1970 307    866 113    672 238   2221  75

   The "core"..."doc" mean the following files from the Perl source code
distribution.  The glob notation ** means recursively, (.) means regular
files.

     core   *.[hcy]
     lib    lib/**/*.p[ml]
     ext    ext/**/*.{[hcyt],xs,pm}
     t      t/**/*(.)
     doc    {README*,INSTALL,*[_.]man{,.?},pod/**/*.pod}

   Here are some statistics for the other subdirectories and one file in
the Perl source distribution for somewhat more selected releases.

     ======================================================================
       Legend:  kB   #

     1.014   2.001   3.044   4.000   4.019   4.036

     atarist      -  -    -  -    -  -    -  -    -  -  113 31
     Configure   31  1   37  1   62  1   73  1   83  1   86  1
     eg           -  -   34 28   47 39   47 39   47 39   47 39
     emacs        -  -    -  -    -  -   67  4   67  4   67  4
     h2pl         -  -    -  -   12 12   12 12   12 12   12 12
     hints        -  -    -  -    -  -    -  -    5 42   11 56
     msdos        -  -    -  -   41 13   57 15   58 15   60 15
     os2          -  -    -  -   63 22   81 29   81 29  113 31
     usub         -  -    -  -   21 16   25  7   43  8   43  8
     x2p        103 17  104 17  137 17  147 18  152 19  154 19

     ======================================================================

     5.000a2 5.000a12h 5.000b3h 5.000  5.001m  5.002   5.003

     atarist    113 31  113 31    -  -      -  -    -  -    -  -    -  -
     bench        -  -    0  1    -  -      -  -    -  -    -  -    -  -
     Bugs         2  5   26  1    -  -      -  -    -  -    -  -    -  -
     dlperl      40  5    -  -    -  -      -  -    -  -    -  -    -  -
     do         127 71    -  -    -  -      -  -    -  -    -  -    -  -
     Configure    -  -  153  1  159  1    160  1  180  1  201  1  201  1
     Doc          -  -   26  1   75  7     11  1   11  1    -  -    -  -
     eg          79 58   53 44   51 43     54 44   54 44   54 44   54 44
     emacs       67  4  104  6  104  6    104  1  104  6  108  1  108  1
     h2pl        12 12   12 12   12 12     12 12   12 12   12 12   12 12
     hints       11 56   12 46   18 48     18 48   44 56   73 59   77 60
     msdos       60 15   60 15    -  -      -  -    -  -    -  -    -  -
     os2        113 31  113 31    -  -      -  -    -  -   84 17   56 10
     U            -  -   62  8  112 42      -  -    -  -    -  -    -  -
     usub        43  8    -  -    -  -      -  -    -  -    -  -    -  -
     utils        -  -    -  -    -  -      -  -    -  -   87  7   88  7
     vms          -  -   80  7  123  9    184 15  304 20  500 24  475 26
     x2p        171 22  171 21  162 20    162 20  279 20  280 20  280 20

     ======================================================================

     5.003_07 5.004   5.004_04 5.004_62 5.004_65 5.004_68

     beos         -  -     -  -    -  -     -  -     1   1    1   1
     Configure  217  1   225  1  225  1   240  1   248   1  256   1
     cygwin32     -  -    23  5   23  5    23  5    24   5   24   5
     djgpp        -  -     -  -    -  -    14  5    14   5   14   5
     eg          54 44    81 62   81 62    81 62    81  62   81  62
     emacs      143  1   194  1  204  1   212  2   212   2  212   2
     h2pl        12 12    12 12   12 12    12 12    12  12   12  12
     hints       90 62   129 69  132 71   144 72   151  74  155  74
     os2        117 42   121 42  127 42   127 44   129  44  129  44
     plan9       79 15    82 15   82 15    82 15    82  15   82  15
     Porting     51  1    94  2  109  4   203  6   234   8  241   9
     qnx          -  -     1  2    1  2     1  2     1   2    1   2
     utils       97  7   112  8  118  8   124  8   156   9  159   9
     vms        505 27   518 34  524 34   538 34   569  34  569  34
     win32        -  -   285 33  378 36   470 39   493  39  575  41
     x2p        280 19   281 19  281 19   281 19   282  19  281  19

     ======================================================================

     5.004_70 5.004_73 5.004_75  5.005  5.005_03

     apollo       -   -    -   -    -   -    -   -    0   1
     beos         1   1    1   1    1   1    1   1    1   1
     Configure  256   1  256   1  264   1  264   1  270   1
     cygwin32    24   5   24   5   24   5   24   5   24   5
     djgpp       14   5   14   5   14   5   14   5	 15   5
     eg          86  65   86  65   86  65   86  65	 86  65
     emacs      262   2  262   2  262   2  262   2	274   2
     h2pl        12  12   12  12   12  12   12  12	 12  12
     hints      157  74  157  74  159  74  160  74	179  77
     mint         -   -    -   -    -   -    -   -	  4   7
     mpeix        -   -    -   -    5   3    5   3	  5   3
     os2        129  44  139  44  142  44  143  44	148  44
     plan9       82  15   82  15   82  15   82  15	 82  15
     Porting    241   9  253   9  259  10  264  12	272  13
     qnx          1   2    1   2    1   2    1   2	  1   2
     utils      160   9  160   9  160   9  160   9	164   9
     vms        570  34  572  34  573  34  575  34	583  34
     vos          -   -    -   -    -   -    -   -	156  10
     win32      577  41  585  41  585  41  587  41	600  42
     x2p        281  19  281  19  281  19  281  19	281  19

SELECTED PATCH SIZES
--------------------

   The "diff lines kb" means that for example the patch 5.003_08, to be
applied on top of the 5.003_07 (or whatever was before the 5.003_08) added
lines for 110 kilobytes, it removed lines for 19 kilobytes, and changed
lines for 424 kilobytes.  Just the lines themselves are counted, not their
context.  The "+ - !" become from the diff(1) context diff output format.

     Pump-  Release         Date           diff lines kB
     king                                  -------------
                                              +   -   !
     ===========================================================================

     Chip     5.003_08      1996-Nov-19     110  19 424
              5.003_09      1996-Nov-26      38   9 248
              5.003_10      1996-Nov-29      29   2  27
              5.003_11      1996-Dec-06      73  12 165
              5.003_12      1996-Dec-19     275   6 436
              5.003_13      1996-Dec-20      95   1  56
              5.003_14      1996-Dec-23      23   7 333
              5.003_15      1996-Dec-23       0   0   1
              5.003_16      1996-Dec-24      12   3  50
              5.003_17      1996-Dec-27      19   1  14
              5.003_18      1996-Dec-31      21   1  32
              5.003_19      1997-Jan-04      80   3  85
              5.003_20      1997-Jan-07      18   1 146
              5.003_21      1997-Jan-15      38  10 221
              5.003_22      1997-Jan-16       4   0  18
              5.003_23      1997-Jan-25      71  15 119
              5.003_24      1997-Jan-29     426   1  20
              5.003_25      1997-Feb-04      21   8 169
              5.003_26      1997-Feb-10      16   1  15
              5.003_27      1997-Feb-18      32  10  38
              5.003_28      1997-Feb-21      58   4  66
              5.003_90      1997-Feb-25      22   2  34
              5.003_91      1997-Mar-01      37   1  39
              5.003_92      1997-Mar-06      16   3  69
              5.003_93      1997-Mar-10      12   3  15
              5.003_94      1997-Mar-22     407   7 200
              5.003_95      1997-Mar-25      41   1  37
              5.003_96      1997-Apr-01     283   5 261
              5.003_97      1997-Apr-03      13   2  34
              5.003_97a     1997-Apr-05      57   1  27
              5.003_97b     1997-Apr-08      14   1  20
              5.003_97c     1997-Apr-10      20   1  16
              5.003_97d     1997-Apr-13       8   0  16
              5.003_97e     1997-Apr-15      15   4  46
              5.003_97f     1997-Apr-17       7   1  33
              5.003_97g     1997-Apr-18       6   1  42
              5.003_97h     1997-Apr-24      23   3  68
              5.003_97i     1997-Apr-25      23   1  31
              5.003_97j     1997-Apr-28      36   1  49
              5.003_98      1997-Apr-30     171  12 539
              5.003_99      1997-May-01       6   0   7
              5.003_99a     1997-May-09      36   2  61
              p54rc1        1997-May-12       8   1  11
              p54rc2        1997-May-14       6   0  40

     5.004           1997-May-15       4   0   4

     Tim      5.004_01      1997-Jun-13     222  14  57
              5.004_02      1997-Aug-07     112  16 119
              5.004_03      1997-Sep-05     109   0  17
              5.004_04      1997-Oct-15      66   8 173

THE KEEPERS OF THE RECORDS
==========================

   Jarkko Hietaniemi <`jhi@iki.fi'>.

   Thanks to the collective memory of the Perlfolk.  In addition to the
Keepers of the Pumpkin also Alan Champion, Andreas Knig, John Macdonald,
Matthias Neeracher, Jeff Okamoto, Michael Peppler, Randal Schwartz, and
Paul D. Smith sent corrections and additions.


File: perl.info,  Node: perlhpux,  Next: perlmachten,  Prev: perldos,  Up: Top

Perl version 5 on Hewlett-Packard Unix (HP-UX) systems
******************************************************

NAME
====

   README.hpux - Perl version 5 on Hewlett-Packard Unix (HP-UX) systems

DESCRIPTION
===========

   This document describes various features of HP's Unix operating system
(HP-UX) that will affect how Perl version 5 (hereafter just Perl) is
compiled and/or runs.

Compiling Perl 5 on HP-UX
-------------------------

   When compiling Perl, the use of an ANSI C compiler is highly
recommended.  The C compiler that ships with all HP-UX systems is a K&R
compiler that should only be used to build new kernels.

   Perl can be compiled with either HP's ANSI C compiler or with gcc.  The
former is recommended, as not only can it compile Perl with no difficulty,
but also can take advantage of features listed later that require the use
of HP compiler-specific command-line flags.

   If you decide to use gcc, make sure your installation is recent and
complete, and be sure to read the Perl README file for more gcc-specific
details.

PA-RISC
-------

   HP's current Unix systems run on its own Precision Architecture
(PA-RISC) chip.  HP-UX used to run on the Motorola MC68000 family of
chips, but any machine with this chip in it is quite obsolete and this
document will not attempt to address issues for compiling Perl on the
Motorola chipset.

   The most recent version of PA-RISC at the time of this document's last
update is 2.0.

PA-RISC 1.0
-----------

   The original version of PA-RISC, HP no longer sells any system with
this chip.

   The following systems contain PA-RISC 1.0 chips:

     600, 635, 645, 800, 808, 815, 822, 825, 832, 834, 835, 840,
     842, 845, 850, 852, 855, 860, 865, 870, 890

PA-RISC 1.1
-----------

   An upgrade to the PA-RISC design, it shipped for many years in many
different system.

   The following systems contain with PA-RISC 1.1 chips:

     705, 710, 712, 715, 720, 722, 725, 728, 730, 735, 743, 745, 747, 750,
     755, 770, 807S, 817S, 827S, 837S, 847S, 857S, 867S, 877S, 887S, 897S,
     D200, D210, D220, D230, D250, D260, D310, D320, D330, D350, D360, D400,
     E25, E35, E45, E55, F10, F20, F30, G30, G40, G50, G60, G70, H30, H40,
     H50, H60, H70, I30, I40, I50, I60, I70, K100, K200, K210, K220, K400,
     K410, K420, T500, T520

PA-RISC 2.0
-----------

   The most recent upgrade to the PA-RISC design, it added support for
64-bit integer data.

   The following systems contain PA-RISC 2.0 chips (this is very likely to
be out of date):

     D270, D280, D370, D380, K250, K260, K370, K380, K450, K460, K570, K580,
     T600, V2200

   A complete list of models at the time the OS was built is in the file
/opt/langtools/lib/sched.models.  The first column corresponds to the
output of the "uname -m" command (without the leading "9000/").  The
second column is the PA-RISC version and the third column is the exact
chip type used.

Portability Between PA-RISC Versions
------------------------------------

   An executable compiled on a PA-RISC 2.0 platform will not execute on a
PA-RISC 1.1 platform, even if they are running the same version of HP-UX.
If you are building Perl on a PA-RISC 2.0 platform and want that Perl to
to also run on a PA-RISC 1.1, the compiler flags +DAportable and +DS32
should be used.

   It is no longer possible to compile PA-RISC 1.0 executables on either
the PA-RISC 1.1 or 2.0 platforms.

Building Dynamic Extensions on HP-UX
------------------------------------

   HP-UX supports dynamically loadable libraries (shared libraries).
Shared libraries end with the suffix .sl.

   Shared libraries created on a platform using a particular PA-RISC
version are not usable on platforms using an earlier PA-RISC version by
default.  However, this backwards compatibility may be enabled using the
same +DAportable compiler flag (with the same PA-RISC 1.0 caveat mentioned
above).

   To create a shared library, the following steps must be performed:

     1. Compile source modules with +z or +Z flag to create a .o module
        which contains Position-Independent Code (PIC).  The linker will
        tell you in the next step if +Z was needed.

     2. Link the shared library using the -b flag.  If the code calls
        any functions in other system libraries (e.g., libm), it must
        be included on this line.

   (Note that these steps are usually handled automatically by the
extension's Makefile).

   If these dependent libraries are not listed at shared library creation
time, you will get fatal "Unresolved symbol" errors at run time when the
library is loaded.

   You may create a shared library that referers to another library, which
may be either an archive library or a shared library.  If it is a shared
library, this is called a "dependent library".  The dependent library's
name is recorded in the main shared library, but it is not linked into the
shared library.  Instead, it is loaded when the main shared library is
loaded.

   If the referred library is an archive library, then it is treated as a
simple collection of .o modules (all of which must contain PIC).  These
modules are then linked into the shared library.

   Note that it is okay to create a library which contains a dependent
library that is already linked into perl.

   It is no longer possible to link PA-RISC 1.0 shared libraries.

The HP ANSI C Compiler
----------------------

   When using this compiler to build Perl, you should make sure that the
flag -Aa is added to the cpprun and cppstdin variables in the config.sh
file.

Using Large Files with Perl
---------------------------

   Beginning with HP-UX version 10.20, files larger than 2GB (2^31) may be
created and manipulated.  Three separate methods of doing this are
available.  Of these methods, the best method for Perl is to compile using
the -D_FILE_OFFSET_BITS=64 compiler flag.  This causes Perl to be compiled
using structures and functions in which these are 64 bits wide, rather
than 32 bits wide.

   There are only two drawbacks to this approach: the first is that the
seek and tell functions (both the builtin version and the POSIX module's
version) will not correctly function for these large files (the offset
arguments in seek and tell are implemented as type long).  The second is
that any extension which calls any file-manipulating C function will need
to be recompiled using the above-mentioned -D_FILE_OFFSET_BITS=64 flag.
The list of functions that will need to recompiled is:
creat,		fgetpos,	fopen, freopen,	fsetpos,	fstat,
fstatvfs,	fstatvfsdev,	ftruncate, ftw,		lockf,		lseek,
lstat,		mmap,		nftw, open,		prealloc,	stat,
statvfs,	statvfsdev,	tmpfile,
truncate,	getrlimit,	setrlimit

Threaded Perl
-------------

   It is impossible to compile a version of threaded Perl on any version of
HP-UX before 10.30, and it is strongly suggested that you be running on
HP-UX 11.00 at least.

   To compile Perl with thread, add -Dusethreads to the arguments of
Configure.  Ensure that the -D_POSIX_C_SOURCE=199506L compiler flag is
automatically added to the list of flags.  Also make sure that -lpthread
is listed before -lc in the list of libraries to link Perl with.

   As of the date of this document, Perl threads are not fully supported
on HP-UX.

64-bit Perl
-----------

   Beginning with HP-UX 11.00, programs compiled under HP-UX can take
advantage of the LP64 programming environment (LP64 means Longs and
Pointers are 64 bits wide).

   Work is being performed on Perl to make it 64-bit compliant on all
versions of Unix.  Once this is complete, scalar variables will be able to
hold numbers larger than 2^32 with complete precision.

   As of the date of this document, Perl is not 64-bit compliant on HP-UX.

   Should a user wish to experiment with compiling Perl in the LP64
environment, the following steps must be taken: libraries must be searched
only within /lib/pa20_64, the compiler flag +DD64 must be used, and the C
library is now located at /lib/pa20_64/libc.sl.

   On the brighter side, the large file problem goes away, as longs are now
64 bits wide.

GDBM and Threads
----------------

   If you attempt to compile Perl with threads on an 11.X system and also
link in the GDBM library, then Perl will immediately core dump when it
starts up.  The only workaround at this point is to relink the GDBM
library under 11.X, then relink it into Perl.

NFS filesystems and utime(2)
----------------------------

   If you are compiling Perl on a remotely-mounted NFS filesystem, the test
io/fs.t may fail on test #18.  This appears to be a bug in HP-UX and no
fix is currently available.

AUTHOR
======

   Jeff Okamoto <okamoto@corp.hp.com>

   With much assistance regarding shared libraries from Marc Sabatella.

DATE
====

   Version 0.2: 1999/03/01


File: perl.info,  Node: perlintern,  Next: perltodo,  Prev: perlapi,  Up: Top

autogenerated documentation of purely internal  		 Perl functions
*****************************************************************

NAME
====

   perlintern - autogenerated documentation of purely internal
Perl functions

DESCRIPTION
===========

   This file is the autogenerated documentation of functions in the Perl
intrepreter that are documented using Perl's internal documentation format
but are not marked as part of the Perl API. In other words, *they are not
for use in extensions*!

AUTHORS
=======

   The autodocumentation system was orignally added to the Perl core by
Benjamin Stuhl. Documentation is by whoever was kind enough to document
their functions.

SEE ALSO
========

   perlguts(1), perlapi(1)


File: perl.info,  Node: perlipc,  Next: perlfork,  Prev: perlbot,  Up: Top

Perl interprocess communication (signals, fifos, pipes, safe subprocesses, sockets, and semaphores)
***************************************************************************************************

NAME
====

   perlipc - Perl interprocess communication (signals, fifos, pipes, safe
subprocesses, sockets, and semaphores)

DESCRIPTION
===========

   The basic IPC facilities of Perl are built out of the good old Unix
signals, named pipes, pipe opens, the Berkeley socket routines, and SysV
IPC calls.  Each is used in slightly different situations.

Signals
=======

   Perl uses a simple signal handling model: the %SIG hash contains names
or references of user-installed signal handlers.  These handlers will be
called with an argument which is the name of the signal that triggered it.
A signal may be generated intentionally from a particular keyboard
sequence like control-C or control-Z, sent to you from another process, or
triggered automatically by the kernel when special events transpire, like
a child process exiting, your process running out of stack space, or
hitting file size limit.

   For example, to trap an interrupt signal, set up a handler like this.
Do as little as you possibly can in your handler; notice how all we do is
set a global variable and then raise an exception.  That's because on most
systems, libraries are not re-entrant; particularly, memory allocation and
I/O routines are not.  That means that doing nearly anything in your
handler could in theory trigger a memory fault and subsequent core dump.

     sub catch_zap {
     	my $signame = shift;
     	$shucks++;
     	die "Somebody sent me a SIG$signame";
     }
     $SIG{INT} = 'catch_zap';  # could fail in modules
     $SIG{INT} = \&catch_zap;  # best strategy

   The names of the signals are the ones listed out by `kill -l' on your
system, or you can retrieve them from the Config module.  Set up an
@signame list indexed by number to get the name and a %signo table indexed
by name to get the number:

     use Config;
     defined $Config{sig_name} || die "No sigs?";
     foreach $name (split(' ', $Config{sig_name})) {
     	$signo{$name} = $i;
     	$signame[$i] = $name;
     	$i++;
     }

   So to check whether signal 17 and SIGALRM were the same, do just this:

     print "signal #17 = $signame[17]\n";
     if ($signo{ALRM}) {
     	print "SIGALRM is $signo{ALRM}\n";
     }

   You may also choose to assign the strings `'IGNORE'' or `'DEFAULT'' as
the handler, in which case Perl will try to discard the signal or do the
default thing.

   On most Unix platforms, the `CHLD' (sometimes also known as `CLD')
signal has special behavior with respect to a value of `'IGNORE''.
Setting `$SIG{CHLD}' to `'IGNORE'' on such a platform has the effect of
not creating zombie processes when the parent process fails to wait() on
its child processes (i.e. child processes are automatically reaped).
Calling wait() with `$SIG{CHLD}' set to `'IGNORE'' usually returns `-1' on
such platforms.

   Some signals can be neither trapped nor ignored, such as the KILL and
STOP (but not the TSTP) signals.  One strategy for temporarily ignoring
signals is to use a local() statement, which will be automatically
restored once your block is exited.  (Remember that local() values are
"inherited" by functions called from within that block.)

     sub precious {
     	local $SIG{INT} = 'IGNORE';
     	&more_functions;
     }
     sub more_functions {
     	# interrupts still ignored, for now...
     }

   Sending a signal to a negative process ID means that you send the signal
to the entire Unix process-group.  This code sends a hang-up signal to all
processes in the current process group (and sets $SIG{HUP} to IGNORE so it
doesn't kill itself):

     {
     	local $SIG{HUP} = 'IGNORE';
     	kill HUP => -$$;
     	# snazzy writing of: kill('HUP', -$$)
     }

   Another interesting signal to send is signal number zero.  This doesn't
actually affect another process, but instead checks whether it's alive or
has changed its UID.

     unless (kill 0 => $kid_pid) {
     	warn "something wicked happened to $kid_pid";
     }

   You might also want to employ anonymous functions for simple signal
handlers:

     $SIG{INT} = sub { die "\nOutta here!\n" };

   But that will be problematic for the more complicated handlers that need
to reinstall themselves.  Because Perl's signal mechanism is currently
based on the signal(3) function from the C library, you may sometimes be so
misfortunate as to run on systems where that function is "broken", that
is, it behaves in the old unreliable SysV way rather than the newer, more
reasonable BSD and POSIX fashion.  So you'll see defensive people writing
signal handlers like this:

     sub REAPER {
     	$waitedpid = wait;
     	# loathe sysV: it makes us not only reinstate
     	# the handler, but place it after the wait
     	$SIG{CHLD} = \&REAPER;
     }
     $SIG{CHLD} = \&REAPER;
     # now do something that forks...

   or even the more elaborate:

     use POSIX ":sys_wait_h";
     sub REAPER {
     	my $child;
         while (($child = waitpid(-1,WNOHANG)) > 0) {
     	    $Kid_Status{$child} = $?;
     	}
     	$SIG{CHLD} = \&REAPER;  # still loathe sysV
     }
     $SIG{CHLD} = \&REAPER;
     # do something that forks...

   Signal handling is also used for timeouts in Unix,   While safely
protected within an `eval{}' block, you set a signal handler to trap alarm
signals and then schedule to have one delivered to you in some number of
seconds.  Then try your blocking operation, clearing the alarm when it's
done but not before you've exited your `eval{}' block.  If it goes off,
you'll use die() to jump out of the block, much as you might using
longjmp() or throw() in other languages.

   Here's an example:

     eval {
         local $SIG{ALRM} = sub { die "alarm clock restart" };
         alarm 10;
         flock(FH, 2);   # blocking write lock
         alarm 0;
     };
     if ($@ and $@ !~ /alarm clock restart/) { die }

   If the operation being timed out is system() or qx(), this technique is
liable to generate zombies.    If this matters to you, you'll need to do
your own fork() and exec(), and kill the errant child process.

   For more complex signal handling, you might see the standard POSIX
module.  Lamentably, this is almost entirely undocumented, but the
`t/lib/posix.t' file from the Perl source distribution has some examples
in it.

Named Pipes
===========

   A named pipe (often referred to as a FIFO) is an old Unix IPC mechanism
for processes communicating on the same machine.  It works just like a
regular, connected anonymous pipes, except that the processes rendezvous
using a filename and don't have to be related.

   To create a named pipe, use the Unix command mknod(1) or on some
systems, mkfifo(1).  These may not be in your normal path.

     # system return val is backwards, so && not ||
     #
     $ENV{PATH} .= ":/etc:/usr/etc";
     if  (      system('mknod',  $path, 'p')
     	    && system('mkfifo', $path) )
     {
     	die "mk{nod,fifo} $path failed";
     }

   A fifo is convenient when you want to connect a process to an unrelated
one.  When you open a fifo, the program will block until there's something
on the other end.

   For example, let's say you'd like to have your `.signature' file be a
named pipe that has a Perl program on the other end.  Now every time any
program (like a mailer, news reader, finger program, etc.) tries to read
from that file, the reading program will block and your program will
supply the new signature.  We'll use the pipe-checking file test -p to
find out whether anyone (or anything) has accidentally removed our fifo.

     chdir; # go home
     $FIFO = '.signature';
     $ENV{PATH} .= ":/etc:/usr/games";

     while (1) {
     	unless (-p $FIFO) {
     	    unlink $FIFO;
     	    system('mknod', $FIFO, 'p')
     		&& die "can't mknod $FIFO: $!";
     	}

     # next line blocks until there's a reader
     open (FIFO, "> $FIFO") || die "can't write $FIFO: $!";
     print FIFO "John Smith (smith\@host.org)\n", `fortune -s`;
     close FIFO;
     sleep 2;    # to avoid dup signals
         }

WARNING
-------

   By installing Perl code to deal with signals, you're exposing yourself
to danger from two things.  First, few system library functions are
re-entrant.  If the signal interrupts while Perl is executing one function
(like malloc(3) or printf(3)), and your signal handler then calls the same
function again, you could get unpredictable behavior-often, a core dump.
Second, Perl isn't itself re-entrant at the lowest levels.  If the signal
interrupts Perl while Perl is changing its own internal data structures,
similarly unpredictable behaviour may result.

   There are two things you can do, knowing this: be paranoid or be
pragmatic.  The paranoid approach is to do as little as possible in your
signal handler.  Set an existing integer variable that already has a
value, and return.  This doesn't help you if you're in a slow system call,
which will just restart.  That means you have to die to longjump(3) out of
the handler.  Even this is a little cavalier for the true paranoiac, who
avoids die in a handler because the system *is* out to get you.  The
pragmatic approach is to say "I know the risks, but prefer the
convenience", and to do anything you want in your signal handler, prepared
to clean up core dumps now and again.

   To forbid signal handlers altogether would bars you from many
interesting programs, including virtually everything in this manpage,
since you could no longer even write SIGCHLD handlers.  Their dodginess is
expected to be addresses in the 5.005 release.

Using open() for IPC
====================

   Perl's basic open() statement can also be used for unidirectional
interprocess communication by either appending or prepending a pipe symbol
to the second argument to open().  Here's how to start something up in a
child process you intend to write to:

     open(SPOOLER, "| cat -v | lpr -h 2>/dev/null")
     		    || die "can't fork: $!";
     local $SIG{PIPE} = sub { die "spooler pipe broke" };
     print SPOOLER "stuff\n";
     close SPOOLER || die "bad spool: $! $?";

   And here's how to start up a child process you intend to read from:

     open(STATUS, "netstat -an 2>&1 |")
     		    || die "can't fork: $!";
     while (<STATUS>) {
     	next if /^(tcp|udp)/;
     	print;
     }
     close STATUS || die "bad netstat: $! $?";

   If one can be sure that a particular program is a Perl script that is
expecting filenames in @ARGV, the clever programmer can write something
like this:

     % program f1 "cmd1|" - f2 "cmd2|" f3 < tmpfile

   and irrespective of which shell it's called from, the Perl program will
read from the file `f1', the process `cmd1', standard input (tmpfile in
this case), the `f2' file, the `cmd2' command, and finally the `f3' file.
Pretty nifty, eh?

   You might notice that you could use backticks for much the same effect
as opening a pipe for reading:

     print grep { !/^(tcp|udp)/ } `netstat -an 2>&1`;
     die "bad netstat" if $?;

   While this is true on the surface, it's much more efficient to process
the file one line or record at a time because then you don't have to read
the whole thing into memory at once.  It also gives you finer control of
the whole process, letting you to kill off the child process early if you'd
like.

   Be careful to check both the open() and the close() return values.  If
you're *writing* to a pipe, you should also trap SIGPIPE.  Otherwise,
think of what happens when you start up a pipe to a command that doesn't
exist: the open() will in all likelihood succeed (it only reflects the
fork()'s success), but then your output will fail-spectacularly.  Perl
can't know whether the command worked because your command is actually
running in a separate process whose exec() might have failed.  Therefore,
while readers of bogus commands return just a quick end of file, writers
to bogus command will trigger a signal they'd better be prepared to
handle.  Consider:

     open(FH, "|bogus")	or die "can't fork: $!";
     print FH "bang\n"	or die "can't write: $!";
     close FH		or die "can't close: $!";

   That won't blow up until the close, and it will blow up with a SIGPIPE.
To catch it, you could use this:

     $SIG{PIPE} = 'IGNORE';
     open(FH, "|bogus")  or die "can't fork: $!";
     print FH "bang\n"   or die "can't write: $!";
     close FH            or die "can't close: status=$?";

Filehandles
-----------

   Both the main process and any child processes it forks share the same
STDIN, STDOUT, and STDERR filehandles.  If both processes try to access
them at once, strange things can happen.  You may also want to close or
reopen the filehandles for the child.  You can get around this by opening
your pipe with open(), but on some systems this means that the child
process cannot outlive the parent.

Background Processes
--------------------

   You can run a command in the background with:

     system("cmd &");

   The command's STDOUT and STDERR (and possibly STDIN, depending on your
shell) will be the same as the parent's.  You won't need to catch SIGCHLD
because of the double-fork taking place (see below for more details).

Complete Dissociation of Child from Parent
------------------------------------------

   In some cases (starting server processes, for instance) you'll want to
completely dissociate the child process from the parent.  This is often
called daemonization.  A well behaved daemon will also chdir() to the root
directory (so it doesn't prevent unmounting the filesystem containing the
directory from which it was launched) and redirect its standard file
descriptors from and to `/dev/null' (so that random output doesn't wind up
on the user's terminal).

     use POSIX 'setsid';

     sub daemonize {
     	chdir '/'		or die "Can't chdir to /: $!";
     	open STDIN, '/dev/null' or die "Can't read /dev/null: $!";
     	open STDOUT, '>/dev/null'
     				or die "Can't write to /dev/null: $!";
     	defined(my $pid = fork)	or die "Can't fork: $!";
     	exit if $pid;
     	setsid			or die "Can't start a new session: $!";
     	open STDERR, '>&STDOUT'	or die "Can't dup stdout: $!";
     }

   The fork() has to come before the setsid() to ensure that you aren't a
process group leader (the setsid() will fail if you are).  If your system
doesn't have the setsid() function, open `/dev/tty' and use the
`TIOCNOTTY' ioctl() on it instead.  See `tty(4)' in this node for details.

   Non-Unix users should check their Your_OS::Process module for other
solutions.

Safe Pipe Opens
---------------

   Another interesting approach to IPC is making your single program go
multiprocess and communicate between (or even amongst) yourselves.  The
open() function will accept a file argument of either `"-|"' or `"|-"' to
do a very interesting thing: it forks a child connected to the filehandle
you've opened.  The child is running the same program as the parent.  This
is useful for safely opening a file when running under an assumed UID or
GID, for example.  If you open a pipe to minus, you can write to the
filehandle you opened and your kid will find it in his STDIN.  If you open
a pipe from minus, you can read from the filehandle you opened whatever
your kid writes to his STDOUT.

     use English;
     my $sleep_count = 0;

     do {
     	$pid = open(KID_TO_WRITE, "|-");
     	unless (defined $pid) {
     	    warn "cannot fork: $!";
     	    die "bailing out" if $sleep_count++ > 6;
     	    sleep 10;
     	}
     } until defined $pid;

     if ($pid) {  # parent
     	print KID_TO_WRITE @some_data;
     	close(KID_TO_WRITE) || warn "kid exited $?";
     } else {     # child
     	($EUID, $EGID) = ($UID, $GID); # suid progs only
     	open (FILE, "> /safe/file")
     	    || die "can't open /safe/file: $!";
     	while (<STDIN>) {
     	    print FILE; # child's STDIN is parent's KID
     	}
     	exit;  # don't forget this
     }

   Another common use for this construct is when you need to execute
something without the shell's interference.  With system(), it's
straightforward, but you can't use a pipe open or backticks safely.
That's because there's no way to stop the shell from getting its hands on
your arguments.   Instead, use lower-level control to call exec() directly.

   Here's a safe backtick or pipe open for read:

     # add error processing as above
     $pid = open(KID_TO_READ, "-|");

     if ($pid) {   # parent
     	while (<KID_TO_READ>) {
     	    # do something interesting
     	}
     	close(KID_TO_READ) || warn "kid exited $?";

     } else {      # child
     	($EUID, $EGID) = ($UID, $GID); # suid only
     	exec($program, @options, @args)
     	    || die "can't exec program: $!";
     	# NOTREACHED
     }

   And here's a safe pipe open for writing:

     # add error processing as above
     $pid = open(KID_TO_WRITE, "|-");
     $SIG{ALRM} = sub { die "whoops, $program pipe broke" };

     if ($pid) {  # parent
     	for (@data) {
     	    print KID_TO_WRITE;
     	}
     	close(KID_TO_WRITE) || warn "kid exited $?";

     } else {     # child
     	($EUID, $EGID) = ($UID, $GID);
     	exec($program, @options, @args)
     	    || die "can't exec program: $!";
     	# NOTREACHED
     }

   Note that these operations are full Unix forks, which means they may
not be correctly implemented on alien systems.  Additionally, these are
not true multithreading.  If you'd like to learn more about threading, see
the modules file mentioned below in the SEE ALSO section.

Bidirectional Communication with Another Process
------------------------------------------------

   While this works reasonably well for unidirectional communication, what
about bidirectional communication?  The obvious thing you'd like to do
doesn't actually work:

     open(PROG_FOR_READING_AND_WRITING, "| some program |")

   and if you forget to use the `use warnings' pragma or the -w flag, then
you'll miss out entirely on the diagnostic message:

     Can't do bidirectional pipe at -e line 1.

   If you really want to, you can use the standard open2() library function
to catch both ends.  There's also an open3() for tridirectional I/O so you
can also catch your child's STDERR, but doing so would then require an
awkward select() loop and wouldn't allow you to use normal Perl input
operations.

   If you look at its source, you'll see that open2() uses low-level
primitives like Unix pipe() and exec() calls to create all the connections.
While it might have been slightly more efficient by using socketpair(), it
would have then been even less portable than it already is.  The open2()
and open3() functions are  unlikely to work anywhere except on a Unix
system or some other one purporting to be POSIX compliant.

   Here's an example of using open2():

     use FileHandle;
     use IPC::Open2;
     $pid = open2(*Reader, *Writer, "cat -u -n" );
     print Writer "stuff\n";
     $got = <Reader>;

   The problem with this is that Unix buffering is really going to ruin
your day.  Even though your `Writer' filehandle is auto-flushed, and the
process on the other end will get your data in a timely manner, you can't
usually do anything to force it to give it back to you in a similarly
quick fashion.  In this case, we could, because we gave cat a -u flag to
make it unbuffered.  But very few Unix commands are designed to operate
over pipes, so this seldom works unless you yourself wrote the program on
the other end of the double-ended pipe.

   A solution to this is the nonstandard `Comm.pl' library.  It uses
pseudo-ttys to make your program behave more reasonably:

     require 'Comm.pl';
     $ph = open_proc('cat -n');
     for (1..10) {
     	print $ph "a line\n";
     	print "got back ", scalar <$ph>;
     }

   This way you don't have to have control over the source code of the
program you're using.  The `Comm' library also has expect() and interact()
functions.  Find the library (and we hope its successor `IPC::Chat') at
your nearest CPAN archive as detailed in the SEE ALSO section below.

   The newer Expect.pm module from CPAN also addresses this kind of thing.
This module requires two other modules from CPAN: IO::Pty and IO::Stty.
It sets up a pseudo-terminal to interact with programs that insist on
using talking to the terminal device driver.  If your system is amongst
those supported, this may be your best bet.

Bidirectional Communication with Yourself
-----------------------------------------

   If you want, you may make low-level pipe() and fork() to stitch this
together by hand.  This example only talks to itself, but you could reopen
the appropriate handles to STDIN and STDOUT and call other processes.

     #!/usr/bin/perl -w
     # pipe1 - bidirectional communication using two pipe pairs
     #         designed for the socketpair-challenged
     use IO::Handle;	# thousands of lines just for autoflush :-(
     pipe(PARENT_RDR, CHILD_WTR);		# XXX: failure?
     pipe(CHILD_RDR,  PARENT_WTR);		# XXX: failure?
     CHILD_WTR->autoflush(1);
     PARENT_WTR->autoflush(1);

     if ($pid = fork) {
     	close PARENT_RDR; close PARENT_WTR;
     	print CHILD_WTR "Parent Pid $$ is sending this\n";
     	chomp($line = <CHILD_RDR>);
     	print "Parent Pid $$ just read this: `$line'\n";
     	close CHILD_RDR; close CHILD_WTR;
     	waitpid($pid,0);
     } else {
     	die "cannot fork: $!" unless defined $pid;
     	close CHILD_RDR; close CHILD_WTR;
     	chomp($line = <PARENT_RDR>);
     	print "Child Pid $$ just read this: `$line'\n";
     	print PARENT_WTR "Child Pid $$ is sending this\n";
     	close PARENT_RDR; close PARENT_WTR;
     	exit;
     }

   But you don't actually have to make two pipe calls.  If you have the
socketpair() system call, it will do this all for you.

     #!/usr/bin/perl -w
     # pipe2 - bidirectional communication using socketpair
     #   "the best ones always go both ways"

     use Socket;
     use IO::Handle;	# thousands of lines just for autoflush :-(
     # We say AF_UNIX because although *_LOCAL is the
     # POSIX 1003.1g form of the constant, many machines
     # still don't have it.
     socketpair(CHILD, PARENT, AF_UNIX, SOCK_STREAM, PF_UNSPEC)
     				or  die "socketpair: $!";

     CHILD->autoflush(1);
     PARENT->autoflush(1);

     if ($pid = fork) {
     	close PARENT;
     	print CHILD "Parent Pid $$ is sending this\n";
     	chomp($line = <CHILD>);
     	print "Parent Pid $$ just read this: `$line'\n";
     	close CHILD;
     	waitpid($pid,0);
     } else {
     	die "cannot fork: $!" unless defined $pid;
     	close CHILD;
     	chomp($line = <PARENT>);
     	print "Child Pid $$ just read this: `$line'\n";
     	print PARENT "Child Pid $$ is sending this\n";
     	close PARENT;
     	exit;
     }

Sockets: Client/Server Communication
====================================

   While not limited to Unix-derived operating systems (e.g., WinSock on
PCs provides socket support, as do some VMS libraries), you may not have
sockets on your system, in which case this section probably isn't going to
do you much good.  With sockets, you can do both virtual circuits (i.e.,
TCP streams) and datagrams (i.e., UDP packets).  You may be able to do
even more depending on your system.

   The Perl function calls for dealing with sockets have the same names as
the corresponding system calls in C, but their arguments tend to differ
for two reasons: first, Perl filehandles work differently than C file
descriptors.  Second, Perl already knows the length of its strings, so you
don't need to pass that information.

   One of the major problems with old socket code in Perl was that it used
hard-coded values for some of the constants, which severely hurt
portability.  If you ever see code that does anything like explicitly
setting `$AF_INET = 2', you know you're in for big trouble:  An
immeasurably superior approach is to use the Socket module, which more
reliably grants access to various constants and functions you'll need.

   If you're not writing a server/client for an existing protocol like
NNTP or SMTP, you should give some thought to how your server will know
when the client has finished talking, and vice-versa.  Most protocols are
based on one-line messages and responses (so one party knows the other has
finished when a "\n" is received) or multi-line messages and responses
that end with a period on an empty line ("\n.\n" terminates a
message/response).

Internet Line Terminators
-------------------------

   The Internet line terminator is "\015\012".  Under ASCII variants of
Unix, that could usually be written as "\r\n", but under other systems,
"\r\n" might at times be "\015\015\012", "\012\012\015", or something
completely different.  The standards specify writing "\015\012" to be
conformant (be strict in what you provide), but they also recommend
accepting a lone "\012" on input (but be lenient in what you require).  We
haven't always been very good about that in the code in this manpage, but
unless you're on a Mac, you'll probably be ok.

Internet TCP Clients and Servers
--------------------------------

   Use Internet-domain sockets when you want to do client-server
communication that might extend to machines outside of your own system.

   Here's a sample TCP client using Internet-domain sockets:

     #!/usr/bin/perl -w
     use strict;
     use Socket;
     my ($remote,$port, $iaddr, $paddr, $proto, $line);

     $remote  = shift || 'localhost';
     $port    = shift || 2345;  # random port
     if ($port =~ /\D/) { $port = getservbyname($port, 'tcp') }
     die "No port" unless $port;
     $iaddr   = inet_aton($remote) 		|| die "no host: $remote";
     $paddr   = sockaddr_in($port, $iaddr);

     $proto   = getprotobyname('tcp');
     socket(SOCK, PF_INET, SOCK_STREAM, $proto)	|| die "socket: $!";
     connect(SOCK, $paddr)    || die "connect: $!";
     while (defined($line = <SOCK>)) {
     	print $line;
     }

     close (SOCK)	    || die "close: $!";
     exit;

   And here's a corresponding server to go along with it.  We'll leave the
address as INADDR_ANY so that the kernel can choose the appropriate
interface on multihomed hosts.  If you want sit on a particular interface
(like the external side of a gateway or firewall machine), you should fill
this in with your real address instead.

     #!/usr/bin/perl -Tw
     use strict;
     BEGIN { $ENV{PATH} = '/usr/ucb:/bin' }
     use Socket;
     use Carp;
     $EOL = "\015\012";

     sub logmsg { print "$0 $$: @_ at ", scalar localtime, "\n" }

     my $port = shift || 2345;
     my $proto = getprotobyname('tcp');
     $port = $1 if $port =~ /(\d+)/; # untaint port number

     socket(Server, PF_INET, SOCK_STREAM, $proto)	|| die "socket: $!";
     setsockopt(Server, SOL_SOCKET, SO_REUSEADDR,
     					pack("l", 1)) 	|| die "setsockopt: $!";
     bind(Server, sockaddr_in($port, INADDR_ANY))	|| die "bind: $!";
     listen(Server,SOMAXCONN) 				|| die "listen: $!";

     logmsg "server started on port $port";

     my $paddr;

     $SIG{CHLD} = \&REAPER;

     for ( ; $paddr = accept(Client,Server); close Client) {
     	my($port,$iaddr) = sockaddr_in($paddr);
     	my $name = gethostbyaddr($iaddr,AF_INET);

     logmsg "connection from $name [",
     	inet_ntoa($iaddr), "]
     	at port $port";

     print Client "Hello there, $name, it's now ",
     		scalar localtime, $EOL;
         }

   And here's a multithreaded version.  It's multithreaded in that like
most typical servers, it spawns (forks) a slave server to handle the
client request so that the master server can quickly go back to service a
new client.

     #!/usr/bin/perl -Tw
     use strict;
     BEGIN { $ENV{PATH} = '/usr/ucb:/bin' }
     use Socket;
     use Carp;
     $EOL = "\015\012";

     sub spawn;  # forward declaration
     sub logmsg { print "$0 $$: @_ at ", scalar localtime, "\n" }

     my $port = shift || 2345;
     my $proto = getprotobyname('tcp');
     $port = $1 if $port =~ /(\d+)/; # untaint port number

     socket(Server, PF_INET, SOCK_STREAM, $proto)	|| die "socket: $!";
     setsockopt(Server, SOL_SOCKET, SO_REUSEADDR,
     					pack("l", 1)) 	|| die "setsockopt: $!";
     bind(Server, sockaddr_in($port, INADDR_ANY))	|| die "bind: $!";
     listen(Server,SOMAXCONN) 				|| die "listen: $!";

     logmsg "server started on port $port";

     my $waitedpid = 0;
     my $paddr;

     sub REAPER {
     	$waitedpid = wait;
     	$SIG{CHLD} = \&REAPER;  # loathe sysV
     	logmsg "reaped $waitedpid" . ($? ? " with exit $?" : '');
     }

     $SIG{CHLD} = \&REAPER;

     for ( $waitedpid = 0;
     	  ($paddr = accept(Client,Server)) || $waitedpid;
     	  $waitedpid = 0, close Client)
     {
     	next if $waitedpid and not $paddr;
     	my($port,$iaddr) = sockaddr_in($paddr);
     	my $name = gethostbyaddr($iaddr,AF_INET);

     logmsg "connection from $name [",
     	inet_ntoa($iaddr), "]
     	at port $port";

     spawn sub {
         print "Hello there, $name, it's now ", scalar localtime, $EOL;
         exec '/usr/games/fortune'		# XXX: `wrong' line terminators
     	or confess "can't exec fortune: $!";
     };

     }

     sub spawn {
     	my $coderef = shift;

     unless (@_ == 0 && $coderef && ref($coderef) eq 'CODE') {
         confess "usage: spawn CODEREF";
     }

     my $pid;
     if (!defined($pid = fork)) {
         logmsg "cannot fork: $!";
         return;
     } elsif ($pid) {
         logmsg "begat $pid";
         return; # I'm the parent
     }
     # else I'm the child -- go spawn

     open(STDIN,  "<&Client")   || die "can't dup client to stdin";
     open(STDOUT, ">&Client")   || die "can't dup client to stdout";
     ## open(STDERR, ">&STDOUT") || die "can't dup stdout to stderr";
     exit &$coderef();
         }

   This server takes the trouble to clone off a child version via fork()
for each incoming request.  That way it can handle many requests at once,
which you might not always want.  Even if you don't fork(), the listen()
will allow that many pending connections.  Forking servers have to be
particularly careful about cleaning up their dead children (called
"zombies" in Unix parlance), because otherwise you'll quickly fill up your
process table.

   We suggest that you use the -T flag to use taint checking (see *Note
Perlsec: perlsec,) even if we aren't running setuid or setgid.  This is
always a good idea for servers and other programs run on behalf of someone
else (like CGI scripts), because it lessens the chances that people from
the outside will be able to compromise your system.

   Let's look at another TCP client.  This one connects to the TCP "time"
service on a number of different machines and shows how far their clocks
differ from the system on which it's being run:

     #!/usr/bin/perl  -w
     use strict;
     use Socket;

     my $SECS_of_70_YEARS = 2208988800;
     sub ctime { scalar localtime(shift) }

     my $iaddr = gethostbyname('localhost');
     my $proto = getprotobyname('tcp');
     my $port = getservbyname('time', 'tcp');
     my $paddr = sockaddr_in(0, $iaddr);
     my($host);

     $| = 1;
     printf "%-24s %8s %s\n",  "localhost", 0, ctime(time());

     foreach $host (@ARGV) {
     	printf "%-24s ", $host;
     	my $hisiaddr = inet_aton($host)     || die "unknown host";
     	my $hispaddr = sockaddr_in($port, $hisiaddr);
     	socket(SOCKET, PF_INET, SOCK_STREAM, $proto)   || die "socket: $!";
     	connect(SOCKET, $hispaddr)          || die "bind: $!";
     	my $rtime = '    ';
     	read(SOCKET, $rtime, 4);
     	close(SOCKET);
     	my $histime = unpack("N", $rtime) - $SECS_of_70_YEARS ;
     	printf "%8d %s\n", $histime - time, ctime($histime);
     }

Unix-Domain TCP Clients and Servers
-----------------------------------

   That's fine for Internet-domain clients and servers, but what about
local communications?  While you can use the same setup, sometimes you
don't want to.  Unix-domain sockets are local to the current host, and are
often used internally to implement pipes.  Unlike Internet domain sockets,
Unix domain sockets can show up in the file system with an ls(1) listing.

     % ls -l /dev/log
     srw-rw-rw-  1 root            0 Oct 31 07:23 /dev/log

   You can test for these with Perl's -S file test:

     unless ( -S '/dev/log' ) {
     	die "something's wicked with the print system";
     }

   Here's a sample Unix-domain client:

     #!/usr/bin/perl -w
     use Socket;
     use strict;
     my ($rendezvous, $line);

     $rendezvous = shift || '/tmp/catsock';
     socket(SOCK, PF_UNIX, SOCK_STREAM, 0)	|| die "socket: $!";
     connect(SOCK, sockaddr_un($rendezvous))	|| die "connect: $!";
     while (defined($line = <SOCK>)) {
     	print $line;
     }
     exit;

   And here's a corresponding server.  You don't have to worry about silly
network terminators here because Unix domain sockets are guaranteed to be
on the localhost, and thus everything works right.

     #!/usr/bin/perl -Tw
     use strict;
     use Socket;
     use Carp;

     BEGIN { $ENV{PATH} = '/usr/ucb:/bin' }
     sub logmsg { print "$0 $$: @_ at ", scalar localtime, "\n" }

     my $NAME = '/tmp/catsock';
     my $uaddr = sockaddr_un($NAME);
     my $proto = getprotobyname('tcp');

     socket(Server,PF_UNIX,SOCK_STREAM,0) 	|| die "socket: $!";
     unlink($NAME);
     bind  (Server, $uaddr) 			|| die "bind: $!";
     listen(Server,SOMAXCONN)			|| die "listen: $!";

     logmsg "server started on $NAME";

     my $waitedpid;

     sub REAPER {
     	$waitedpid = wait;
     	$SIG{CHLD} = \&REAPER;  # loathe sysV
     	logmsg "reaped $waitedpid" . ($? ? " with exit $?" : '');
     }

     $SIG{CHLD} = \&REAPER;

     for ( $waitedpid = 0;
     	  accept(Client,Server) || $waitedpid;
     	  $waitedpid = 0, close Client)
     {
     	next if $waitedpid;
     	logmsg "connection on $NAME";
     	spawn sub {
     	    print "Hello there, it's now ", scalar localtime, "\n";
     	    exec '/usr/games/fortune' or die "can't exec fortune: $!";
     	};
     }

   As you see, it's remarkably similar to the Internet domain TCP server,
so much so, in fact, that we've omitted several duplicate
functions-spawn(), logmsg(), ctime(), and REAPER()-which are exactly the
same as in the other server.

   So why would you ever want to use a Unix domain socket instead of a
simpler named pipe?  Because a named pipe doesn't give you sessions.  You
can't tell one process's data from another's.  With socket programming,
you get a separate session for each client: that's why accept() takes two
arguments.

   For example, let's say that you have a long running database server
daemon that you want folks from the World Wide Web to be able to access,
but only if they go through a CGI interface.  You'd have a small, simple
CGI program that does whatever checks and logging you feel like, and then
acts as a Unix-domain client and connects to your private server.

TCP Clients with IO::Socket
===========================

   For those preferring a higher-level interface to socket programming, the
IO::Socket module provides an object-oriented approach.  IO::Socket is
included as part of the standard Perl distribution as of the 5.004
release.  If you're running an earlier version of Perl, just fetch
IO::Socket from CPAN, where you'll also find find modules providing easy
interfaces to the following systems: DNS, FTP, Ident (RFC 931), NIS and
NISPlus, NNTP, Ping, POP3, SMTP, SNMP, SSLeay, Telnet, and Time-just to
name a few.

A Simple Client
---------------

   Here's a client that creates a TCP connection to the "daytime" service
at port 13 of the host name "localhost" and prints out everything that the
server there cares to provide.

     #!/usr/bin/perl -w
     use IO::Socket;
     $remote = IO::Socket::INET->new(
     			Proto    => "tcp",
     			PeerAddr => "localhost",
     			PeerPort => "daytime(13)",
     		    )
     		  or die "cannot connect to daytime port at localhost";
     while ( <$remote> ) { print }

   When you run this program, you should get something back that looks
like this:

     Wed May 14 08:40:46 MDT 1997

   Here are what those parameters to the new constructor mean:

Proto
     This is which protocol to use.  In this case, the socket handle
     returned will be connected to a TCP socket, because we want a
     stream-oriented connection, that is, one that acts pretty much like a
     plain old file.  Not all sockets are this of this type.  For example,
     the UDP protocol can be used to make a datagram socket, used for
     message-passing.

`PeerAddr'
     This is the name or Internet address of the remote host the server is
     running on.  We could have specified a longer name like
     `"www.perl.com"', or an address like `"204.148.40.9"'.  For
     demonstration purposes, we've used the special hostname
     `"localhost"', which should always mean the current machine you're
     running on.  The corresponding Internet address for localhost is
     `"127.1"', if you'd rather use that.

`PeerPort'
     This is the service name or port number we'd like to connect to.  We
     could have gotten away with using just `"daytime"' on systems with a
     well-configured system services file,[FOOTNOTE: The system services
     file is in */etc/services* under Unix] but just in case, we've
     specified the port number (13) in parentheses.  Using just the number
     would also have worked, but constant numbers make careful programmers
     nervous.

   Notice how the return value from the new constructor is used as a
filehandle in the while loop?  That's what's called an indirect
filehandle, a scalar variable containing a filehandle.  You can use it the
same way you would a normal filehandle.  For example, you can read one
line from it this way:

     $line = <$handle>;

   all remaining lines from is this way:

     @lines = <$handle>;

   and send a line of data to it this way:

     print $handle "some data\n";

A Webget Client
---------------

   Here's a simple client that takes a remote host to fetch a document
from, and then a list of documents to get from that host.  This is a more
interesting client than the previous one because it first sends something
to the server before fetching the server's response.

     #!/usr/bin/perl -w
     use IO::Socket;
     unless (@ARGV > 1) { die "usage: $0 host document ..." }
     $host = shift(@ARGV);
     $EOL = "\015\012";
     $BLANK = $EOL x 2;
     foreach $document ( @ARGV ) {
     	$remote = IO::Socket::INET->new( Proto     => "tcp",
     					 PeerAddr  => $host,
     					 PeerPort  => "http(80)",
     				        );
     	unless ($remote) { die "cannot connect to http daemon on $host" }
     	$remote->autoflush(1);
     	print $remote "GET $document HTTP/1.0" . $BLANK;
     	while ( <$remote> ) { print }
     	close $remote;
     }

   The web server handing the "http" service, which is assumed to be at
its standard port, number 80.  If your the web server you're trying to
connect to is at a different port (like 1080 or 8080), you should specify
as the named-parameter pair, `< PeerPort =' 8080 >>.  The autoflush method
is used on the socket because otherwise the system would buffer up the
output we sent it.  (If you're on a Mac, you'll also need to change every
`"\n"' in your code that sends data over the network to be a `"\015\012"'
instead.)

   Connecting to the server is only the first part of the process: once you
have the connection, you have to use the server's language.  Each server
on the network has its own little command language that it expects as
input.  The string that we send to the server starting with "GET" is in
HTTP syntax.  In this case, we simply request each specified document.
Yes, we really are making a new connection for each document, even though
it's the same host.  That's the way you always used to have to speak HTTP.
Recent versions of web browsers may request that the remote server leave
the connection open a little while, but the server doesn't have to honor
such a request.

   Here's an example of running that program, which we'll call *webget*:

     % webget www.perl.com /guanaco.html
     HTTP/1.1 404 File Not Found
     Date: Thu, 08 May 1997 18:02:32 GMT
     Server: Apache/1.2b6
     Connection: close
     Content-type: text/html

     <HEAD><TITLE>404 File Not Found</TITLE></HEAD>
     <BODY><H1>File Not Found</H1>
     The requested URL /guanaco.html was not found on this server.<P>
     </BODY>

   Ok, so that's not very interesting, because it didn't find that
particular document.  But a long response wouldn't have fit on this page.

   For a more fully-featured version of this program, you should look to
the *lwp-request* program included with the LWP modules from CPAN.

Interactive Client with IO::Socket
----------------------------------

   Well, that's all fine if you want to send one command and get one
answer, but what about setting up something fully interactive, somewhat
like the way *telnet* works?  That way you can type a line, get the answer,
type a line, get the answer, etc.

   This client is more complicated than the two we've done so far, but if
you're on a system that supports the powerful fork call, the solution
isn't that rough.  Once you've made the connection to whatever service
you'd like to chat with, call fork to clone your process.  Each of these
two identical process has a very simple job to do: the parent copies
everything from the socket to standard output, while the child
simultaneously copies everything from standard input to the socket.  To
accomplish the same thing using just one process would be *much* harder,
because it's easier to code two processes to do one thing than it is to
code one process to do two things.  (This keep-it-simple principle a
cornerstones of the Unix philosophy, and good software engineering as
well, which is probably why it's spread to other systems.)

   Here's the code:

     #!/usr/bin/perl -w
     use strict;
     use IO::Socket;
     my ($host, $port, $kidpid, $handle, $line);

     unless (@ARGV == 2) { die "usage: $0 host port" }
     ($host, $port) = @ARGV;

     # create a tcp connection to the specified host and port
     $handle = IO::Socket::INET->new(Proto     => "tcp",
     				    PeerAddr  => $host,
     				    PeerPort  => $port)
     	   or die "can't connect to port $port on $host: $!";

     $handle->autoflush(1);		# so output gets there right away
     print STDERR "[Connected to $host:$port]\n";

     # split the program into two processes, identical twins
     die "can't fork: $!" unless defined($kidpid = fork());

     # the if{} block runs only in the parent process
     if ($kidpid) {
     	# copy the socket to standard output
     	while (defined ($line = <$handle>)) {
     	    print STDOUT $line;
     	}
     	kill("TERM", $kidpid);  		# send SIGTERM to child
     }
     # the else{} block runs only in the child process
     else {
     	# copy standard input to the socket
     	while (defined ($line = <STDIN>)) {
     	    print $handle $line;
     	}
     }

   The kill function in the parent's if block is there to send a signal to
our child process (current running in the else block) as soon as the
remote server has closed its end of the connection.

   If the remote server sends data a byte at time, and you need that data
immediately without waiting for a newline (which might not happen), you
may wish to replace the while loop in the parent with the following:

     my $byte;
     while (sysread($handle, $byte, 1) == 1) {
     	print STDOUT $byte;
     }

   Making a system call for each byte you want to read is not very
efficient (to put it mildly) but is the simplest to explain and works
reasonably well.

TCP Servers with IO::Socket
===========================

   As always, setting up a server is little bit more involved than running
a client.  The model is that the server creates a special kind of socket
that does nothing but listen on a particular port for incoming connections.
It does this by calling the `< IO::Socket::INET-'new() >> method with
slightly different arguments than the client did.

Proto
     This is which protocol to use.  Like our clients, we'll still specify
     `"tcp"' here.

LocalPort
     We specify a local port in the LocalPort argument, which we didn't do
     for the client.  This is service name or port number for which you
     want to be the server. (Under Unix, ports under 1024 are restricted
     to the superuser.)  In our sample, we'll use port 9000, but you can
     use any port that's not currently in use on your system.  If you try
     to use one already in used, you'll get an "Address already in use"
     message.  Under Unix, the `netstat -a' command will show which
     services current have servers.

Listen
     The Listen parameter is set to the maximum number of pending
     connections we can accept until we turn away incoming clients.  Think
     of it as a call-waiting queue for your telephone.  The low-level
     Socket module has a special symbol for the system maximum, which is
     SOMAXCONN.

Reuse
     The Reuse parameter is needed so that we restart our server manually
     without waiting a few minutes to allow system buffers to clear out.

   Once the generic server socket has been created using the parameters
listed above, the server then waits for a new client to connect to it.
The server blocks in the accept method, which eventually an bidirectional
connection to the remote client.  (Make sure to autoflush this handle to
circumvent buffering.)

   To add to user-friendliness, our server prompts the user for commands.
Most servers don't do this.  Because of the prompt without a newline,
you'll have to use the sysread variant of the interactive client above.

   This server accepts one of five different commands, sending output back
to the client.  Note that unlike most network servers, this one only
handles one incoming client at a time.  Multithreaded servers are covered
in Chapter 6 of the Camel.

   Here's the code.  We'll

     #!/usr/bin/perl -w
     use IO::Socket;
     use Net::hostent;		# for OO version of gethostbyaddr

     $PORT = 9000;			# pick something not in use

     $server = IO::Socket::INET->new( Proto     => 'tcp',
                                      LocalPort => $PORT,
                                      Listen    => SOMAXCONN,
                                      Reuse     => 1);

     die "can't setup server" unless $server;
     print "[Server $0 accepting clients]\n";

     while ($client = $server->accept()) {
       $client->autoflush(1);
       print $client "Welcome to $0; type help for command list.\n";
       $hostinfo = gethostbyaddr($client->peeraddr);
       printf "[Connect from %s]\n", $hostinfo->name || $client->peerhost;
       print $client "Command? ";
       while ( <$client>) {
         next unless /\S/;	     # blank line
         if    (/quit|exit/i)    { last;                                     }
         elsif (/date|time/i)    { printf $client "%s\n", scalar localtime;  }
         elsif (/who/i )         { print  $client `who 2>&1`;                }
         elsif (/cookie/i )      { print  $client `/usr/games/fortune 2>&1`; }
         elsif (/motd/i )        { print  $client `cat /etc/motd 2>&1`;      }
         else {
           print $client "Commands: quit date who cookie motd\n";
         }
       } continue {
          print $client "Command? ";
       }
       close $client;
     }

UDP: Message Passing
====================

   Another kind of client-server setup is one that uses not connections,
but messages.  UDP communications involve much lower overhead but also
provide less reliability, as there are no promises that messages will
arrive at all, let alone in order and unmangled.  Still, UDP offers some
advantages over TCP, including being able to "broadcast" or "multicast" to
a whole bunch of destination hosts at once (usually on your local subnet).
If you find yourself overly concerned about reliability and start
building checks into your message system, then you probably should use
just TCP to start with.

   Here's a UDP program similar to the sample Internet TCP client given
earlier.  However, instead of checking one host at a time, the UDP version
will check many of them asynchronously by simulating a multicast and then
using select() to do a timed-out wait for I/O.  To do something similar
with TCP, you'd have to use a different socket handle for each host.

     #!/usr/bin/perl -w
     use strict;
     use Socket;
     use Sys::Hostname;

     my ( $count, $hisiaddr, $hispaddr, $histime,
     	 $host, $iaddr, $paddr, $port, $proto,
     	 $rin, $rout, $rtime, $SECS_of_70_YEARS);

     $SECS_of_70_YEARS      = 2208988800;

     $iaddr = gethostbyname(hostname());
     $proto = getprotobyname('udp');
     $port = getservbyname('time', 'udp');
     $paddr = sockaddr_in(0, $iaddr); # 0 means let kernel pick

     socket(SOCKET, PF_INET, SOCK_DGRAM, $proto)   || die "socket: $!";
     bind(SOCKET, $paddr)                          || die "bind: $!";

     $| = 1;
     printf "%-12s %8s %s\n",  "localhost", 0, scalar localtime time;
     $count = 0;
     for $host (@ARGV) {
     	$count++;
     	$hisiaddr = inet_aton($host) 	|| die "unknown host";
     	$hispaddr = sockaddr_in($port, $hisiaddr);
     	defined(send(SOCKET, 0, 0, $hispaddr))    || die "send $host: $!";
     }

     $rin = '';
     vec($rin, fileno(SOCKET), 1) = 1;

     # timeout after 10.0 seconds
     while ($count && select($rout = $rin, undef, undef, 10.0)) {
     	$rtime = '';
     	($hispaddr = recv(SOCKET, $rtime, 4, 0)) 	|| die "recv: $!";
     	($port, $hisiaddr) = sockaddr_in($hispaddr);
     	$host = gethostbyaddr($hisiaddr, AF_INET);
     	$histime = unpack("N", $rtime) - $SECS_of_70_YEARS ;
     	printf "%-12s ", $host;
     	printf "%8d %s\n", $histime - time, scalar localtime($histime);
     	$count--;
     }

SysV IPC
========

   While System V IPC isn't so widely used as sockets, it still has some
interesting uses.  You can't, however, effectively use SysV IPC or
Berkeley mmap() to have shared memory so as to share a variable amongst
several processes.  That's because Perl would reallocate your string when
you weren't wanting it to.

   Here's a small example showing shared memory usage.

     use IPC::SysV qw(IPC_PRIVATE IPC_RMID S_IRWXU);

     $size = 2000;
     $id = shmget(IPC_PRIVATE, $size, S_IRWXU) || die "$!";
     print "shm key $id\n";

     $message = "Message #1";
     shmwrite($id, $message, 0, 60) || die "$!";
     print "wrote: '$message'\n";
     shmread($id, $buff, 0, 60) || die "$!";
     print "read : '$buff'\n";

     # the buffer of shmread is zero-character end-padded.
     substr($buff, index($buff, "\0")) = '';
     print "un" unless $buff eq $message;
     print "swell\n";

     print "deleting shm $id\n";
     shmctl($id, IPC_RMID, 0) || die "$!";

   Here's an example of a semaphore:

     use IPC::SysV qw(IPC_CREAT);

     $IPC_KEY = 1234;
     $id = semget($IPC_KEY, 10, 0666 | IPC_CREAT ) || die "$!";
     print "shm key $id\n";

   Put this code in a separate file to be run in more than one process.
Call the file take:

     # create a semaphore

     $IPC_KEY = 1234;
     $id = semget($IPC_KEY,  0 , 0 );
     die if !defined($id);

     $semnum = 0;
     $semflag = 0;

     # 'take' semaphore
     # wait for semaphore to be zero
     $semop = 0;
     $opstring1 = pack("s!s!s!", $semnum, $semop, $semflag);

     # Increment the semaphore count
     $semop = 1;
     $opstring2 = pack("s!s!s!", $semnum, $semop,  $semflag);
     $opstring = $opstring1 . $opstring2;

     semop($id,$opstring) || die "$!";

   Put this code in a separate file to be run in more than one process.
Call this file give:

     # 'give' the semaphore
     # run this in the original process and you will see
     # that the second process continues

     $IPC_KEY = 1234;
     $id = semget($IPC_KEY, 0, 0);
     die if !defined($id);

     $semnum = 0;
     $semflag = 0;

     # Decrement the semaphore count
     $semop = -1;
     $opstring = pack("s!s!s!", $semnum, $semop, $semflag);

     semop($id,$opstring) || die "$!";

   The SysV IPC code above was written long ago, and it's definitely
clunky looking.  For a more modern look, see the IPC::SysV module which is
included with Perl starting from Perl 5.005.

   A small example demonstrating SysV message queues:

     use IPC::SysV qw(IPC_PRIVATE IPC_RMID IPC_CREAT S_IRWXU);

     my $id = msgget(IPC_PRIVATE, IPC_CREAT | S_IRWXU);

     my $sent = "message";
     my $type = 1234;
     my $rcvd;
     my $type_rcvd;

     if (defined $id) {
         if (msgsnd($id, pack("l! a*", $type_sent, $sent), 0)) {
             if (msgrcv($id, $rcvd, 60, 0, 0)) {
                 ($type_rcvd, $rcvd) = unpack("l! a*", $rcvd);
                 if ($rcvd eq $sent) {
                     print "okay\n";
                 } else {
                     print "not okay\n";
                 }
             } else {
                 die "# msgrcv failed\n";
             }
         } else {
             die "# msgsnd failed\n";
         }
         msgctl($id, IPC_RMID, 0) || die "# msgctl failed: $!\n";
     } else {
         die "# msgget failed\n";
     }

NOTES
=====

   Most of these routines quietly but politely return undef when they fail
instead of causing your program to die right then and there due to an
uncaught exception.  (Actually, some of the new Socket conversion
functions  croak() on bad arguments.)  It is therefore essential to check
return values from these functions.  Always begin your socket programs
this way for optimal success, and don't forget to add -T taint checking
flag to the #! line for servers:

     #!/usr/bin/perl -Tw
     use strict;
     use sigtrap;
     use Socket;

BUGS
====

   All these routines create system-specific portability problems.  As
noted elsewhere, Perl is at the mercy of your C libraries for much of its
system behaviour.  It's probably safest to assume broken SysV semantics for
signals and to stick with simple TCP and UDP socket operations; e.g., don't
try to pass open file descriptors over a local UDP datagram socket if you
want your code to stand a chance of being portable.

   As mentioned in the signals section, because few vendors provide C
libraries that are safely re-entrant, the prudent programmer will do
little else within a handler beyond setting a numeric variable that
already exists; or, if locked into a slow (restarting) system call, using
die() to raise an exception and longjmp(3) out.  In fact, even these may
in some cases cause a core dump.  It's probably best to avoid signals
except where they are absolutely inevitable.  This will be addressed in a
future release of Perl.

AUTHOR
======

   Tom Christiansen, with occasional vestiges of Larry Wall's original
version and suggestions from the Perl Porters.

SEE ALSO
========

   There's a lot more to networking than this, but this should get you
started.

   For intrepid programmers, the indispensable textbook is *Unix Network
Programming* by W. Richard Stevens (published by Addison-Wesley).  Note
that most books on networking address networking from the perspective of a
C programmer; translation to Perl is left as an exercise for the reader.

   The IO::Socket(3) manpage describes the object library, and the
Socket(3) manpage describes the low-level interface to sockets.  Besides
the obvious functions in *Note Perlfunc: perlfunc,, you should also check
out the modules file at your nearest CPAN site.  (See *Note Perlmodlib:
perlmodlib, or best yet, the `Perl FAQ' for a description of what CPAN is
and where to get it.)

   Section 5 of the modules file is devoted to "Networking, Device Control
(modems), and Interprocess Communication", and contains numerous unbundled
modules numerous networking modules, Chat and Expect operations, CGI
programming, DCE, FTP, IPC, NNTP, Proxy, Ptty, RPC, SNMP, SMTP, Telnet,
Threads, and ToolTalk-just to name a few.


File: perl.info,  Node: perllexwarn,  Next: perlfilter,  Prev: perlthrtut,  Up: Top

Perl Lexical Warnings
*********************

NAME
====

   perllexwarn - Perl Lexical Warnings

DESCRIPTION
===========

   The `use warnings' pragma is a replacement for both the command line
flag -w and the equivalent Perl variable, $^W.

   The pragma works just like the existing "strict" pragma.  This means
that the scope of the warning pragma is limited to the enclosing block. It
also means that that the pragma setting will not leak across files (via
use, require or do). This allows authors to independently define the
degree of warning checks that will be applied to their module.

   By default, optional warnings are disabled, so any legacy code that
doesn't attempt to control the warnings will work unchanged.

   All warnings are enabled in a block by either of these:

     use warnings ;
     use warnings 'all' ;

   Similarly all warnings are disabled in a block by either of these:

     no warnings ;
     no warnings 'all' ;

   For example, consider the code below:

     use warnings ;
     my $a ;
     my $b ;
     {
         no warnings ;
     	$b = 2 if $a EQ 3 ;
     }
     $b = 1 if $a NE 3 ;

   The code in the enclosing block has warnings enabled, but the inner
block has them disabled. In this case that means that the use of the `EQ'
operator won't trip a `"Use of EQ is deprecated"' warning, but the use of
`NE' will produce a `"Use of NE is deprecated"' warning.

Default Warnings and Optional Warnings
--------------------------------------

   Before the introduction of lexical warnings, Perl had two classes of
warnings: mandatory and optional.

   As its name suggests, if your code tripped a mandatory warning, you
would get a warning whether you wanted it or not.  For example, the code
below would always produce an `"isn't numeric"' warning about the "2:".

     my $a = "2:" + 3;

   With the introduction of lexical warnings, mandatory warnings now become
default warnings. The difference is that although the previously mandatory
warnings are still enabled by default, they can then be subsequently
enabled or disabled with the lexical warning pragma. For example, in the
code below, an `"isn't numeric"' warning will only be reported for the
`$a' variable.

     my $a = "2:" + 3;
     no warnings ;
     my $b = "2:" + 3;

   Note that neither the -w flag or the $^W can be used to disable/enable
default warnings. They are still mandatory in this case.

What's wrong with -w and $^W
----------------------------

   Although very useful, the big problem with using -w on the command line
to enable warnings is that it is all or nothing. Take the typical scenario
when you are writing a Perl program. Parts of the code you will write
yourself, but it's very likely that you will make use of pre-written Perl
modules. If you use the -w flag in this case, you end up enabling warnings
in pieces of code that you haven't written.

   Similarly, using $^W to either disable or enable blocks of code is
fundamentally flawed. For a start, say you want to disable warnings in a
block of code. You might expect this to be enough to do the trick:

     {
         local ($^W) = 0 ;
     	 my $a =+ 2 ;
     	 my $b ; chop $b ;
     }

   When this code is run with the -w flag, a warning will be produced for
the `$a' line - `"Reversed += operator"'.

   The problem is that Perl has both compile-time and run-time warnings. To
disable compile-time warnings you need to rewrite the code like this:

     {
         BEGIN { $^W = 0 }
     	 my $a =+ 2 ;
     	 my $b ; chop $b ;
     }

   The other big problem with $^W is that way you can inadvertently change
the warning setting in unexpected places in your code. For example, when
the code below is run (without the -w flag), the second call to `doit'
will trip a `"Use of uninitialized value"' warning, whereas the first will
not.

     sub doit
     {
         my $b ; chop $b ;
     }

     doit() ;

     {
         local ($^W) = 1 ;
         doit()
     }

   This is a side-effect of $^W being dynamically scoped.

   Lexical warnings get around these limitations by allowing finer control
over where warnings can or can't be tripped.

Controlling Warnings from the Command Line
------------------------------------------

   There are three Command Line flags that can be used to control when
warnings are (or aren't) produced:

-w
     This is  the existing flag. If the lexical warnings pragma is not
     used in any of you code, or any of the modules that you use, this flag
     will enable warnings everywhere. See `Backward Compatibility' in this
     node for details of how this flag interacts with lexical warnings.

-W
     If the -W flag is used on the command line, it will enable all
     warnings throughout the program regardless of whether warnings were
     disabled locally using `no warnings' or `$^W =0'. This includes all
     files that get included via use, require or do.  Think of it as the
     Perl equivalent of the "lint" command.

-X
     Does the exact opposite to the -W flag, i.e. it disables all warnings.

Backward Compatibility
----------------------

   If you are used with working with a version of Perl prior to the
introduction of lexically scoped warnings, or have code that uses both
lexical warnings and $^W, this section will describe how they interact.

   How Lexical Warnings interact with -w/$^W:

  1. If none of the three command line flags (-w, -W or -X) that control
     warnings is used and neither $^W or the warnings pragma are used,
     then default warnings will be enabled and optional warnings disabled.
     This means that legacy code that doesn't attempt to control the
     warnings will work unchanged.

  2. The -w flag just sets the global $^W variable as in 5.005 - this
     means that any legacy code that currently relies on manipulating $^W
     to control warning behavior will still work as is.

  3. Apart from now being a boolean, the $^W variable operates in exactly
     the same horrible uncontrolled global way, except that it cannot
     disable/enable default warnings.

  4. If a piece of code is under the control of the warnings pragma, both
     the $^W variable and the -w flag will be ignored for the scope of the
     lexical warning.

  5. The only way to override a lexical warnings setting is with the -W or
     -X command line flags.

        The combined effect of 3 & 4 is that it will will allow code which
uses the warnings pragma to control the warning behavior of $^W-type code
(using a `local $^W=0') if it really wants to, but not vice-versa.

Category Hierarchy
------------------

   A hierarchy of "categories" have been defined to allow groups of
warnings to be enabled/disabled in isolation.

   The current hierarchy is:

     all -+
          |
          +- chmod
          |
          +- closure
          |
          +- exiting
          |
          +- glob
          |
          +- io -----------+
          |                |
          |                +- closed
          |                |
          |                +- exec
          |                |
          |                +- newline
          |                |
          |                +- pipe
          |                |
          |                +- unopened
          |
          +- misc
          |
          +- numeric
          |
          +- once
          |
          +- overflow
          |
          +- pack
          |
          +- portable
          |
          +- recursion
          |
          +- redefine
          |
          +- regexp
          |
          +- severe -------+
          |                |
          |                +- debugging
          |                |
          |                +- inplace
          |                |
          |                +- internal
          |                |
          |                +- malloc
          |
          +- signal
          |
          +- substr
          |
          +- syntax -------+
          |                |
          |                +- ambiguous
          |                |
          |                +- bareword
          |                |
          |                +- deprecated
          |                |
          |                +- digit
          |                |
          |                +- parenthesis
          |                |
          |                +- precedence
          |                |
          |                +- printf
          |                |
          |                +- prototype
          |                |
          |                +- qw
          |                |
          |                +- reserved
          |                |
          |                +- semicolon
          |
          +- taint
          |
          +- umask
          |
          +- uninitialized
          |
          +- unpack
          |
          +- untie
          |
          +- utf8
          |
          +- void
          |
          +- y2k

   Just like the "strict" pragma any of these categories can be combined

     use warnings qw(void redefine) ;
     no warnings qw(io syntax untie) ;

   Also like the "strict" pragma, if there is more than one instance of the
warnings pragma in a given scope the cumulative effect is additive.

     use warnings qw(void) ; # only "void" warnings enabled
     ...
     use warnings qw(io) ;   # only "void" & "io" warnings enabled
     ...
     no warnings qw(void) ;  # only "io" warnings enabled

   To determine which category a specific warning has been assigned to see
*Note Perldiag: perldiag,.

Fatal Warnings
--------------

   The presence of the word "FATAL" in the category list will escalate any
warnings detected from the categories specified in the lexical scope into
fatal errors. In the code below, there are 3 places where a deprecated
warning will be detected, the middle one will produce a fatal error.

     use warnings ;

     $a = 1 if $a EQ $b ;

     {
         use warnings FATAL => qw(deprecated) ;
         $a = 1 if $a EQ $b ;
     }

     $a = 1 if $a EQ $b ;

Reporting Warnings from a Module
--------------------------------

   The warnings pragma provides a number of functions that are useful for
module authors. These are used when you want to report a module-specific
warning when the calling module has enabled warnings via the warnings
pragma.

   Consider the module `MyMod::Abc' below.

     package MyMod::Abc;

     use warnings::register;

     sub open {
         my $path = shift ;
         if (warnings::enabled() && $path !~ m#^/#) {
             warnings::warn("changing relative path to /tmp/");
             $path = "/tmp/$path" ;
         }
     }

     1 ;

   The call to `warnings::register' will create a new warnings category
called "MyMod::abc", i.e. the new category name matches the module name.
The open function in the module will display a warning message if it gets
given a relative path as a parameter. This warnings will only be displayed
if the code that uses `MyMod::Abc' has actually enabled them with the
warnings pragma like below.

     use MyMod::Abc;
     use warnings 'MyMod::Abc';
     ...
     abc::open("../fred.txt");

   It is also possible to test whether the pre-defined warnings categories
are set in the calling module with the `warnings::enabled' function.
Consider this snippet of code:

     package MyMod::Abc;

     sub open {
         if (warnings::enabled("deprecated")) {
             warnings::warn("deprecated",
                            "open is deprecated, use new instead") ;
         }
         new(@_) ;
     }

     sub new
     ...
     1 ;

   The function open has been deprecated, so code has been included to
display a warning message whenever the calling module has (at least) the
"deprecated" warnings category enabled. Something like this, say.

     use warnings 'deprecated';
     use MyMod::Abc;
     ...
     MyMod::Abc::open($filename) ;

   The `warnings::warn' function should be used to actually display the
warnings message. This is because they can make use of the feature that
allows warnings to be escalated into fatal errors. So in this case

     use MyMod::Abc;
     use warnings FATAL => 'MyMod::Abc';
     ...
     MyMod::Abc::open('../fred.txt');

   the `warnings::warn' function will detect this and die after displaying
the warning message.

TODO
====

     perl5db.pl
       The debugger saves and restores C<$^W> at runtime. I haven't checked
       whether the debugger will still work with the lexical warnings
       patch applied.

     diagnostics.pm
       I *think* I've got diagnostics to work with the lexical warnings
       patch, but there were design decisions made in diagnostics to work
       around the limitations of C<$^W>. Now that those limitations are gone,
       the module should be revisited.

SEE ALSO
========

   *Note Warnings: (pm.info)warnings,, *Note Perldiag: perldiag,.

AUTHOR
======

   Paul Marquess


File: perl.info,  Node: perllocale,  Next: perlreftut,  Prev: perlunicode,  Up: Top

Perl locale handling (internationalization and localization)
************************************************************

NAME
====

   perllocale - Perl locale handling (internationalization and
localization)

DESCRIPTION
===========

   Perl supports language-specific notions of data such as "is this a
letter", "what is the uppercase equivalent of this letter", and "which of
these letters comes first".  These are important issues, especially for
languages other than English-but also for English: it would be naE<iuml>ve
to imagine that `A-Za-z' defines all the "letters" needed to write in
English. Perl is also aware that some character other than '.' may be
preferred as a decimal point, and that output date representations may be
language-specific.  The process of making an application take account of
its users' preferences in such matters is called *internationalization*
(often abbreviated as *i18n*); telling such an application about a
particular set of preferences is known as *localization* (*l10n*).

   Perl can understand language-specific data via the standardized (ISO C,
XPG4, POSIX 1.c) method called "the locale system". The locale system is
controlled per application using one pragma, one function call, and
several environment variables.

   NOTE: This feature is new in Perl 5.004, and does not apply unless an
application specifically requests it-see `Backward compatibility' in this
node.  The one exception is that write() now always uses the current locale
- see `"NOTES"' in this node.

PREPARING TO USE LOCALES
========================

   If Perl applications are to understand and present your data correctly
according a locale of your choice, all of the following must be true:

   * *Your operating system must support the locale system*.  If it does,
     you should find that the setlocale() function is a documented part of
     its C library.

   * *Definitions for locales that you use must be installed*.  You, or
     your system administrator, must make sure that this is the case. The
     available locales, the location in which they are kept, and the manner
     in which they are installed all vary from system to system.  Some
     systems provide only a few, hard-wired locales and do not allow more
     to be added.  Others allow you to add "canned" locales provided by
     the system supplier.  Still others allow you or the system
     administrator to define and add arbitrary locales.  (You may have to
     ask your supplier to provide canned locales that are not delivered
     with your operating system.)  Read your system documentation for
     further illumination.

   * *Perl must believe that the locale system is supported*.  If it does,
     `perl -V:d_setlocale' will say that the value for `d_setlocale' is
     define.

   If you want a Perl application to process and present your data
according to a particular locale, the application code should include the
`use locale' pragma (see `The use locale pragma' in this node) where
appropriate, and *at least one* of the following must be true:

   * *The locale-determining environment variables (see `"ENVIRONMENT"' in
     this node) must be correctly set up* at the time the application is
     started, either by yourself or by whoever set up your system account.

   * *The application must set its own locale* using the method described
     in `The setlocale function' in this node.

USING LOCALES
=============

The use locale pragma
---------------------

   By default, Perl ignores the current locale.  The `use locale' pragma
tells Perl to use the current locale for some operations:

   * *The comparison operators* (lt, le, cmp, ge, and gt) and the POSIX
     string collation functions strcoll() and strxfrm() use LC_COLLATE.
     sort() is also affected if used without an explicit comparison
     function, because it uses cmp by default.

     Note: eq and ne are unaffected by locale: they always perform a
     byte-by-byte comparison of their scalar operands.  What's more, if
     cmp finds that its operands are equal according to the collation
     sequence specified by the current locale, it goes on to perform a
     byte-by-byte comparison, and only returns 0 (equal) if the operands
     are bit-for-bit identical.  If you really want to know whether two
     strings-which eq and cmp may consider different-are equal as far as
     collation in the locale is concerned, see the discussion in `Category
     LC_COLLATE: Collation' in this node.

   * *Regular expressions and case-modification functions* (uc(), lc(),
     ucfirst(), and lcfirst()) use LC_CTYPE

   * *The formatting functions* (printf(), sprintf() and write()) use
     LC_NUMERIC

   * *The POSIX date formatting function* (strftime()) uses LC_TIME.

   LC_COLLATE, LC_CTYPE, and so on, are discussed further in `LOCALE
CATEGORIES' in this node.

   The default behavior is restored with the `no locale' pragma, or upon
reaching the end of block enclosing `use locale'.

   The string result of any operation that uses locale information is
tainted, as it is possible for a locale to be untrustworthy.  See
`"SECURITY"' in this node.

The setlocale function
----------------------

   You can switch locales as often as you wish at run time with the
POSIX::setlocale() function:

     # This functionality not usable prior to Perl 5.004
     require 5.004;

     # Import locale-handling tool set from POSIX module.
     # This example uses: setlocale -- the function call
     #                    LC_CTYPE -- explained below
     use POSIX qw(locale_h);

     # query and save the old locale
     $old_locale = setlocale(LC_CTYPE);

     setlocale(LC_CTYPE, "fr_CA.ISO8859-1");
     # LC_CTYPE now in locale "French, Canada, codeset ISO 8859-1"

     setlocale(LC_CTYPE, "");
     # LC_CTYPE now reset to default defined by LC_ALL/LC_CTYPE/LANG
     # environment variables.  See below for documentation.

     # restore the old locale
     setlocale(LC_CTYPE, $old_locale);

   The first argument of setlocale() gives the category, the second the
locale.  The category tells in what aspect of data processing you want to
apply locale-specific rules.  Category names are discussed in `LOCALE
CATEGORIES' in this node and `"ENVIRONMENT"' in this node.  The locale is
the name of a collection of customization information corresponding to a
particular combination of language, country or territory, and codeset.
Read on for hints on the naming of locales: not all systems name locales
as in the example.

   If no second argument is provided and the category is something else
than LC_ALL, the function returns a string naming the current locale for
the category.  You can use this value as the second argument in a
subsequent call to setlocale().

   If no second argument is provided and the category is LC_ALL, the
result is implementation-dependent.  It may be a string of concatenated
locales names (separator also implementation-dependent) or a single locale
name.  Please consult your `setlocale(3)' in this node for details.

   If a second argument is given and it corresponds to a valid locale, the
locale for the category is set to that value, and the function returns the
now-current locale value.  You can then use this in yet another call to
setlocale().  (In some implementations, the return value may sometimes
differ from the value you gave as the second argument-think of it as an
alias for the value you gave.)

   As the example shows, if the second argument is an empty string, the
category's locale is returned to the default specified by the
corresponding environment variables.  Generally, this results in a return
to the default that was in force when Perl started up: changes to the
environment made by the application after startup may or may not be
noticed, depending on your system's C library.

   If the second argument does not correspond to a valid locale, the locale
for the category is not changed, and the function returns undef.

   For further information about the categories, consult `setlocale(3)' in
this node.

Finding locales
---------------

   For locales available in your system, consult also `setlocale(3)' in
this node to see whether it leads to the list of available locales (search
for the SEE ALSO section).  If that fails, try the following command lines:

     locale -a

     nlsinfo

     ls /usr/lib/nls/loc

     ls /usr/lib/locale

     ls /usr/lib/nls

     ls /usr/share/locale

   and see whether they list something resembling these

     en_US.ISO8859-1     de_DE.ISO8859-1     ru_RU.ISO8859-5
     en_US.iso88591      de_DE.iso88591      ru_RU.iso88595
     en_US               de_DE               ru_RU
     en                  de                  ru
     english             german              russian
     english.iso88591    german.iso88591     russian.iso88595
     english.roman8                          russian.koi8r

   Sadly, even though the calling interface for setlocale() has been
standardized, names of locales and the directories where the configuration
resides have not been.  The basic form of the name is
*language_territory*.*codeset*, but the latter parts after language are
not always present.  The language and country are usually from the
standards *ISO 3166* and *ISO 639*, the two-letter abbreviations for the
countries and the languages of the world, respectively.  The *codeset*
part often mentions some *ISO 8859* character set, the Latin codesets.
For example, `ISO 8859-1' is the so-called "Western European codeset" that
can be used to encode most Western European languages adequately.  Again,
there are several ways to write even the name of that one standard.
Lamentably.

   Two special locales are worth particular mention: "C" and "POSIX".
Currently these are effectively the same locale: the difference is mainly
that the first one is defined by the C standard, the second by the POSIX
standard.  They define the *default locale* in which every program starts
in the absence of locale information in its environment.  (The default
default locale, if you will.)  Its language is (American) English and its
character codeset ASCII.

   NOTE: Not all systems have the "POSIX" locale (not all systems are
POSIX-conformant), so use "C" when you need explicitly to specify this
default locale.

LOCALE PROBLEMS
---------------

   You may encounter the following warning message at Perl startup:

     perl: warning: Setting locale failed.
     perl: warning: Please check that your locale settings:
             LC_ALL = "En_US",
             LANG = (unset)
         are supported and installed on your system.
     perl: warning: Falling back to the standard locale ("C").

   This means that your locale settings had LC_ALL set to "En_US" and LANG
exists but has no value.  Perl tried to believe you but could not.
Instead, Perl gave up and fell back to the "C" locale, the default locale
that is supposed to work no matter what.  This usually means your locale
settings were wrong, they mention locales your system has never heard of,
or the locale installation in your system has problems (for example, some
system files are broken or missing).  There are quick and temporary fixes
to these problems, as well as more thorough and lasting fixes.

Temporarily fixing locale problems
----------------------------------

   The two quickest fixes are either to render Perl silent about any
locale inconsistencies or to run Perl under the default locale "C".

   Perl's moaning about locale problems can be silenced by setting the
environment variable PERL_BADLANG to a zero value, for example "0".  This
method really just sweeps the problem under the carpet: you tell Perl to
shut up even when Perl sees that something is wrong.  Do not be surprised
if later something locale-dependent misbehaves.

   Perl can be run under the "C" locale by setting the environment
variable LC_ALL to "C".  This method is perhaps a bit more civilized than
the PERL_BADLANG approach, but setting LC_ALL (or other locale variables)
may affect other programs as well, not just Perl.  In particular, external
programs run from within Perl will see these changes.  If you make the new
settings permanent (read on), all programs you run see the changes.  See
`ENVIRONMENT' in this node for for the full list of relevant environment
variables and `USING LOCALES' in this node for their effects in Perl.
Effects in other programs are easily deducible.  For example, the variable
LC_COLLATE may well affect your sort program (or whatever the program that
arranges `records' alphabetically in your system is called).

   You can test out changing these variables temporarily, and if the new
settings seem to help, put those settings into your shell startup files.
Consult your local documentation for the exact details.  For in
Bourne-like shells (*sh*, *ksh*, *bash*, *zsh*):

     LC_ALL=en_US.ISO8859-1
     export LC_ALL

   This assumes that we saw the locale "en_US.ISO8859-1" using the commands
discussed above.  We decided to try that instead of the above faulty
locale "En_US"-and in Cshish shells (*csh*, *tcsh*)

     setenv LC_ALL en_US.ISO8859-1

   If you do not know what shell you have, consult your local helpdesk or
the equivalent.

Permanently fixing locale problems
----------------------------------

   The slower but superior fixes are when you may be able to yourself fix
the misconfiguration of your own environment variables.  The
mis(sing)configuration of the whole system's locales usually requires the
help of your friendly system administrator.

   First, see earlier in this document about `Finding locales' in this
node.  That tells how to find which locales are really supported-and more
importantly, installed-on your system.  In our example error message,
environment variables affecting the locale are listed in the order of
decreasing importance (and unset variables do not matter).  Therefore,
having LC_ALL set to "En_US" must have been the bad choice, as shown by the
error message.  First try fixing locale settings listed first.

   Second, if using the listed commands you see something *exactly*
(prefix matches do not count and case usually counts) like "En_US" without
the quotes, then you should be okay because you are using a locale name
that should be installed and available in your system.  In this case, see
`Permanently fixing your system's locale configuration' in this node.

Permanently fixing your system's locale configuration
-----------------------------------------------------

   This is when you see something like:

     perl: warning: Please check that your locale settings:
             LC_ALL = "En_US",
             LANG = (unset)
         are supported and installed on your system.

   but then cannot see that "En_US" listed by the above-mentioned
commands.  You may see things like "en_US.ISO8859-1", but that isn't the
same.  In this case, try running under a locale that you can list and
which somehow matches what you tried.  The rules for matching locale names
are a bit vague because standardization is weak in this area.  See again
the `Finding locales' in this node about general rules.

Fixing system locale configuration
----------------------------------

   Contact a system administrator (preferably your own) and report the
exact error message you get, and ask them to read this same documentation
you are now reading.  They should be able to check whether there is
something wrong with the locale configuration of the system.  The `Finding
locales' in this node section is unfortunately a bit vague about the exact
commands and places because these things are not that standardized.

The localeconv function
-----------------------

   The POSIX::localeconv() function allows you to get particulars of the
locale-dependent numeric formatting information specified by the current
LC_NUMERIC and LC_MONETARY locales.  (If you just want the name of the
current locale for a particular category, use POSIX::setlocale() with a
single parameter-see `The setlocale function' in this node.)

     use POSIX qw(locale_h);

     # Get a reference to a hash of locale-dependent info
     $locale_values = localeconv();

     # Output sorted list of the values
     for (sort keys %$locale_values) {
         printf "%-20s = %s\n", $_, $locale_values->{$_}
     }

   localeconv() takes no arguments, and returns *a reference to* a hash.
The keys of this hash are variable names for formatting, such as
`decimal_point' and `thousands_sep'.  The values are the corresponding,
er, values.  See `POSIX (3)' in this node for a longer example listing the
categories an implementation might be expected to provide; some provide
more and others fewer.  You don't need an explicit `use locale', because
localeconv() always observes the current locale.

   Here's a simple-minded example program that rewrites its command-line
parameters as integers correctly formatted in the current locale:

     # See comments in previous example
     require 5.004;
     use POSIX qw(locale_h);

     # Get some of locale's numeric formatting parameters
     my ($thousands_sep, $grouping) =
          @{localeconv()}{'thousands_sep', 'grouping'};

     # Apply defaults if values are missing
     $thousands_sep = ',' unless $thousands_sep;

     # grouping and mon_grouping are packed lists
     # of small integers (characters) telling the
     # grouping (thousand_seps and mon_thousand_seps
     # being the group dividers) of numbers and
     # monetary quantities.  The integers' meanings:
     # 255 means no more grouping, 0 means repeat
     # the previous grouping, 1-254 means use that
     # as the current grouping.  Grouping goes from
     # right to left (low to high digits).  In the
     # below we cheat slightly by never using anything
     # else than the first grouping (whatever that is).
     if ($grouping) {
         @grouping = unpack("C*", $grouping);
     } else {
         @grouping = (3);
     }

     # Format command line params for current locale
     for (@ARGV) {
         $_ = int;    # Chop non-integer part
         1 while
         s/(\d)(\d{$grouping[0]}($|$thousands_sep))/$1$thousands_sep$2/;
         print "$_";
     }
     print "\n";

LOCALE CATEGORIES
=================

   The following subsections describe basic locale categories.  Beyond
these, some combination categories allow manipulation of more than one
basic category at a time.  See `"ENVIRONMENT"' in this node for a
discussion of these.

Category LC_COLLATE: Collation
------------------------------

   In the scope of `use locale', Perl looks to the LC_COLLATE environment
variable to determine the application's notions on collation (ordering) of
characters.  For example, 'b' follows 'a' in Latin alphabets, but where do
'E<aacute>' and 'E<aring>' belong?  And while 'color' follows 'chocolate'
in English, what about in Spanish?

   The following collations all make sense and you may meet any of them if
you "use locale".

     A B C D E a b c d e
     A a B b C c D d D e
     a A b B c C d D e E
     a b c d e A B C D E

   Here is a code snippet to tell what alphanumeric characters are in the
current locale, in that locale's order:

     use locale;
     print +(sort grep /\w/, map { chr() } 0..255), "\n";

   Compare this with the characters that you see and their order if you
state explicitly that the locale should be ignored:

     no locale;
     print +(sort grep /\w/, map { chr() } 0..255), "\n";

   This machine-native collation (which is what you get unless
`use locale' has appeared earlier in the same block) must be used for
sorting raw binary data, whereas the locale-dependent collation of the
first example is useful for natural text.

   As noted in `USING LOCALES' in this node, cmp compares according to the
current collation locale when `use locale' is in effect, but falls back to
a byte-by-byte comparison for strings that the locale says are equal. You
can use POSIX::strcoll() if you don't want this fall-back:

     use POSIX qw(strcoll);
     $equal_in_locale =
         !strcoll("space and case ignored", "SpaceAndCaseIgnored");

   $equal_in_locale will be true if the collation locale specifies a
dictionary-like ordering that ignores space characters completely and
which folds case.

   If you have a single string that you want to check for "equality in
locale" against several others, you might think you could gain a little
efficiency by using POSIX::strxfrm() in conjunction with eq:

     use POSIX qw(strxfrm);
     $xfrm_string = strxfrm("Mixed-case string");
     print "locale collation ignores spaces\n"
         if $xfrm_string eq strxfrm("Mixed-casestring");
     print "locale collation ignores hyphens\n"
         if $xfrm_string eq strxfrm("Mixedcase string");
     print "locale collation ignores case\n"
         if $xfrm_string eq strxfrm("mixed-case string");

   strxfrm() takes a string and maps it into a transformed string for use
in byte-by-byte comparisons against other transformed strings during
collation.  "Under the hood", locale-affected Perl comparison operators
call strxfrm() for both operands, then do a byte-by-byte comparison of the
transformed strings.  By calling strxfrm() explicitly and using a non
locale-affected comparison, the example attempts to save a couple of
transformations.  But in fact, it doesn't save anything: Perl magic (see
`Magic Variables', *Note Perlguts: perlguts,) creates the transformed
version of a string the first time it's needed in a comparison, then keeps
this version around in case it's needed again.  An example rewritten the
easy way with cmp runs just about as fast.  It also copes with null
characters embedded in strings; if you call strxfrm() directly, it treats
the first null it finds as a terminator.  don't expect the transformed
strings it produces to be portable across systems-or even from one revision
of your operating system to the next.  In short, don't call strxfrm()
directly: let Perl do it for you.

   Note: `use locale' isn't shown in some of these examples because it
isn't needed: strcoll() and strxfrm() exist only to generate
locale-dependent results, and so always obey the current LC_COLLATE locale.

Category LC_CTYPE: Character Types
----------------------------------

   In the scope of `use locale', Perl obeys the LC_CTYPE locale setting.
This controls the application's notion of which characters are alphabetic.
This affects Perl's `\w' regular expression metanotation, which stands
for alphanumeric characters-that is, alphabetic and numeric characters.
(Consult *Note Perlre: perlre, for more information about regular
expressions.)  Thanks to LC_CTYPE, depending on your locale setting,
characters like 'E<aelig>', 'E<eth>', 'E<szlig>', and 'E<oslash>' may be
understood as `\w' characters.

   The LC_CTYPE locale also provides the map used in transliterating
characters between lower and uppercase.  This affects the case-mapping
functions-lc(), lcfirst, uc(), and ucfirst(); case-mapping interpolation
with `\l', `\L', `\u', or `\U' in double-quoted strings and s///
substitutions; and case-independent regular expression pattern matching
using the i modifier.

   Finally, LC_CTYPE affects the POSIX character-class test
functions-isalpha(), islower(), and so on.  For example, if you move from
the "C" locale to a 7-bit Scandinavian one, you may find-possibly to your
surprise-that "|" moves from the ispunct() class to isalpha().

   Note: A broken or malicious LC_CTYPE locale definition may result in
clearly ineligible characters being considered to be alphanumeric by your
application.  For strict matching of (mundane) letters and digits-for
example, in command strings-locale-aware applications should use `\w'
inside a `no locale' block.  See `"SECURITY"' in this node.

Category LC_NUMERIC: Numeric Formatting
---------------------------------------

   In the scope of `use locale', Perl obeys the LC_NUMERIC locale
information, which controls an application's idea of how numbers should be
formatted for human readability by the printf(), sprintf(), and write()
functions.  String-to-numeric conversion by the POSIX::strtod() function
is also affected.  In most implementations the only effect is to change
the character used for the decimal point-perhaps from '.'  to ','.  These
functions aren't aware of such niceties as thousands separation and so on.
(See `The localeconv function' in this node if you care about these
things.)

   Output produced by print() is never affected by the current locale: it
is independent of whether `use locale' or `no locale' is in effect, and
corresponds to what you'd get from printf() in the "C" locale.  The same
is true for Perl's internal conversions between numeric and string formats:

     use POSIX qw(strtod);
     use locale;

     $n = 5/2;   # Assign numeric 2.5 to $n

     $a = " $n"; # Locale-independent conversion to string

     print "half five is $n\n";       # Locale-independent output

     printf "half five is %g\n", $n;  # Locale-dependent output

     print "DECIMAL POINT IS COMMA\n"
         if $n == (strtod("2,5"))[0]; # Locale-dependent conversion

Category LC_MONETARY: Formatting of monetary amounts
----------------------------------------------------

   The C standard defines the LC_MONETARY category, but no function that
is affected by its contents.  (Those with experience of standards
committees will recognize that the working group decided to punt on the
issue.)  Consequently, Perl takes no notice of it.  If you really want to
use LC_MONETARY, you can query its contents-see `The localeconv function'
in this node-and use the information that it returns in your application's
own formatting of currency amounts.  However, you may well find that the
information, voluminous and complex though it may be, still does not quite
meet your requirements: currency formatting is a hard nut to crack.

LC_TIME
-------

   Output produced by POSIX::strftime(), which builds a formatted
human-readable date/time string, is affected by the current LC_TIME
locale.  Thus, in a French locale, the output produced by the `%B' format
element (full month name) for the first month of the year would be
"janvier".  Here's how to get a list of long month names in the current
locale:

     use POSIX qw(strftime);
     for (0..11) {
         $long_month_name[$_] =
             strftime("%B", 0, 0, 0, 1, $_, 96);
     }

   Note: `use locale' isn't needed in this example: as a function that
exists only to generate locale-dependent results, strftime() always obeys
the current LC_TIME locale.

Other categories
----------------

   The remaining locale category, `LC_MESSAGES' (possibly supplemented by
others in particular implementations) is not currently used by Perl-except
possibly to affect the behavior of library functions called by extensions
outside the standard Perl distribution and by the operating system and its
utilities.  Note especially that the string value of $! and the error
messages given by external utilities may be changed by `LC_MESSAGES'.  If
you want to have portable error codes, use `%!'.  See *Note Errno:
(pm.info)Errno,.

SECURITY
========

   Although the main discussion of Perl security issues can be found in
*Note Perlsec: perlsec,, a discussion of Perl's locale handling would be
incomplete if it did not draw your attention to locale-dependent security
issues.  Locales-particularly on systems that allow unprivileged users to
build their own locales-are untrustworthy.  A malicious (or just plain
broken) locale can make a locale-aware application give unexpected
results.  Here are a few possibilities:

   * Regular expression checks for safe file names or mail addresses using
     `\w' may be spoofed by an LC_CTYPE locale that claims that characters
     such as ">" and "|" are alphanumeric.

   * String interpolation with case-mapping, as in, say, `$dest =
     "C:\U$name.$ext"', may produce dangerous results if a bogus LC_CTYPE
     case-mapping table is in effect.

   * Some systems are broken in that they allow the "C" locale to be
     overridden by users.  If the decimal point character in the
     LC_NUMERIC category of the "C" locale is surreptitiously changed from
     a dot to a comma, `sprintf("%g", 0.123456e3)' produces a string
     result of "123,456".  Many people would interpret this as one hundred
     and twenty-three thousand, four hundred and fifty-six.

   * A sneaky LC_COLLATE locale could result in the names of students with
     "D" grades appearing ahead of those with "A"s.

   * An application that takes the trouble to use information in
     LC_MONETARY may format debits as if they were credits and vice versa
     if that locale has been subverted.  Or it might make payments in US
     dollars instead of Hong Kong dollars.

   * The date and day names in dates formatted by strftime() could be
     manipulated to advantage by a malicious user able to subvert the
     `LC_DATE' locale.  ("Look-it says I wasn't in the building on
     Sunday.")

   Such dangers are not peculiar to the locale system: any aspect of an
application's environment which may be modified maliciously presents
similar challenges.  Similarly, they are not specific to Perl: any
programming language that allows you to write programs that take account
of their environment exposes you to these issues.

   Perl cannot protect you from all possibilities shown in the
examples-there is no substitute for your own vigilance-but, when `use
locale' is in effect, Perl uses the tainting mechanism (see *Note Perlsec:
perlsec,) to mark string results that become locale-dependent, and which
may be untrustworthy in consequence.  Here is a summary of the tainting
behavior of operators and functions that may be affected by the locale:

*Comparison operators* (lt, le, ge, gt and cmp):
     Scalar true/false (or less/equal/greater) result is never tainted.

*Case-mapping interpolation* (with `\l', `\L', `\u' or `\U')
     Result string containing interpolated material is tainted if `use
     locale' is in effect.

*Matching operator* (m//):
     Scalar true/false result never tainted.

     Subpatterns, either delivered as a list-context result or as $1 etc.
     are tainted if `use locale' is in effect, and the subpattern regular
     expression contains `\w' (to match an alphanumeric character), `\W'
     (non-alphanumeric character), `\s' (white-space character), or `\S'
     (non white-space character).  The matched-pattern variable, $&, $`
     (pre-match), $' (post-match), and $+ (last match) are also tainted if
     `use locale' is in effect and the regular expression contains `\w',
     `\W', `\s', or `\S'.

*Substitution operator* (s///):
     Has the same behavior as the match operator.  Also, the left operand
     of `=~' becomes tainted when `use locale' in effect if modified as a
     result of a substitution based on a regular expression match
     involving `\w', `\W', `\s', or `\S'; or of case-mapping with `\l',
     `\L',`\u' or `\U'.

*Output formatting functions* (printf() and write()):
     Success/failure result is never tainted.

*Case-mapping functions* (lc(), lcfirst(), uc(), ucfirst()):
     Results are tainted if `use locale' is in effect.

*POSIX locale-dependent functions* (localeconv(), strcoll(), strftime(), strxfrm()):
     Results are never tainted.

*POSIX character class tests* (isalnum(), isalpha(), isdigit(), isgraph(), islower(), isprint(), ispunct(), isspace(), isupper(), isxdigit()):
     True/false results are never tainted.

   Three examples illustrate locale-dependent tainting.  The first
program, which ignores its locale, won't run: a value taken directly from
the command line may not be used to name an output file when taint checks
are enabled.

     #/usr/local/bin/perl -T
     # Run with taint checking

     # Command line sanity check omitted...
     $tainted_output_file = shift;

     open(F, ">$tainted_output_file")
         or warn "Open of $untainted_output_file failed: $!\n";

   The program can be made to run by "laundering" the tainted value through
a regular expression: the second example-which still ignores locale
information-runs, creating the file named on its command line if it can.

     #/usr/local/bin/perl -T

     $tainted_output_file = shift;
     $tainted_output_file =~ m%[\w/]+%;
     $untainted_output_file = $&;

     open(F, ">$untainted_output_file")
         or warn "Open of $untainted_output_file failed: $!\n";

   Compare this with a similar but locale-aware program:

     #/usr/local/bin/perl -T

     $tainted_output_file = shift;
     use locale;
     $tainted_output_file =~ m%[\w/]+%;
     $localized_output_file = $&;

     open(F, ">$localized_output_file")
         or warn "Open of $localized_output_file failed: $!\n";

   This third program fails to run because $& is tainted: it is the result
of a match involving `\w' while `use locale' is in effect.

ENVIRONMENT
===========

PERL_BADLANG
     A string that can suppress Perl's warning about failed locale settings
     at startup.  Failure can occur if the locale support in the operating
     system is lacking (broken) in some way-or if you mistyped the name of
     a locale when you set up your environment.  If this environment
     variable is absent, or has a value that does not evaluate to integer
     zero-that is, "0" or ""- Perl will complain about locale setting
     failures.

     NOTE: PERL_BADLANG only gives you a way to hide the warning message.
     The message tells about some problem in your system's locale support,
     and you should investigate what the problem is.

   The following environment variables are not specific to Perl: They are
part of the standardized (ISO C, XPG4, POSIX 1.c) setlocale() method for
controlling an application's opinion on data.

LC_ALL
     LC_ALL is the "override-all" locale environment variable. If set, it
     overrides all the rest of the locale environment variables.

LANGUAGE
     NOTE: LANGUAGE is a GNU extension, it affects you only if you are
     using the GNU libc.  This is the case if you are using e.g. Linux.
     If you are using "commercial" UNIXes you are most probably not using
     GNU libc and you can ignore LANGUAGE.

     However, in the case you are using LANGUAGE: it affects the language
     of informational, warning, and error messages output by commands (in
     other words, it's like `LC_MESSAGES') but it has higher priority than
     `LC_ALL' in this node.  Moreover, it's not a single value but instead
     a "path" (":"-separated list) of languages (not locales).  See the
     GNU `gettext' library documentation for more information.

LC_CTYPE
     In the absence of LC_ALL, LC_CTYPE chooses the character type locale.
     In the absence of both LC_ALL and LC_CTYPE, LANG chooses the
     character type locale.

LC_COLLATE
     In the absence of LC_ALL, LC_COLLATE chooses the collation (sorting)
     locale.  In the absence of both LC_ALL and LC_COLLATE, LANG chooses
     the collation locale.

LC_MONETARY
     In the absence of LC_ALL, LC_MONETARY chooses the monetary formatting
     locale.  In the absence of both LC_ALL and LC_MONETARY, LANG chooses
     the monetary formatting locale.

LC_NUMERIC
     In the absence of LC_ALL, LC_NUMERIC chooses the numeric format
     locale.  In the absence of both LC_ALL and LC_NUMERIC, LANG chooses
     the numeric format.

LC_TIME
     In the absence of LC_ALL, LC_TIME chooses the date and time
     formatting locale.  In the absence of both LC_ALL and LC_TIME, LANG
     chooses the date and time formatting locale.

LANG
     LANG is the "catch-all" locale environment variable. If it is set, it
     is used as the last resort after the overall LC_ALL and the
     category-specific `LC_...'.

NOTES
=====

Backward compatibility
----------------------

   Versions of Perl prior to 5.004 *mostly* ignored locale information,
generally behaving as if something similar to the `"C"' locale were always
in force, even if the program environment suggested otherwise (see `The
setlocale function' in this node).  By default, Perl still behaves this
way for backward compatibility.  If you want a Perl application to pay
attention to locale information, you must use the `use locale' pragma (see
`The use locale pragma' in this node) to instruct it to do so.

   Versions of Perl from 5.002 to 5.003 did use the LC_CTYPE information
if available; that is, `\w' did understand what were the letters according
to the locale environment variables.  The problem was that the user had no
control over the feature: if the C library supported locales, Perl used
them.

I18N:Collate obsolete
---------------------

   In versions of Perl prior to 5.004, per-locale collation was possible
using the I18N::Collate library module.  This module is now mildly
obsolete and should be avoided in new applications.  The LC_COLLATE
functionality is now integrated into the Perl core language: One can use
locale-specific scalar data completely normally with `use locale', so
there is no longer any need to juggle with the scalar references of
I18N::Collate.

Sort speed and memory use impacts
---------------------------------

   Comparing and sorting by locale is usually slower than the default
sorting; slow-downs of two to four times have been observed.  It will also
consume more memory: once a Perl scalar variable has participated in any
string comparison or sorting operation obeying the locale collation rules,
it will take 3-15 times more memory than before.  (The exact multiplier
depends on the string's contents, the operating system and the locale.)
These downsides are dictated more by the operating system's implementation
of the locale system than by Perl.

write() and LC_NUMERIC
----------------------

   Formats are the only part of Perl that unconditionally use information
from a program's locale; if a program's environment specifies an
LC_NUMERIC locale, it is always used to specify the decimal point
character in formatted output.  Formatted output cannot be controlled by
`use locale' because the pragma is tied to the block structure of the
program, and, for historical reasons, formats exist outside that block
structure.

Freely available locale definitions
-----------------------------------

   There is a large collection of locale definitions at
`ftp://dkuug.dk/i18n/WG15-collection'.  You should be aware that it is
unsupported, and is not claimed to be fit for any purpose.  If your system
allows installation of arbitrary locales, you may find the definitions
useful as they are, or as a basis for the development of your own locales.

I18n and l10n
-------------

   "Internationalization" is often abbreviated as *i18n* because its first
and last letters are separated by eighteen others.  (You may guess why the
internalin ... internaliti ... i18n tends to get abbreviated.)  In the
same way, "localization" is often abbreviated to *l10n*.

An imperfect standard
---------------------

   Internationalization, as defined in the C and POSIX standards, can be
criticized as incomplete, ungainly, and having too large a granularity.
(Locales apply to a whole process, when it would arguably be more useful
to have them apply to a single thread, window group, or whatever.)  They
also have a tendency, like standards groups, to divide the world into
nations, when we all know that the world can equally well be divided into
bankers, bikers, gamers, and so on.  But, for now, it's the only standard
we've got.  This may be construed as a bug.

BUGS
====

Broken systems
--------------

   In certain systems, the operating system's locale support is broken and
cannot be fixed or used by Perl.  Such deficiencies can and will result in
mysterious hangs and/or Perl core dumps when the `use locale' is in
effect.  When confronted with such a system, please report in excruciating
detail to <`perlbug@perl.com'>, and complain to your vendor: bug fixes may
exist for these problems in your operating system.  Sometimes such bug
fixes are called an operating system upgrade.

SEE ALSO
========

   `POSIX (3)' in this node

   `POSIX (3)' in this node

   `POSIX (3)' in this node

   `POSIX (3)' in this node

   `POSIX (3)' in this node

   `POSIX (3)' in this node,

   `POSIX (3)' in this node

   `POSIX (3)' in this node

   `POSIX (3)' in this node,

   `POSIX (3)' in this node

   `POSIX (3)' in this node

   `POSIX (3)' in this node,

   `POSIX (3)' in this node

   `POSIX (3)' in this node

   `POSIX (3)' in this node,

   `POSIX (3)' in this node

HISTORY
=======

   Jarkko Hietaniemi's original `perli18n.pod' heavily hacked by Dominic
Dunlop, assisted by the perl5-porters.  Prose worked over a bit by Tom
Christiansen.

   Last update: Thu Jun 11 08:44:13 MDT 1998


File: perl.info,  Node: perllol,  Next: perlboot,  Prev: perldsc,  Up: Top

Manipulating Arrays of Arrays in Perl
*************************************

NAME
====

   perllol - Manipulating Arrays of Arrays in Perl

DESCRIPTION
===========

Declaration and Access of Arrays of Arrays
==========================================

   The simplest thing to build an array of arrays (sometimes imprecisely
called a list of lists).  It's reasonably easy to understand, and almost
everything that applies here will also be applicable later on with the
fancier data structures.

   An array of an array is just a regular old array @AoA that you can get
at with two subscripts, like `$AoA[3][2]'.  Here's a declaration of the
array:

     # assign to our array, an array of array references
     @AoA = (
     	   [ "fred", "barney" ],
     	   [ "george", "jane", "elroy" ],
     	   [ "homer", "marge", "bart" ],
     );

     print $AoA[2][2];
       bart

   Now you should be very careful that the outer bracket type is a round
one, that is, a parenthesis.  That's because you're assigning to an
@array, so you need parentheses.  If you wanted there not to be an @AoA,
but rather just a reference to it, you could do something more like this:

     # assign a reference to array of array references
     $ref_to_AoA = [
     	[ "fred", "barney", "pebbles", "bambam", "dino", ],
     	[ "homer", "bart", "marge", "maggie", ],
     	[ "george", "jane", "elroy", "judy", ],
     ];

     print $ref_to_AoA->[2][2];

   Notice that the outer bracket type has changed, and so our access syntax
has also changed.  That's because unlike C, in perl you can't freely
interchange arrays and references thereto.  $ref_to_AoA is a reference to
an array, whereas @AoA is an array proper.  Likewise, `$AoA[2]' is not an
array, but an array ref.  So how come you can write these:

     $AoA[2][2]
     $ref_to_AoA->[2][2]

   instead of having to write these:

     $AoA[2]->[2]
     $ref_to_AoA->[2]->[2]

   Well, that's because the rule is that on adjacent brackets only (whether
square or curly), you are free to omit the pointer dereferencing arrow.
But you cannot do so for the very first one if it's a scalar containing a
reference, which means that $ref_to_AoA always needs it.

Growing Your Own
================

   That's all well and good for declaration of a fixed data structure, but
what if you wanted to add new elements on the fly, or build it up entirely
from scratch?

   First, let's look at reading it in from a file.  This is something like
adding a row at a time.  We'll assume that there's a flat file in which
each line is a row and each word an element.  If you're trying to develop
an  @AoA array containing all these, here's the right way to do that:

     while (<>) {
     	@tmp = split;
     	push @AoA, [ @tmp ];
     }

   You might also have loaded that from a function:

     for $i ( 1 .. 10 ) {
     	$AoA[$i] = [ somefunc($i) ];
     }

   Or you might have had a temporary variable sitting around with the
array in it.

     for $i ( 1 .. 10 ) {
     	@tmp = somefunc($i);
     	$AoA[$i] = [ @tmp ];
     }

   It's very important that you make sure to use the [] array reference
constructor.  That's because this will be very wrong:

     $AoA[$i] = @tmp;

   You see, assigning a named array like that to a scalar just counts the
number of elements in @tmp, which probably isn't what you want.

   If you are running under `use strict', you'll have to add some
declarations to make it happy:

     use strict;
     my(@AoA, @tmp);
     while (<>) {
     	@tmp = split;
     	push @AoA, [ @tmp ];
     }

   Of course, you don't need the temporary array to have a name at all:

     while (<>) {
     	push @AoA, [ split ];
     }

   You also don't have to use push().  You could just make a direct
assignment if you knew where you wanted to put it:

     my (@AoA, $i, $line);
     for $i ( 0 .. 10 ) {
     	$line = <>;
     	$AoA[$i] = [ split ' ', $line ];
     }

   or even just

     my (@AoA, $i);
     for $i ( 0 .. 10 ) {
     	$AoA[$i] = [ split ' ', <> ];
     }

   You should in general be leery of using functions that could
potentially return lists in scalar context without explicitly stating
such.  This would be clearer to the casual reader:

     my (@AoA, $i);
     for $i ( 0 .. 10 ) {
     	$AoA[$i] = [ split ' ', scalar(<>) ];
     }

   If you wanted to have a $ref_to_AoA variable as a reference to an array,
you'd have to do something like this:

     while (<>) {
     	push @$ref_to_AoA, [ split ];
     }

   Now you can add new rows.  What about adding new columns?  If you're
dealing with just matrices, it's often easiest to use simple assignment:

     for $x (1 .. 10) {
     	for $y (1 .. 10) {
     	    $AoA[$x][$y] = func($x, $y);
     	}
     }

     for $x ( 3, 7, 9 ) {
     	$AoA[$x][20] += func2($x);
     }

   It doesn't matter whether those elements are already there or not:
it'll gladly create them for you, setting intervening elements to undef as
need be.

   If you wanted just to append to a row, you'd have to do something a bit
funnier looking:

     # add new columns to an existing row
     push @{ $AoA[0] }, "wilma", "betty";

   Notice that I *couldn't* say just:

     push $AoA[0], "wilma", "betty";  # WRONG!

   In fact, that wouldn't even compile.  How come?  Because the argument
to push() must be a real array, not just a reference to such.

Access and Printing
===================

   Now it's time to print your data structure out.  How are you going to
do that?  Well, if you want only one of the elements, it's trivial:

     print $AoA[0][0];

   If you want to print the whole thing, though, you can't say

     print @AoA;		# WRONG

   because you'll get just references listed, and perl will never
automatically dereference things for you.  Instead, you have to roll
yourself a loop or two.  This prints the whole structure, using the
shell-style for() construct to loop across the outer set of subscripts.

     for $aref ( @AoA ) {
     	print "\t [ @$aref ],\n";
     }

   If you wanted to keep track of subscripts, you might do this:

     for $i ( 0 .. $#AoA ) {
     	print "\t elt $i is [ @{$AoA[$i]} ],\n";
     }

   or maybe even this.  Notice the inner loop.

     for $i ( 0 .. $#AoA ) {
     	for $j ( 0 .. $#{$AoA[$i]} ) {
     	    print "elt $i $j is $AoA[$i][$j]\n";
     	}
     }

   As you can see, it's getting a bit complicated.  That's why sometimes
is easier to take a temporary on your way through:

     for $i ( 0 .. $#AoA ) {
     	$aref = $AoA[$i];
     	for $j ( 0 .. $#{$aref} ) {
     	    print "elt $i $j is $AoA[$i][$j]\n";
     	}
     }

   Hmm... that's still a bit ugly.  How about this:

     for $i ( 0 .. $#AoA ) {
     	$aref = $AoA[$i];
     	$n = @$aref - 1;
     	for $j ( 0 .. $n ) {
     	    print "elt $i $j is $AoA[$i][$j]\n";
     	}
     }

Slices
======

   If you want to get at a slice (part of a row) in a multidimensional
array, you're going to have to do some fancy subscripting.  That's because
while we have a nice synonym for single elements via the pointer arrow for
dereferencing, no such convenience exists for slices.  (Remember, of
course, that you can always write a loop to do a slice operation.)

   Here's how to do one operation using a loop.  We'll assume an @AoA
variable as before.

     @part = ();
     $x = 4;
     for ($y = 7; $y < 13; $y++) {
     	push @part, $AoA[$x][$y];
     }

   That same loop could be replaced with a slice operation:

     @part = @{ $AoA[4] } [ 7..12 ];

   but as you might well imagine, this is pretty rough on the reader.

   Ah, but what if you wanted a *two-dimensional slice*, such as having $x
run from 4..8 and $y run from 7 to 12?  Hmm... here's the simple way:

     @newAoA = ();
     for ($startx = $x = 4; $x <= 8; $x++) {
     	for ($starty = $y = 7; $y <= 12; $y++) {
     	    $newAoA[$x - $startx][$y - $starty] = $AoA[$x][$y];
     	}
     }

   We can reduce some of the looping through slices

     for ($x = 4; $x <= 8; $x++) {
     	push @newAoA, [ @{ $AoA[$x] } [ 7..12 ] ];
     }

   If you were into Schwartzian Transforms, you would probably have
selected map for that

     @newAoA = map { [ @{ $AoA[$_] } [ 7..12 ] ] } 4 .. 8;

   Although if your manager accused of seeking job security (or rapid
insecurity) through inscrutable code, it would be hard to argue. :-) If I
were you, I'd put that in a function:

     @newAoA = splice_2D( \@AoA, 4 => 8, 7 => 12 );
     sub splice_2D {
     	my $lrr = shift; 	# ref to array of array refs!
     	my ($x_lo, $x_hi,
     	    $y_lo, $y_hi) = @_;

     return map {
         [ @{ $lrr->[$_] } [ $y_lo .. $y_hi ] ]
     } $x_lo .. $x_hi;
         }

SEE ALSO
========

   perldata(1), perlref(1), perldsc(1)

AUTHOR
======

   Tom Christiansen <`tchrist@perl.com'>

   Last update: Thu Jun  4 16:16:23 MDT 1998


File: perl.info,  Node: perlmachten,  Next: perlos2,  Prev: perlhpux,  Up: Top

Perl version 5 on Power MachTen systems
***************************************

NAME
====

   README.machten - Perl version 5 on Power MachTen systems

DESCRIPTION
===========

   This document describes how to build Perl 5 on Power MachTen systems,
and discusses a few wrinkles in the implementation.

Compiling Perl 5 on MachTen
---------------------------

   To compile perl under MachTen 4.1.4 (and probably earlier versions):

     ./Configure -de
     make
     make test
     make install

   This builds and installs a statically-linked perl; MachTen's dynamic
linking facilities are not adequate to support Perl's use of dynamically
linked libraries.  (See `hints/machten.sh' for more information.)

   You should have at least 32 megabytes of free memory on your system
before running the make command.

   For much more information on building perl - for example, on how to
change the default installation directory - see INSTALL.

Failures during make test
-------------------------

op/lexassign.t
     This test may fail when first run after building perl.  It does not
     fail subsequently.  The cause is unknown.

pragma/warnings.t
     Test 257 fails due to a failure to warn about attempts to read from a
     filehandle which is a duplicate of stdout when stdout is attached to a
     pipe.  The output of the test contains a block comment which discusses
     a different failure, not applicable to MachTen.

     The root of the problem is that Machten does not assign a file type to
     either end of a pipe (see `stat' in this node), resulting, among
     other things in Perl's -p test failing on file descriptors belonging
     to pipes.  As a result, perl becomes confused, and the test for
     reading from a write-only file fails.  I am reluctant to patch perl
     to get around this, as it's clearly an OS bug (about which Tenon has
     been informed), and limited in its effect on practical Perl programs.

Using external modules
----------------------

   If warnings are enabled with Perl's -w command-line flag, you are
likely to see warnings when using external modules containing XS
(compiled) code:

     Subroutine DynaLoader::dl_error redefined at /usr/local/lib/perl5/5.6.0/powerpc-machten/DynaLoader.pm line 93.

   This is a harmless consequence of the static linking used for MachTen
perl.  You can suppress the warnings by using the more modern `-Mwarnings'
instead of the traditional -w.  (See *Note Perllexwarn: perllexwarn,.)

Building external modules
-------------------------

   To add an external module to perl, build in the normal way, which is
documented in *Note ExtUtils/MakeMaker: (pm.info)ExtUtils/MakeMaker,, or
which can be driven automatically by the CPAN module (see *Note CPAN:
(pm.info)CPAN,), which is part of the standard distribution.  If wou want
to install a module contains XS code (C or C++ source which compiles to
object code for linking with perl), you will have to replace your perl
binary with a new version containing the new statically-linked object
module.  The build process tells you how to do this.

   There is a gotcha, however, which users usually encounter immediately
they respond to CPAN's invitation to `install Bundle::CPAN'. When
installing a *bundle* - a group of modules which together achieve some
particular purpose, the installation process for later modules in the
bundle tends to assume that earlier modules have been fully installed and
are available for use.  This is not true on a statically-linked system for
earlier modules which contain XS code.  As a result the installation of
the bundle fails.  The work-around is not to install the bundle as a
one-shot operation, but instead to see what modules it contains, and
install these one-at-a-time by hand in the order given.

AUTHOR
======

   Dominic Dunlop <domo@computer.org>

DATE
====

   Version 1.0 2000-03-22


File: perl.info,  Node: perlmod,  Next: perlmodlib,  Prev: perlsub,  Up: Top

Perl modules (packages and symbol tables)
*****************************************

NAME
====

   perlmod - Perl modules (packages and symbol tables)

DESCRIPTION
===========

Packages
--------

   Perl provides a mechanism for alternative namespaces to protect
packages from stomping on each other's variables.  In fact, there's really
no such thing as a global variable in Perl .  The package statement
declares the compilation unit as being in the given namespace.  The scope
of the package declaration is from the declaration itself through the end
of the enclosing block, eval, or file, whichever comes first (the same
scope as the my() and local() operators).  Unqualified dynamic identifiers
will be in this namespace, except for those few identifiers that if
unqualified, default to the main package instead of the current one as
described below.  A package statement affects only dynamic
variables-including those you've used local() on-but not lexical variables
created with my().  Typically it would be the first declaration in a file
included by the do, require, or use operators.  You can switch into a
package in more than one place; it merely influences which symbol table is
used by the compiler for the rest of that block.  You can refer to
variables and filehandles in other packages by prefixing the identifier
with the package name and a double colon: `$Package::Variable'.  If the
package name is null, the main package is assumed.  That is, `$::sail' is
equivalent to `$main::sail'.

   The old package delimiter was a single quote, but double colon is now
the preferred delimiter, in part because it's more readable to humans, and
in part because it's more readable to emacs macros.  It also makes C++
programmers feel like they know what's going on-as opposed to using the
single quote as separator, which was there to make Ada programmers feel
like they knew what's going on.  Because the old-fashioned syntax is still
supported for backwards compatibility, if you try to use a string like
`"This is $owner's house"', you'll be accessing `$owner::s'; that is, the
$s variable in package owner, which is probably not what you meant.  Use
braces to disambiguate, as in `"This is ${owner}'s house"'.

   Packages may themselves contain package separators, as in
`$OUTER::INNER::var'.  This implies nothing about the order of name
lookups, however.  There are no relative packages: all symbols are either
local to the current package, or must be fully qualified from the outer
package name down.  For instance, there is nowhere within package `OUTER'
that `$INNER::var' refers to `$OUTER::INNER::var'.  It would treat package
`INNER' as a totally separate global package.

   Only identifiers starting with letters (or underscore) are stored in a
package's symbol table.  All other symbols are kept in package main,
including all punctuation variables, like $_.  In addition, when
unqualified, the identifiers STDIN, STDOUT, STDERR, ARGV, ARGVOUT, ENV,
INC, and SIG are forced to be in package main, even when used for other
purposes than their built-in one.  If you have a package called m, s, or
y, then you can't use the qualified form of an identifier because it would
be instead interpreted as a pattern match, a substitution, or a
transliteration.

   Variables beginning with underscore used to be forced into package
main, but we decided it was more useful for package writers to be able to
use leading underscore to indicate private variables and method names.  $_
is still global though.  See also `"Technical Note on the Syntax of
Variable Names"', *Note Perlvar: perlvar,.

   evaled strings are compiled in the package in which the eval() was
compiled.  (Assignments to `$SIG{}', however, assume the signal handler
specified is in the main package.  Qualify the signal handler name if you
wish to have a signal handler in a package.)  For an example, examine
`perldb.pl' in the Perl library.  It initially switches to the DB package
so that the debugger doesn't interfere with variables in the program you
are trying to debug.  At various points, however, it temporarily switches
back to the main package to evaluate various expressions in the context of
the main package (or wherever you came from).  See *Note Perldebug:
perldebug,.

   The special symbol __PACKAGE__ contains the current package, but cannot
(easily) be used to construct variables.

   See *Note Perlsub: perlsub, for other scoping issues related to my()
and local(), and *Note Perlref: perlref, regarding closures.

Symbol Tables
-------------

   The symbol table for a package happens to be stored in the hash of that
name with two colons appended.  The main symbol table's name is thus
`%main::', or `%::' for short.  Likewise symbol table for the nested
package mentioned earlier is named `%OUTER::INNER::'.

   The value in each entry of the hash is what you are referring to when
you use the `*name' typeglob notation.  In fact, the following have the
same effect, though the first is more efficient because it does the symbol
table lookups at compile time:

     local *main::foo    = *main::bar;
     local $main::{foo}  = $main::{bar};

   You can use this to print out all the variables in a package, for
instance.  The standard but antequated `dumpvar.pl' library and the CPAN
module Devel::Symdump make use of this.

   Assignment to a typeglob performs an aliasing operation, i.e.,

     *dick = *richard;

   causes variables, subroutines, formats, and file and directory handles
accessible via the identifier `richard' also to be accessible via the
identifier `dick'.  If you want to alias only a particular variable or
subroutine, assign a reference instead:

     *dick = \$richard;

   Which makes $richard and $dick the same variable, but leaves  @richard
and @dick as separate arrays.  Tricky, eh?

   This mechanism may be used to pass and return cheap references into or
from subroutines if you won't want to copy the whole thing.  It only works
when assigning to dynamic variables, not lexicals.

     %some_hash = ();			# can't be my()
     *some_hash = fn( \%another_hash );
     sub fn {
     	local *hashsym = shift;
     	# now use %hashsym normally, and you
     	# will affect the caller's %another_hash
     	my %nhash = (); # do what you want
     	return \%nhash;
     }

   On return, the reference will overwrite the hash slot in the symbol
table specified by the *some_hash typeglob.  This is a somewhat tricky way
of passing around references cheaply when you won't want to have to
remember to dereference variables explicitly.

   Another use of symbol tables is for making "constant" scalars.

     *PI = \3.14159265358979;

   Now you cannot alter $PI, which is probably a good thing all in all.
This isn't the same as a constant subroutine, which is subject to
optimization at compile-time.  This isn't.  A constant subroutine is one
prototyped to take no arguments and to return a constant expression.  See
*Note Perlsub: perlsub, for details on these.  The `use constant' pragma
is a convenient shorthand for these.

   You can say `*foo{PACKAGE}' and `*foo{NAME}' to find out what name and
package the *foo symbol table entry comes from.  This may be useful in a
subroutine that gets passed typeglobs as arguments:

     sub identify_typeglob {
         my $glob = shift;
         print 'You gave me ', *{$glob}{PACKAGE}, '::', *{$glob}{NAME}, "\n";
     }
     identify_typeglob *foo;
     identify_typeglob *bar::baz;

   This prints

     You gave me main::foo
     You gave me bar::baz

   The `*foo{THING}' notation can also be used to obtain references to the
individual elements of *foo, see *Note Perlref: perlref,.

   Subroutine definitions (and declarations, for that matter) need not
necessarily be situated in the package whose symbol table they occupy.
You can define a subroutine outside its package by explicitly qualifying
the name of the subroutine:

     package main;
     sub Some_package::foo { ... }   # &foo defined in Some_package

   This is just a shorthand for a typeglob assignment at compile time:

     BEGIN { *Some_package::foo = sub { ... } }

   and is not the same as writing:

     {
     	package Some_package;
     	sub foo { ... }
     }

   In the first two versions, the body of the subroutine is lexically in
the main package, not in Some_package. So something like this:

     package main;

     $Some_package::name = "fred";
     $main::name = "barney";

     sub Some_package::foo {
     	print "in ", __PACKAGE__, ": \$name is '$name'\n";
     }

     Some_package::foo();

   prints:

     in main: $name is 'barney'

   rather than:

     in Some_package: $name is 'fred'

   This also has implications for the use of the SUPER:: qualifier (see
*Note Perlobj: perlobj,).

Package Constructors and Destructors
------------------------------------

   Four special subroutines act as package constructors and destructors.
These are the BEGIN, CHECK, `INIT', and END routines.  The sub is optional
for these routines.

   A BEGIN subroutine is executed as soon as possible, that is, the moment
it is completely defined, even before the rest of the containing file is
parsed.  You may have multiple BEGIN blocks within a file-they will
execute in order of definition.  Because a BEGIN block executes
immediately, it can pull in definitions of subroutines and such from other
files in time to be visible to the rest of the file.  Once a BEGIN has
run, it is immediately undefined and any code it used is returned to
Perl's memory pool.  This means you can't ever explicitly call a BEGIN.

   An END subroutine is executed as late as possible, that is, after perl
has finished running the program and just before the interpreter is being
exited, even if it is exiting as a result of a die() function.  (But not
if it's polymorphing into another program via exec, or being blown out of
the water by a signal-you have to trap that yourself (if you can).)  You
may have multiple END blocks within a file-they will execute in reverse
order of definition; that is: last in, first out (LIFO).  END blocks are
not executed when you run perl with the -c switch.

   Inside an END subroutine, $? contains the value that the program is
going to pass to exit().  You can modify $? to change the exit value of
the program.  Beware of changing $? by accident (e.g. by running something
via system).

   Similar to BEGIN blocks, `INIT' blocks are run just before the Perl
runtime begins execution, in "first in, first out" (FIFO) order.  For
example, the code generators documented in `perlcc' in this node make use
of `INIT' blocks to initialize and resolve pointers to XSUBs.

   Similar to END blocks, CHECK blocks are run just after the Perl compile
phase ends and before the run time begins, in LIFO order.  CHECK blocks
are again useful in the Perl compiler suite to save the compiled state of
the program.

   When you use the -n and -p switches to Perl, BEGIN and END work just as
they do in *awk*, as a degenerate case.  As currently implemented (and
subject to change, since its inconvenient at best), both BEGIN and<END>
blocks are run when you use the -c switch for a compile-only syntax check,
although your main code is not.

Perl Classes
------------

   There is no special class syntax in Perl, but a package may act as a
class if it provides subroutines to act as methods.  Such a package may
also derive some of its methods from another class (package) by listing
the other package name(s) in its global @ISA array (which must be a
package global, not a lexical).

   For more on this, see *Note Perltoot: perltoot, and *Note Perlobj:
perlobj,.

Perl Modules
------------

   A module is just a set of related function in a library file a Perl
package with the same name as the file.  It is specifically designed to be
reusable by other modules or programs.  It may do this by providing a
mechanism for exporting some of its symbols into the symbol table of any
package using it.  Or it may function as a class definition and make its
semantics available implicitly through method calls on the class and its
objects, without explicitly exportating anything.  Or it can do a little
of both.

   For example, to start a traditional, non-OO module called Some::Module,
create a file called `Some/Module.pm' and start with this template:

     package Some::Module;  # assumes Some/Module.pm

     use strict;
     use warnings;

     BEGIN {
         use Exporter   ();
         our ($VERSION, @ISA, @EXPORT, @EXPORT_OK, %EXPORT_TAGS);

     # set the version for version checking
     $VERSION     = 1.00;
     # if using RCS/CVS, this may be preferred
     $VERSION = do { my @r = (q$Revision: 2.21 $ =~ /\d+/g); sprintf "%d."."%02d" x $#r, @r }; # must be all one line, for MakeMaker

     @ISA         = qw(Exporter);
     @EXPORT      = qw(&func1 &func2 &func4);
     %EXPORT_TAGS = ( );     # eg: TAG => [ qw!name1 name2! ],

     # your exported package globals go here,
     # as well as any optionally exported functions
     @EXPORT_OK   = qw($Var1 %Hashit &func3);
         }
         our @EXPORT_OK;

     # non-exported package globals go here
     our @more;
     our $stuff;

     # initialize package globals, first exported ones
     $Var1   = '';
     %Hashit = ();

     # then the others (which are still accessible as $Some::Module::stuff)
     $stuff  = '';
     @more   = ();

     # all file-scoped lexicals must be created before
     # the functions below that use them.

     # file-private lexicals go here
     my $priv_var    = '';
     my %secret_hash = ();

     # here's a file-private function as a closure,
     # callable as &$priv_func;  it cannot be prototyped.
     my $priv_func = sub {
         # stuff goes here.
     };

     # make all your functions, whether exported or not;
     # remember to put something interesting in the {} stubs
     sub func1      {}    # no prototype
     sub func2()    {}    # proto'd void
     sub func3($$)  {}    # proto'd to 2 scalars

     # this one isn't exported, but could be called!
     sub func4(\%)  {}    # proto'd to 1 hash ref

     END { }       # module clean-up code here (global destructor)

     ## YOUR CODE GOES HERE

     1;  # don't forget to return a true value from the file

   Then go on to declare and use your variables in functions without any
qualifications.  See *Note Exporter: (pm.info)Exporter, and the *Note
Perlmodlib: perlmodlib, for details on mechanics and style issues in
module creation.

   Perl modules are included into your program by saying

     use Module;

   or

     use Module LIST;

   This is exactly equivalent to

     BEGIN { require Module; import Module; }

   or

     BEGIN { require Module; import Module LIST; }

   As a special case

     use Module ();

   is exactly equivalent to

     BEGIN { require Module; }

   All Perl module files have the extension `.pm'.  The use operator
assumes this so you don't have to spell out "`Module.pm'" in quotes.  This
also helps to differentiate new modules from old `.pl' and `.ph' files.
Module names are also capitalized unless they're functioning as pragmas;
pragmas are in effect compiler directives, and are sometimes called
"pragmatic modules" (or even "pragmata" if you're a classicist).

   The two statements:

     require SomeModule;
     require "SomeModule.pm";

   differ from each other in two ways.  In the first case, any double
colons in the module name, such as Some::Module, are translated into your
system's directory separator, usually "/".   The second case does not, and
would have to be specified literally.  The other difference is that seeing
the first require clues in the compiler that uses of indirect object
notation involving "SomeModule", as in `$ob = purge SomeModule', are
method calls, not function calls.  (Yes, this really can make a
difference.)

   Because the use statement implies a BEGIN block, the importing of
semantics happens as soon as the use statement is compiled, before the
rest of the file is compiled.  This is how it is able to function as a
pragma mechanism, and also how modules are able to declare subroutines
that are then visible as list or unary operators for the rest of the
current file.  This will not work if you use require instead of use.  With
require you can get into this problem:

     require Cwd;		# make Cwd:: accessible
     $here = Cwd::getcwd();

     use Cwd;			# import names from Cwd::
     $here = getcwd();

     require Cwd;	    	# make Cwd:: accessible
     $here = getcwd(); 		# oops! no main::getcwd()

   In general, `use Module ()' is recommended over `require Module',
because it determines module availability at compile time, not in the
middle of your program's execution.  An exception would be if two modules
each tried to use each other, and each also called a function from that
other module.  In that case, it's easy to use requires instead.

   Perl packages may be nested inside other package names, so we can have
package names containing `::'.  But if we used that package name directly
as a filename it would makes for unwieldy or impossible filenames on some
systems.  Therefore, if a module's name is, say, Text::Soundex, then its
definition is actually found in the library file `Text/Soundex.pm'.

   Perl modules always have a `.pm' file, but there may also be
dynamically linked executables (often ending in `.so') or autoloaded
subroutine definitions (often ending in `.al' associated with the module.
If so, these will be entirely transparent to the user of the module.  It
is the responsibility of the `.pm' file to load (or arrange to autoload)
any additional functionality.  For example, although the POSIX module
happens to do both dynamic loading and autoloading, but the user can say
just `use POSIX' to get it all.

SEE ALSO
========

   See *Note Perlmodlib: perlmodlib, for general style issues related to
building Perl modules and classes, as well as descriptions of the standard
library and CPAN, *Note Exporter: (pm.info)Exporter, for how Perl's
standard import/export mechanism works, *Note Perltoot: perltoot, and
*Note Perltootc: perltootc, for an in-depth tutorial on creating classes,
*Note Perlobj: perlobj, for a hard-core reference document on objects,
*Note Perlsub: perlsub, for an explanation of functions and scoping, and
*Note Perlxstut: perlxstut, and *Note Perlguts: perlguts, for more
information on writing extension modules.


File: perl.info,  Node: perlmodinstall,  Next: perlform,  Prev: perlmodlib,  Up: Top

Installing CPAN Modules
***********************

NAME
====

   perlmodinstall - Installing CPAN Modules

DESCRIPTION
===========

   You can think of a module as the fundamental unit of reusable Perl
code; See *Note Perlmod: perlmod, for details.  Whenever anyone creates a
chunk of Perl code that they think will be useful to the world, they
register as a Perl developer at
http://www.perl.com/CPAN/modules/04pause.html so that they can then upload
their code to CPAN.  CPAN is the Comprehensive Perl Archive Network and
can be accessed at http://www.perl.com/CPAN/, or searched via
http://cpan.perl.com/ and
http://theory.uwinnipeg.ca/mod_perl/cpan-search.pl .

   This documentation is for people who want to download CPAN modules and
install them on their own computer.

PREAMBLE
--------

   You have a file ending in `.tar.gz' (or, less often, `.zip').  You know
there's a tasty module inside.  You must now take four steps:

DECOMPRESS the file
UNPACK the file into a directory
BUILD the module (sometimes unnecessary)
INSTALL the module.
   Here's how to perform each step for each operating system.  This is not
a substitute for reading the README and INSTALL files that might have come
with your module!

   Also note that these instructions are tailored for installing the
module into your system's repository of Perl modules.  But you can install
modules into any directory you wish.  For instance, where I say `perl
Makefile.PL', you can substitute `perl Makefile.PL
PREFIX=/my/perl_directory' to install the modules into
`/my/perl_directory'.  Then you can use the modules from your Perl
programs with `use lib "/my/perl_directory/lib/site_perl"' or sometimes
just `use "/my/perl_directory"'.

   * *If you're on Unix,*

     You can use Andreas Koenig's CPAN module (which comes standard with
     Perl, or can itself be downloaded from
     http://www.perl.com/CPAN/modules/by-module/CPAN) to automate the
     following steps, from DECOMPRESS through INSTALL.

     A. DECOMPRESS

     Decompress the file with `gzip -d yourmodule.tar.gz'

     You can get gzip from ftp://prep.ai.mit.edu/pub/gnu.

     Or, you can combine this step with the next to save disk space:

          gzip -dc yourmodule.tar.gz | tar -xof -

     B. UNPACK

     Unpack the result with `tar -xof yourmodule.tar'

     C. BUILD

     Go into the newly-created directory and type:

          perl Makefile.PL
          make
          make test

     D. INSTALL

     While still in that directory, type:

          make install

     Make sure you have appropriate permissions to install the module in
     your Perl 5 library directory.  Often, you'll need to be root.

     Perl maintains a record of all module installations.  To look at this
     list, simply type:

          perldoc perllocal

     That's all you need to do on Unix systems with dynamic linking.  Most
     Unix systems have dynamic linking-if yours doesn't, or if for another
     reason you have a statically-linked perl, and the module requires
     compilation, you'll need to build a new Perl binary that includes the
     module.  Again, you'll probably need to be root.

   * *If you're running Windows 95 or NT with the ActiveState port of Perl*

          A. DECOMPRESS

     You can use the shareware *Winzip* program ( http://www.winzip.com )
     to decompress and unpack modules.

          B. UNPACK

     If you used WinZip, this was already done for you.

          C. BUILD

     Does the module require compilation (i.e. does it have files that end
     in .xs, .c, .h, .y, .cc, .cxx, or .C)?  If it does, you're on your
     own.  You can try compiling it yourself if you have a C compiler.  If
     you're successful, consider uploading the resulting binary to CPAN
     for others to use.  If it doesn't, go to INSTALL.

          D. INSTALL

     Copy the module into your Perl's lib directory.  That'll be one of
     the directories you see when you type

          perl -e 'print "@INC"'

   * *If you're running Windows 95 or NT with the core Windows
     distribution of Perl,*

          A. DECOMPRESS

     When you download the module, make sure it ends in either `.tar.gz'
     or `.zip'.  Windows browsers sometimes download `.tar.gz' files as
     `_tar.tar', because early versions of Windows prohibited more than
     one dot in a filename.

     You can use the shareware *WinZip* program ( http://www.winzip.com )
     to decompress and unpack modules.

     Or, you can use InfoZip's unzip utility (
     http://www.cdrom.com/pub/infozip/ ) to uncompress `.zip' files; type
     `unzip yourmodule.zip' in your shell.

     Or, if you have a working `tar' and `gzip', you can type

          gzip -cd yourmodule.tar.gz | tar xvf -

     in the shell to decompress `yourmodule.tar.gz'.  This will UNPACK
     your module as well.

          B. UNPACK

     The methods in DECOMPRESS will have done this for you.

          C. BUILD

     Go into the newly-created directory and type:

          perl Makefile.PL
          dmake
          dmake test

     Depending on your perl configuration, `dmake' might not be available.
     You might have to substitute whatever `perl -V:make' says. (Usually,
     that will be `nmake' or make.)

          D. INSTALL

     While still in that directory, type:

          dmake install

   * *If you're using a Macintosh,*

     A. DECOMPRESS

     In general, all Macintosh decompression utilities mentioned here can
     be found in the Info-Mac Hyperarchive (
     http://hyperarchive.lcs.mit.edu/HyperArchive.html ).  Specificly the
     "Commpress & Translate" listing (







     http://hyperarchive.lcs.mit.edu/HyperArchive/Abstracts/cmp/HyperArchive.html
     ).

     You can either use the shareware *StuffIt Expander* program (
     http://www.aladdinsys.com/expander/ ) in combination with *DropStuff
     with Expander Enhancer* ( http://www.aladdinsys.com/dropstuff/ ) or
     the freeware *MacGzip* program (
     http://persephone.cps.unizar.es/general/gente/spd/gzip/gzip.html ).

     B. UNPACK

     If you're using DropStuff or Stuffit, you can just extract the tar
     archive.  Otherwise, you can use the freeware *suntar* or Tar (
     http://hyperarchive.lcs.mit.edu/HyperArchive/Archive/cmp/ ).

     C. BUILD

     Does the module require compilation?

     1. If it does,

     Overview: You need MPW and a combination of new and old CodeWarrior
     compilers for MPW and libraries.  Makefiles created for building under
     MPW use Metrowerks compilers.  It's most likely possible to build
     without other compilers, but it has not been done successfully, to our
     knowledge.  Read the documentation in *MacPerl: Power and Ease* (
     http://www.ptf.com/macperl/ ) on porting/building extensions, or find
     an existing precompiled binary, or hire someone to build it for you.

     Or, ask someone on the mac-perl mailing list (mac-perl@iis.ee.ethz.ch)
     to build it for you.  To subscribe to the mac-perl mailing list, send
     mail to mac-perl-request@iis.ee.ethz.ch.

     2. If the module doesn't require compilation, go to INSTALL.

     D. INSTALL

     Make sure the newlines for the modules are in Mac format, not Unix
     format.  If they are not then you might have decompressed them
     incorrectly.  Check your decompression and unpacking utilities
     settings to make sure they are translating text files properly.

     As a last resort, you can use the perl one-liner:

          perl -i.bak -pe 's/(?:\015)?\012/\015/g' <filenames>

     on the source files.

     Move the files manually into the correct folders.

     Move the files to their final destination: This will most likely be
     in `$ENV{MACPERL}site_lib:' (i.e., `HD:MacPerl folder:site_lib:').
     You can add new paths to the default `@INC' in the Preferences menu
     item in the MacPerl application (`$ENV{MACPERL}site_lib:' is added
     automagically).  Create whatever directory structures are required
     (i.e., for Some::Module, create `$ENV{MACPERL}site_lib:Some:' and put
     `Module.pm' in that directory).

     Run the following script (or something like it):

          #!perl -w
          use AutoSplit;
          my $dir = "${MACPERL}site_perl";
          autosplit("$dir:Some:Module.pm", "$dir:auto", 0, 1, 1);

     Eventually there should be a way to automate the installation
     process; some solutions exist, but none are ready for the general
     public yet.

   * *If you're on the DJGPP port of DOS,*

          A. DECOMPRESS

     djtarx ( ftp://ftp.simtel.net/pub/simtelnet/gnu/djgpp/v2/ ) will both
     uncompress and unpack.

          B. UNPACK

     See above.

          C. BUILD

     Go into the newly-created directory and type:

          perl Makefile.PL
          make
          make test

     You will need the packages mentioned in `README.dos' in the Perl
     distribution.

          D. INSTALL

     While still in that directory, type:

          make install

     You will need the packages mentioned in `README.dos' in the Perl
     distribution.

   * *If you're on OS/2,*

     Get the EMX development suite and gzip/tar, from either Hobbes (
     http://hobbes.nmsu.edu ) or Leo ( http://www.leo.org ), and then
     follow the instructions for Unix.

   * *If you're on VMS,*

     When downloading from CPAN, save your file with a `.tgz' extension
     instead of `.tar.gz'.  All other periods in the filename should be
     replaced with underscores.  For example, `Your-Module-1.33.tar.gz'
     should be downloaded as `Your-Module-1_33.tgz'.

     A. DECOMPRESS

     Type

          gzip -d Your-Module.tgz

     or, for zipped modules, type

          unzip Your-Module.zip

     Executables for gzip, zip, and VMStar ( Alphas:
     http://www.openvms.digital.com/freeware/000TOOLS/ALPHA/ and Vaxen:
     http://www.openvms.digital.com/freeware/000TOOLS/VAX/ ).

     gzip and tar are also available at ftp://ftp.digital.com/pub/VMS.

     Note that GNU's gzip/gunzip is not the same as Info-ZIP's zip/unzip
     package.  The former is a simple compression tool; the latter permits
     creation of multi-file archives.

     B. UNPACK

     If you're using VMStar:

          VMStar xf Your-Module.tar

     Or, if you're fond of VMS command syntax:

          tar/extract/verbose Your_Module.tar

     C. BUILD

     Make sure you have MMS (from Digital) or the freeware MMK ( available
     from MadGoat at  http://www.madgoat.com ).  Then type this to create
     the DESCRIP.MMS for the module:

          perl Makefile.PL

     Now you're ready to build:

          mms
          mms test

     Substitute `mmk' for `mms' above if you're using MMK.

     D. INSTALL

     Type

          mms install

     Substitute `mmk' for `mms' above if you're using MMK.

   * *If you're on MVS*,

     Introduce the `.tar.gz' file into an HFS as binary; don't translate
     from ASCII to EBCDIC.

     A. DECOMPRESS

          Decompress the file with C<gzip -d yourmodule.tar.gz>

          You can get gzip from
          http://www.s390.ibm.com/products/oe/bpxqp1.html.

     B. UNPACK

     Unpack the result with

          pax -o to=IBM-1047,from=ISO8859-1 -r < yourmodule.tar

     The BUILD and INSTALL steps are identical to those for Unix.  Some
     modules generate Makefiles that work better with GNU make, which is
     available from http://www.mks.com/s390/gnu/index.htm.

HEY
===

   If you have any suggested changes for this page, let me know.  Please
don't send me mail asking for help on how to install your modules.  There
are too many modules, and too few Orwants, for me to be able to answer or
even acknowledge all your questions.  Contact the module author instead,
or post to comp.lang.perl.modules, or ask someone familiar with Perl on
your operating system.

AUTHOR
======

   Jon Orwant

   orwant@tpj.com

   The Perl Journal, http://tpj.com

   with invaluable help from Brandon Allbery, Charles Bailey, Graham Barr,
Dominic Dunlop, Jarkko Hietaniemi, Ben Holzman, Tom Horsley, Nick
Ing-Simmons, Tuomas J. Lukka, Laszlo Molnar, Chris Nandor, Alan Olsen,
Peter Prymmer, Gurusamy Sarathy, Christoph Spalinger, Dan Sugalski, Larry
Virden, and Ilya Zakharevich.

   July 22, 1998

COPYRIGHT
=========

   Copyright (C) 1998 Jon Orwant.  All Rights Reserved.

   Permission is granted to make and distribute verbatim copies of this
documentation provided the copyright notice and this permission notice are
preserved on all copies.

   Permission is granted to copy and distribute modified versions of this
documentation under the conditions for verbatim copying, provided also
that they are marked clearly as modified versions, that the authors' names
and title are unchanged (though subtitles and additional authors' names
may be added), and that the entire resulting derived work is distributed
under the terms of a permission notice identical to this one.

   Permission is granted to copy and distribute translations of this
documentation into another language, under the above conditions for
modified versions.


