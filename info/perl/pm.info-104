This is Info file pm.info, produced by Makeinfo version 1.68 from the
input file bigpm.texi.


File: pm.info,  Node: Convert/Context,  Next: Convert/Cyrillic,  Prev: Convert/BinHex,  Up: Module List

an Attributed Text data type
****************************

NAME
====

   Convert::Context - an Attributed Text data type

   - ALPHA - release

   $Revision: 1.77 $ $Date: 1998/10/03 22:21:23 $

SYNOPSIS
========

   See below.

DESCRIPTION
===========

   Convert::Context maintains attributed strings. It allows you to access
those strings similar to perl's normal strings.

   An attributed string is a string to that attributes are connected at
certain string positions. An attribute can be everything scalar: numbers,
strings, references are welcome. Attributes are not part of the string.
Semantics of the attributes have to be done by the applying code.

   What does this mean?

   A basic work for a text system is to localize a certain text part. This
is trivial if you have only plain text to look at. It is no longer
trivial, if you have attributes or entries among your text like: bold,
italic, bookmarks and so on. One has two strategies to mingle attributes
with a string:

  1. You can enrich the text by inserting control codes. E.g., if you have
     a line with two bold words:

     (A) "The word bold is always bold"

     it would look (here with HTML controls) like:

     (B) "The word <b>bold</b> is always <b>bold</b>"

     If you would look for the text "bold is" in (B) with perls m//
     operator, you'd fail. You would have to strip the HTML control
     sequences first. This is an ok method, but not used here.

  2. You can maintain separate lists, holding at which position of the text
     which control codes are stored. This is, what Convert::Context does.
     The example from above would look like:

          offset    0---------1---------2-------
          text      The word bold is always bold
          attrib   (0        1   0          1   )

     Internally this is stored as:

          $Context = {
             "T" => \("The word bold is always bold"),
             "A" => [0, 1,  0,  1]
             "O" => [0, 9, 13, 24],
          }

     The maintainance of these lists is a little bit tricky, so what a
     luck, that you don't need to care about this.

        Do not rely on this internal representation, as it might change.
E.g. it could happen, that "O" in future stores relative offsets instead
of absolute.

   *Available Methods*

acmp
     *sub { $Code }* = *$Ct* -> acmp (*sub { $Code }*)

     When two attribs shall be compared, this normally is done stringwise,
     using function "cmp". If this is not practical for you, with acmp you
     could provide a new compare function, similar to the way you do when
     using sort.

     The standard behavior is implemented this way:

          $Ct -> acmp (sub { $_[0] cmp $_[1] })

     Note: The code provided via acmp is not used when comparing identity.
     That means: *$Ct1* -> eq (*$Ct1*) is always true.

append
     *$Ct1* = *$Ct1* -> append (*$Ct2*||*$str2*||*$strR2*, ...)

     Appends all strings, string references or Contexts to the end of
     Context1.

attrib
     Attrib is used to yield and change the attributes of a Context. It can
     be called several ways.

     (1) *$attrib* = *$Ct* -> attrib (*$pos* [,*[$attrib]*])

     When called in a scalar context with only *$pos* as parameter, attrib
     returns the attribute of Context at character position *$pos*. You can
     can set the attribute by specifying the new one as a list reference
     (not recommended).

     (2) (*[@attrib]*, *[@offset]*) = *$Ct* -> attrib (*$pos*, *$len*)

     When called in an array context, a list with references to a free
     usable attrib array and a free usable offset array is returned.

     (3) *$attrib* = *$Ct* -> attrib (*$pos*, *$len*, *$attrib*)

     When called in a scalar context with three parameters and *$attrib* is
     scalar, the attributes of Context Ct starting at position *$pos* with
     length *$len* will be set to *$attrib*.

     (4) 1||undef = *$Ct* -> attrib (*$o1*, $l1, *[@attrib]*, *[@offset]*)

     Substitutes attributes of Context Ct from position o1 and length l1
     with attributes *[@attrib]* according to offsets *[@offset]*.

     (5) 1||undef = *$Ct* -> attrib (*$o1*, $l1, *[@attrib]*, *[@offset]*,
     *$o2*, $l2)

     Like (4), but *@attrib* and *@offset* are reduced according to offset
     *$o2* and length $l2.

     (6) 1||undef = *$Ct1* -> attrib (*$o1*, $l1, *$Ct2*)

     Substitutes attributes of Context *$Ct1* from position *$o1* and
     length $l1 with attributes of Context *Ct2* from position 0 to
     position $l1.

     Note: Attrib does not care for the length of *$Ct2*!

     (7) 1||undef = *$Ct1* -> attrib (*$o1*, $l1, *$Ct2* [,*$o2*, $l2])

     Like (6), but only the part of *$Ct2* from position *$o2* with a
     length $l2 is used.

charsize
     *$Ct* = *$Ct* -> charsize ([*$bytesize_of_one_char*])

     Returns the character size of Context Ct. The character size is the
     size of one character measured in bytes. If parameter bytesize is
     given, Context Ct additionally is converted to a Context with the new
     character size bytesize.

chunks
     [ [*$str1*, *$attr1*], [*$str2*, *$attr2*], ... ] = *$Ct* -> chunks ()

     Until now this is the only way to traverse a Context by it's different
     attributes. You would use it like:

          for ( @{$Ct1->chunks()} ) {
             my ($text, $attrib) = @{$_};
             if ($attrib) {
                # do something (text has attribute $attrib)
             } else {
                # do something (text has default attribute)
             }
          }

clone
     *$Ct2* = *$Ct1* -> clone

     Returns a 1:1 copy of Context Ct1 as new Context Ct2.

dump
     *$Ct* = *$Ct* -> dump

     For debugging purposes. Dumps the Context structure to stdout.

eq
     1||0 = *$Ct1* -> eq (*$Ct2*)

     Returns 1, if Context1 is equal to Context2, returns 0 otherwise.

index
     *$pos* = *$Ct* -> index ($string [,*$pos*])

     Analogue to perls index. (see "man perlfunc")

join
     *$Ct* = Convert::Context -> join ($expr, *$Ct1*||*$str1*||*$strR1*,
     ...)

     Concatenates all strings (scalar or reference) or Contexts with
     delimitor $expr, returns a new build Context.

     *$Ct1* = *$Ct1* -> join (*$Ct2*||*$str2*||*$strR2*, ...)

     Like above, but modifies *$Ct1* instead of creating a new Context.

lc
     *$Ct2* = *$Ct1* -> lc

     Like perls lc. Returns a lowercased version of Context1 as Context2.

lcfirst
     *$Ct2* = *$Ct1* -> lcfirst

     Like perls lcfirst. Returns a version of Context1 with a lowercased
     first character as Context2.

length
     $length = *$Ct* -> length

     Returns the length of Context Ct. This is the length of the text part
     of Ct, measured in characters.

ne
     1||0 = *$Ct1* -> ne (*$Ct2*)

     Returns 1, if Context1 is different from Context2, returns 0
     otherwise.

new
     *$Ct* = Convert::Context -> new ([*$cs*])

     *$Ct* = Convert::Context -> new ([*$cs*,] *\$txt* [,*[@a]*, *[@o]*])

     *$Ct* = Convert::Context -> new ([*$cs*,] [*\$txt* [,*[@a]*, *[@o]*]],
     [...], ...)

     Returns a new Context string. It can be initialized three ways: (1)
     Without parameters, (2) with a reference to a text string, an attrib
     list reference and an offset list reference, or (3) with a list of
     references of (2).

     Optionally it can be initialized with a leading parameter *$cs*. This
     stands for "character length" and specifies the byte size of one
     character.  One needs this when using e.g. UTF16 (Unicode) characters.

     Example:

          (1)
            $Empty = Convert::Context -> new;

          (2)
            $Plain = Convert::Context -> new (\("Plain text\n"));
            $Bold  = Convert::Context -> new (\("Attribute 1 text"), [1]);

          (3)
            Special (but useful) case:
            $Mixed = Convert::Context -> new (
               [\("This is an "),                         [0] ],
               [\("all bold"),                          [122] ],
               [\(", short and sometimes ")                   ],
               [\("italic"),       ["Strange text attribute"] ],
               [\(" text."                                    ]
            ;

     Attribute 0 and Offset 0 is used as default value, if none is
     explicitly given. The meaning of all attributes (here 0, 122 and
     "Strange text attribute") has to be defined 100% by the applying code.
     In this example one would assume, that a text processor was connoting
     the attributes 0, 122 and "Strange text attribute" to the semantics:
     plain, bold and italic.

replace
     $n = *$Ct* -> replace (*$pattern*, *$replace*, `egimosx')

     Replaces one or all occurrances matching to *$pattern* with
     *$replace*.  Returns the number of replacements, or false if pattern
     is not found.  Implemented mainly via perls replace operator:

          s/$pattern/$replace/egimosx

     *$replace* here can be a string, a Context or a code reference. In the
     latter case this routine will be called at each match, passing the
     matched string as parameter. The matched text will then be replaced
     with the return value of the routine.

     $n = *$Ct* -> replace (*[@pattern]*, *[@replace]*, `egimosx')

     You can call replace with list references holding corresponding sets
     of patterns and replacements. pattern and replace can be strings or
     Contexts, and replace additionally code references. The patterns will
     be glued together to a single pattern match, using pattern match or
     operator |.

     Examples:

          (1) $Ct -> replace ("krims", "kram", "g")

     Option g says, that not only one, but all occurrances of string
     "krims" shall be substituted by string "kram".  "kram" will get the
     attributes of "krims" (see method "substr"). If you want to have more
     control about the attributes of "kram", you can pass the replacement
     string as a Context.

          (2) $Ct -> replace ("krims", $Ct, "g")

     Replaces all occurrances of string "krims" with the Context $Ct. This
     is useful, if you want to have $Ct special attributes.

          (3) $Ct -> replace (" asta tu ", " AStA TU ", "ig")

     Option i says, that the characters case shall be ignored. So example
     (3) would replace " asta tu ", " ASTA TU ", " Asta Tu " ... with "
     AStA TU ".  (AStA stands for Allgemeiner Studierendenausschuß.
     Students governments are called like this in Germany and quite cool).

          (4) $Ct -> replace ("\02", \&footnote, "g")

     This would call a function "footnote". The function will be called
     with three parameters:

          &function($match, $Ct, $pos)

          1. The matched string (here "\02")
          2. The Context        (here $Ct)
          3. The match position

          (5) $Ct -> replace ("krims", sub {allow (@_, "kram")}, "ig")

     This notation would call a function "allow" for each match, quite like
     (4). But further more here the string "kram" would be passed as
     additional parameter.

          (6) $Ct -> replace (["a", "o"], ["o", "a"], "g")

     Substitutes a's with o's and o's with a's.

rindex
     *$pos* = *$Ct* -> rindex ($string [,*$pos*])

     Analogue to perls rindex. (try "man perlfunc")

split
     *@Ct* = *$Ct* -> split (*$pattern* [$option [,*$limit*]])

     Similar to perls split. Splits a Context according to string or
     Context delimitor *$pattern*. Returns an array of Contexts. If
     *$limit* is given, returns only that many elements. *$pattern* and
     $option are to be used according to perls
     s/*$pattern*/something/`egimosx' operator (but option "g" here is
     always set).

substr
     *$Ct2* = *$Ct1* -> substr (*$o1*, $l1)

     Returns a partial Context of Ct1 as new Context Ct2. Ct2 will be
     copied from Ct1 starting at position o1 and with the length l1.

     *$Ct*  = *$Ct*  -> substr (*$o1*, $l1, $str [,*$o2*, $l2])

     If a string is given as argument, the partial Context starting at
     offset o1 with length l1 is substituted by string. String gets the
     attributes of the partial Context. If e.g. the string to be replaced
     would be "<0>di<1>n<2>g<0>s", after the replacement it might look like
     "<0>bu<1>m<2>s".

     *$Ct1* = *$Ct1* -> substr (*$o1*, $l1, *$Ct2* [,*$o2*, $l2])

     The partial Context of Ct1 starting at offset o1 with length l2 is
     substituted by Context Ct2.

     If o<n> is undef, o<n> is set to 0.

     If l<n> is undef, l<n> is set according to end of Ct<n>

text
     *\$text* = *$Ct* -> text

     Returns a reference to the text section of Context Ct.

tr
     Synonyme for y. (see below)

uc
     *$Ct2* = *$Ct1* -> uc

     Like perls uc. Returns an uppercased version of Context Ct1 as
     Context Ct2.

ucfirst
     *$Ct2* = *$Ct1* -> ucfirst

     Like perls ucfirst. Returns a version of Context Ct1 with an
     uppercased first character as Context Ct2.

y
     y can be called three ways.

     (1) *$Ct* -> y (*$search*, *$replace*, cds)

     If charsize of *$Ct* is 1, y behaves quite like perls y. Each
     character of string *$search* is replaced by the corresponding
     character of *$replace*.

     (2) *$Ct* -> y (*$search*, *$replace*, `egimosx')

     If charsize of *$Ct* is bigger than 1, y breaks the strings *$search*
     and *$replace* into substrings, each charsize bytes long. These
     corresponding strings are then passed to method replace,
     automatically with option "g".  Note, that thus internally perls tr
     operator is not used.

     (3) *$Ct* -> y (*[@search]*, *[@replace]*, `egimosx')

     This actually just calls method replace with option "g". *@search* and
     *@replace* can be Contexts or strings, just like you want. *@replace*
     can also be code references.

ERRORS
======

   - I just found that split with parameter *$limit* behaves not like perls
 split. Will be done.

TO DO
=====

   - Speeding up

   - When programming this a long time ago I was very fond of references.
 Today this seems quite odd to me sometimes. So there might happen a
major redesign sooner or later.

   - The only real way to traverse a Context is still method "chunks()".
There need to be some enhancements.

   - Support for a hash parameter style for calling methods?

   - Support for overloaded operators?

AUTHOR
======

   Martin Schwartz <`schwartz@cs.tu-berlin.de'>.


File: pm.info,  Node: Convert/Cyrillic,  Next: Convert/EBCDIC,  Prev: Convert/Context,  Up: Module List

Routines for converting from one cyrillic charset to another.
*************************************************************

NAME
====

   Convert::Cyrillic v1.01 - Routines for converting from one cyrillic
charset to another.

SYNOPSIS
========

     use Convert::Cyrillic;

     $src = 'koi8';
     $dst = 'win';
     $SrcBuf = 'text in koi8 here';
     $DstBuf = Convert::Cyrillic::cstocs ($Src, $Dst, $SrcBuf);

DESCRIPTION
===========

   This package implements routine for converting from one cyrillic
charset to another. It is intended to be used from cgi's which need
built-in support for translations. For example, you may wish to use it in
form processor to translate from user encoding to one used by your site.

   Where *$Src* and *$Dst* are one of:

     KOI8 - for KOI8-R
     WIN - for WIN-1251
     DOS - for DOS, alternative, CP-866
     MAC - for Macintosh
     ISO - for ISO-8859-5
     UTF-8 - for UTF-8 (Unicode)
     VOL - for Volapuk (transliteration)

   Buffer may contain line breaks, which are preserved.

NOTES
=====

   Part of "WWW Cyrillic Encoding Suite" Get docs and newest version from
http://www.neystadt.org/cyrillic/

   Copyright (c) 1997-98, John Neystadt <http://www.neystadt.org/john/>
You may install this script on your web site for free.  To obtain
permision for redistribution or any other usage contact john@neystadt.org.

   Drop me a line if you deploy this script on your site.

AUTHOR
======

   John Neystadt <john@neystadt.org>

SEE ALSO
========

   perl(1), Lingua::DetectCharset(3).


File: pm.info,  Node: Convert/EBCDIC,  Next: Convert/Ethiopic,  Prev: Convert/Cyrillic,  Up: Module List

Perl module for string conversion between EBCDIC and ASCII
**********************************************************

NAME
====

   Convert::EBCDIC, ascii2ebcdic, ebcdic2ascii - Perl module for string
conversion between EBCDIC and ASCII

SYNOPSIS
========

     use Convert::EBCDIC;
     $ascii_string = ebcdic2ascii($ebcdic_string);
     $ebcdic_string = ascci2ebcdic($ascii_string);

     $translator = new Convert::EBCDIC;
     $translator = new Convert::EBCDIC($table);
     $ascii_string = $translator->toascii($ebcdic_string);
     $ebcdic_string = $translator->toebcdic($ascii_string);

     $Convert::EBCDIC::ccsid819

DESCRIPTION
===========

   This module can be used to import then functions ascii2ebcdic and/or
ebcdic2ascii or in an Object mode.

   Exported Functions:

ascii2ebcdic()
     takes as the first argument a EBCDIC string that is to be converted
     to ASCII using default converion table.

ebcdic2ascii()
     takes as the first argument a ASCII string that is to be converted to
     EBCDIC using default converion table.

   Object methods:

new()
     creates a new translator object.  Will take an optional argument
     being a 256 character conversion table.

toascii()
     takes and ASCII string and return and EBCDIC string.

toebcdic()
     takes and EBCDIC string and return and ASCII string.

   Translation tables:

$Convert::EBCDIC::ccsid819
     Character Code Set ID 00819.  This is the default on most systems.

$Convert::EBCDIC::ccsid1047
     Character Code Set ID 01047.  This is the default on OS390.

PORTABILITY
===========

   This module should work on any system with Perl 5.  Tested under SPARC
Solaris, OS390, HP-UX AS400/OS400 RISC.

AUTHOR
======

   Chris Leach <leachcj@bp.com>.


File: pm.info,  Node: Convert/Ethiopic,  Next: Convert/Ethiopic/Cstocs,  Prev: Convert/EBCDIC,  Up: Module List

Perl extension for the Ethiopic information processing library.
***************************************************************

NAME
====

   Ethiopic - Perl extension for the Ethiopic information processing
library.

SYNOPSIS
========

     use Convert::Ethiopic;

DESCRIPTION
===========

   Convert::Ethiopic.pm is an interface to the LibEth Ethiopic programmers
library.

   Convert::Ethiopic.pm is not a comprehensive interface to the LibEth
library.  The LibEth Perl module is the minimal interface required by the
"Zobel" implementation of the LiveGe'ez Remote Processing Protocol.

STATUS
======

   This is the third release of the LibEth Perl module and requires the
"LibEth" library version 0.35c or later.

   The LibEth Perl Module is very early in its life cycle, extensions will
be made to further utilize the LibEth library through Perl as the need
arises.

BUGS
====

   None known at this time.

AUTHOR
======

   Daniel Yacob,
`LibEth@EthiopiaOnline.Net|mailto:LibEth@EthiopiaOnline.Net' in this node

SEE ALSO
========

   perl(1).  `http:' in this node


File: pm.info,  Node: Convert/Ethiopic/Cstocs,  Next: Convert/Ethiopic/System,  Prev: Convert/Ethiopic,  Up: Module List

conversions of charset encodings for Ethiopic script
****************************************************

NAME
====

   Ethiopic::Cstocs - conversions of charset encodings for Ethiopic script

SYNOPSIS
========

     use LiveGeez::Request;
     require Convert::Ethiopic::Cstocs;
     my $r = LiveGeez::Request->new;

     ReadParse ( \%input );
     $r->ParseInput ( \%input );

     my $c = Convert::Ethiopic::Cstocs->new ( $r );

     print &$c ("`selam:");
     print $c->conv("`alem"), "\n";

     $r->{number} = 1991;

     print "The Year in Ethiopia is ", EthiopicNumber ( $r ), "\n";

DESCRIPTION
===========

   Ethiopic::Cstocs and Ethiopic::Time are designed as interfaces to the
methods in the Ethiopic:: module and is oriented as services for the
LiveGeez:: module.  In this version Ethiopic::Cstocs expects to receive an
object with hash elements using the keys:

   'sysInNum', 'xferInNum', 'sysOutNum', 'xferOutNum', 'fontOutNum',
'langNum', 'iPath', 'options', '7-bit', and 'number' if a numeral system
conversion is being performed.

   These keys are set when using a LiveGeez::Request object as shown in
the example.

AUTHOR
======

   Daniel Yacob,
`LibEth@EthiopiaOnline.Net|mailto:LibEth@EthiopiaOnline.Net' in this node

SEE ALSO
========

   perl(1).  LiveGeez(3).  `http:' in this node


File: pm.info,  Node: Convert/Ethiopic/System,  Next: Convert/Ethiopic/Time,  Prev: Convert/Ethiopic/Cstocs,  Up: Module List

conversions of charset encodings for Ethiopic script
****************************************************

NAME
====

   Ethiopic::System - conversions of charset encodings for Ethiopic script

SYNOPSIS
========

     use LiveGeez::Request;
     require Convert::Ethiopic::Cstocs;
     my $r = LiveGeez::Request->new;

     ReadParse ( \%input );
     $r->ParseInput ( \%input );

     my $c = Convert::Ethiopic::Cstocs->new ( $r );

     print &$c ("`selam:");
     print $c->conv("`alem"), "\n";

     $r->{number} = 1991;

     print "The Year in Ethiopia is ", EthiopicNumber ( $r ), "\n";

DESCRIPTION
===========

   Ethiopic::Cstocs and Ethiopic::Time are designed as interfaces to the
methods in the Ethiopic:: module and is oriented as services for the
LiveGeez:: module.  In this version Ethiopic::Cstocs expects to receive an
object with hash elements using the keys:

   'sysInNum', 'xferInNum', 'sysOutNum', 'xferOutNum', 'fontOutNum',
'langNum', 'iPath', 'options', '7-bit', and 'number' if a numeral system
conversion is being performed.

   These keys are set when using a LiveGeez::Request object as shown in
the example.

AUTHOR
======

   Daniel Yacob,
`LibEth@EthiopiaOnline.Net|mailto:LibEth@EthiopiaOnline.Net' in this node

SEE ALSO
========

   perl(1).  LiveGeez(3).  `http:' in this node


File: pm.info,  Node: Convert/Ethiopic/Time,  Next: Convert/GeekCode,  Prev: Convert/Ethiopic/System,  Up: Module List

conversions of calendar systems to/from Ethiopic and Gregorian.
***************************************************************

NAME
====

   Ethiopic::Time - conversions of calendar systems to/from Ethiopic and
Gregorian.

SYNOPSIS
========

     use LiveGeez::Request;
     require Convert::Ethiopic::Time;
     my $r = LiveGeez::Request->new;

     ReadParse ( \%input );
     $r->ParseInput ( \%input );

     my $t = Convert::Ethiopic::Time->new ( $r );

     $t->GregorianToEthiopic;

     print "$t->{euDay}/$t->{euMonth}/$t->{euYear} = ";
     print "$t->{etDay}/$t->{etMonth}/$t->{etYear}\n"

DESCRIPTION
===========

   Ethiopic::Time and Ethiopic::Cstocs are designed as interfaces to the
methods in the Ethiopic:: module and is oriented as services for the
LiveGeez:: module.  In this version Ethiopic::Time expects to receive an
object with hash elements using the keys:

'calIn'
     which can be "euro or "ethio".

'date'
     a comma separated list as "day,month,year".

'LCInfo'
     locale settings *see the LibEth man pages*.

   These keys are set when using a LiveGeez::Request object as shown in
the example.

AUTHOR
======

   Daniel Yacob,
`LibEth@EthiopiaOnline.Net|mailto:LibEth@EthiopiaOnline.Net' in this node

SEE ALSO
========

   perl(1).  LiveGeez(3), `http:' in this node


File: pm.info,  Node: Convert/GeekCode,  Next: Convert/IBM390,  Prev: Convert/Ethiopic/Time,  Up: Module List

Convert and generate geek code sequences.
*****************************************

NAME
====

   Convert::GeekCode - Convert and generate geek code sequences.

SYNOPSIS
========

     use Convert::GeekCode; # exports geek_decode()

     print geek_decode(<<'.'); # yes, that's author's geek code
     -----BEGIN GEEK CODE BLOCK-----
     Version: 3.12
     GB/C/CM/CS/CC/ED/H/IT/L/M/MU/P/SS/TW/AT d---x s+: a--- C++++ UB++++
     P++++$ L+ E--- W+++$ N++ o? K w++(++++) O-- M- V-- PS+++ PE Y+
     PGP- t+ 5? X+ R+++ !tv b++++ DI+++@ D++ G+++ e-- h* r+ z**
     ------END GEEK CODE BLOCK------
     .

DESCRIPTION
===========

   Convert::GeekCode converts and generates Geek Code `http:' in this node
sequences. It supports different charsets and user-customizable codesets.

AUTHORS
=======

   Autrijus Tang <autrijus@autrijus.org>

   Copyright (c) 2001 by Autrijus Tang.  All rights reserved.  This module
is free software; you can redistribute it and/or modify it under the same
terms as Perl itself.


File: pm.info,  Node: Convert/IBM390,  Next: Convert/IBM390p,  Prev: Convert/GeekCode,  Up: Module List

functions for manipulating mainframe data
*****************************************

NAME
====

   Convert::IBM390 - functions for manipulating mainframe data

SYNOPSIS
========

     use Convert::IBM390 qw(...those desired... or :all);

     $eb  = asc2eb($string);
     $asc = eb2asc($string);
     $asc = eb2ascp($string);

     $ebrecord = packeb($template, LIST...);
     @fields = unpackeb($template, $record);
     @lines = hexdump($string [,startaddr [,charset]]);

DESCRIPTION
===========

   *Convert::IBM390* supplies various functions that you may find useful
when messing with IBM System/3[679]0 data.  No functions are exported
automatically; you must ask for the ones you want.  "use ... qw(:all)"
exports all functions.

   By the way, this module is called "IBM390" because it will deal with
data from any mainframe operating system.  Nothing about it is specific to
MVS, VM, VSE, or OS/390.

FUNCTIONS
=========

asc2eb STRING
     Converts a character string from ASCII to EBCDIC.  The translation
     table is taken from the LE/370 code set converter EDCUI1EY; it
     translates ISO8859-1 to IBM-1047.  For more information, see "IBM
     C/C++ for MVS/ESA V3R2 Programming Guide", SC09-2164.

eb2asc STRING
     Converts a character string from EBCDIC to ASCII.  EBCDIC character
     strings ordinarily come from files transferred from mainframes via
     the binary option of FTP.  The translation table is taken from the
     LE/370 code set converter EDCUEYI1; it translates IBM-1047 to
     ISO8859-1 (see above).

eb2ascp STRING
     Like eb2asc, but the output will contain only printable ASCII
     characters.

packeb TEMPLATE LIST
     This function is much like Perl's built-in "pack".  It takes a list
     of values and packs it into an EBCDIC record (structure).  If called
     in list context, it will return a list of one element.  The TEMPLATE
     is patterned after Perl's pack template but allows fewer options.
     The following characters are allowed in the template:

          c  (1)  Character string without translation, padded with nulls
          C  (1)  Character string without translation, padded with native
                  spaces
          e  (1)  ASCII string to be translated into EBCDIC, padded with nulls
          E  (1)  ASCII string to be translated into EBCDIC, padded with EBCDIC
                  spaces
          h  (1)  A hexadecimal string, high nybble always first
          i  (2)  Signed integer (S/390 fullword)
          p  (1)  Packed-decimal field (default length = 8)
          s  (2)  Signed short integer (S/390 halfword)
          S  (2)  Unsigned short integer (2 bytes)
          x  (2)  A null byte
          z  (1)  Zoned-decimal field (default length = 8)
          @       Null-fill to absolute offset

          (1) May be followed by a number giving the length of the output field;
              or, for hexadecimal, the number of nybbles in the input.
          (2) May be followed by a number giving the repeat count.

     Each character may be followed by a number giving either the length
     of the field or a repeat count, as shown above.  Types 'i', 's', and
     'S' will gobble the specified number of items from the list; if '*' is
     given as the length, all the remaining items will be gobbled.  All
     other types will gobble only one item; you will usually want to give
     a length for the output field.  The following defaults apply:

          Conversion                No length given   '*' given
          Character string [cCeE]   1                 Same length as input
          Hex string [hH]           2                 Same length as input
          Decimal [pz]              8                 8

     The number must immediately follow the character, but whitespace may
     appear between field specifiers.

     The length for packed (p) or zoned (z) fields may include a number of
     decimal places, which is added after the byte count and a '.'.  For
     instance, "p3.2" indicates a 3-byte (5-digit) packed field with 2
     implied decimal places; if the corresponding list element is 24.68,
     the result will be x'02468C'.  Likewise, "z7.2" indicates a 7-byte
     (7-digit) zoned field with 2 implied decimal places; if the input is
     -35.79, the result will be '000357R' in EBCDIC.  The number of
     implied decimals may be greater than the number of digits, but such a
     specification will usually cause you to lose part of your value;
     e.g., packing .589 with "p3.6" would yield x'89000c'.  If the input
     is not a valid Perl number, the results are unpredictable (since they
     depend on internal Perl code), but most likely the output field will
     contain zero.

     Zoned output will always have an overpunch in the last byte for the
     sign (e.g., x'C1' (EBCDIC 'A') for +1 or x'D3' (EBCDIC 'L') for -3).
     If you want unsigned numbers, you can use sprintf() and then translate
     the result: e.g., `asc2eb(sprintf("%08d", $num))'.

     The ASCII-to-EBCDIC translation used by [Ee] is the same as in
     asc2eb().

     Either 'h' or 'H' may be used to request hexadecimal conversion.  This
     conversion is exactly the same as in the Perl pack function, except
     that the high nybble must always come first in the input.

     The maximum length of a packed field is 16 bytes; of a zoned field, 32
     bytes.  All other fields may have a maximum specifier (length or
     repeat count) of 32767.  These maxima are enforced.

unpackeb TEMPLATE RECORD
     This function is much like Perl's built-in "unpack".  It takes an
     EBCDIC record (structure) and unpacks it into a list of values.  If
     called in scalar context, it will return only the first unpacked
     value.  The TEMPLATE is patterned after Perl's unpack template but
     allows fewer options.  The following characters are allowed in the
     template:

          c or C (1)   Character string without translation
          e or E (1)   EBCDIC string to be translated into ASCII
          i      (2)   Signed integer (S/390 fullword)
          I      (2)   Unsigned integer (4 bytes)
          p      (1)   Packed-decimal field
          s      (2)   Signed short integer (S/390 halfword)
          S      (2)   Unsigned short integer (2 bytes)
          v      (2)   EBCDIC varchar string
          x      (1)   Ignore these bytes
          z      (1)   Zoned-decimal field

          (1) May be followed by a number giving the length of the field.
          (2) May be followed by a number giving the repeat count.

     Each character may be followed by a number giving either the length
     of the field or a repeat count, as shown above, or by '*', which means
     to use however many items are left in the string.  The number must
     immediately follow the character, but whitespace may appear between
     field specifiers.

     The length for packed (p) or zoned (z) fields may include a number of
     decimal places, which is added after the byte count and a '.'.  For
     instance, "p3.2" indicates a 3-byte (5-digit) packed field with 2
     implied decimal places; if this field contains x'02468C', the result
     will be 24.68.  Likewise, "z7.2" indicates a 7-byte (7-digit) zoned
     field with 2 implied decimal places; if this field contains '000357R'
     (in EBCDIC), the result will be -35.79.  The number of implied
     decimals may be greater than the number of digits; e.g., unpacking
     the packed field above with "p3.6" would yield 0.002468.  Zoned input
     fields may, but need not, have an overpunch sign in the last byte.
     If the field is not a valid packed or zoned field, the resulting
     element of the list will be undefined.

     Varchar (v) fields are assumed to consist of a signed halfword
     (16-bit) integer followed by EBCDIC characters.  If the number
     appearing in the initial halfword is N, the following N bytes are
     translated from EBCDIC to ASCII and returned as one string.  This
     format is used, for instance, by DB2/MVS.  A repeat count may be
     specified; e.g., "v2" does not mean a length of 2 bytes, but that
     there are two such fields in succession.  If the length is found to
     be less than 0, the resulting element of the list will be undefined.

     The EBCDIC-to-ASCII translation used by [Eev] is the same as in
     eb2asc().

     The maximum length of a packed field is 16 bytes; of a zoned field, 32
     bytes.  All other fields may have a maximum specifier (length or
     repeat count) of 32767.  These maxima are enforced.

     In most cases, you should use 'i' rather than 'I' when unpacking
     fullword integers.  Unsigned long integers are not handled cleanly by
     all systems.

hexdump STRING [STARTADDR [CHARSET]]
     Generates a hexadecimal dump of STRING.  The dump is similar to a
     SYSABEND dump in MVS: each line contains an address, 32 bytes of data
     in hexadecimal, and the same data in printable form.  This function
     returns a list of lines, each of which is terminated with a newline.
     This allows them to be printed immediately; for instance, you can say
     "print hexdump($crud);".

     The second and third arguments are optional.  The second specifies a
     starting address for the dump (default = 0); the third specifies the
     character set to use for the printable data at the end of each line
     ("ascii" or "ebcdic", in upper or lower case; default = ascii).

REFERENCES
==========

   IBM ESA/390 Principles of Operation, SA22-7201.

   IBM System/370 Principles of Operation, GA22-7000.

   IBM C/C++ for MVS/ESA V3R2 Programming Guide, SC09-2164.

BUGS
====

   None, of course.  What do you think this is - Unix?

AUTHOR
======

   Convert::IBM390 was written by Geoffrey Rommel <grommel@webley.com> in
January 1999.


File: pm.info,  Node: Convert/IBM390p,  Next: Convert/Morse,  Prev: Convert/IBM390,  Up: Module List

OBSOLETE
********

NAME
====

   Convert::IBM390p - OBSOLETE

SYNOPSIS
========

   This synopsis intentionally left blank.

DESCRIPTION
===========

   *Convert::IBM390p* is now obsolete.  Install Convert::IBM390 instead.


File: pm.info,  Node: Convert/Morse,  Next: Convert/RACE,  Prev: Convert/IBM390p,  Up: Module List

Package to convert between ASCII text and MORSE alphabet.
*********************************************************

NAME
====

   Convert::Morse - Package to convert between ASCII text and MORSE
alphabet.

SYNOPSIS
========

     use Convert::Morse qw(as_ascii as_morse is_morsable);

     print as_ascii('.... . .-.. .-.. ---  -- --- .-. ... .'),"\n";
     						 # 'Helo Morse'
     print as_morse('Perl?'),"\n";		 # '.--. . .-. .-.. ..--..'
     print "Yes!\n" if is_morsable('Helo Perl.'); # print "Yes!"

REQUIRES
========

   perl5.6.0, Exporter

EXPORTS
=======

   Exports nothing on default, but can export as_ascii() and as_morse().

DESCRIPTION
===========

   This module lets you convert between normal ASCII text and international
Morse code. You can redefine the token sets, if you like.

INPUT
-----

   ASCII text can have both lower and upper case, it will be converted to
upper case prior to converting.

   Morse code input consists of dashes '-' and dots `'.''. The elements
*MUST NOT* to have spaces between, e.g. A is `'.-'' and not `'. -''.
Characters *MUST* have at least one space between. Additonal spaces are
left over to indicate word boundaries. This means `'.- -...'' means 'AB'
and and `'.-  -...'' means 'A B'.

   The conversion routines are designed to be stable and ignore/skip
unknown input, so that you can write:

     print as_ascii('Hello -- --- .-. ... .  Perl!');

   beware, though, a single '.' or '-' at the end will be interpreted as
'. ' respective '- ' and thus become 'E' or 'T'. Use
`Convert::Morse::error()' to check wether all went ok or not.

OUTPUT
------

   The output will always consist of upper case letters or, in case of
as_morse(), of `[-. ]'.

ERRORS
------

   Unknown tokens in the input are ignored/skipped. In these cases you get
the last error message with `Convert::Morse::error()'.

FUNCTIONS
=========

as_ascii()
----------

     as_ascii();

   Convert a Morse code text consisting of dashes and dots to ASCII.

as_morse()
----------

     as_morse();

   Convert a ASCII text to Morse code text consisting of dashes, dots and
spaces.

is_morse()
----------

     is_morse();

   Return wether input is a true Morse code string or not.

is_morsable()
-------------

     is_morseable();

   Return wether input can be completely expressed as Morse code or not.

error()
-------

     error();

   Returns the last error message or undef when no error occured.

LIMITATIONS
===========

   Can not yet do Japanese code nor German Umlaute.

BUGS
====

   None known yet.

AUTHOR
======

   Tels http://bloodgate.com in late 2000.


File: pm.info,  Node: Convert/RACE,  Next: Convert/Recode,  Prev: Convert/Morse,  Up: Module List

Conversion between Unicode and RACE
***********************************

NAME
====

   Convert::RACE - Conversion between Unicode and RACE

SYNOPSIS
========

     use Convert::RACE;

     $domain = to_race($utf16str);
     $utf16str = from_race($domain);

DESCRIPTION
===========

   This module provides functions to convert between RACE (Row-based
ASCII-Compatible Encoding) and Unicode Encodings.

   RACE converts strings with internationalized characters into strings of
US-ASCII that are acceptable as host name parts in current DNS host naming
usage.

   See http://www.ietf.org/internet-drafts/draft-ietf-idn-race-03.txt for
more details.

FUNCTION
========

   Following functions are provided; they are all in *@EXPORT* array.  See
*Note Exporter: Exporter, for details.

to_race($utf16)
     to_race() takes UTF-16 encoding and returns RACE-encoded strings such
     as 'bq-aewrcsy'.

     This function throws an exception such as 'String includes no
     internationalized characters', 'String too long' and 'Invalid encoding
     to compress'. Exceptions are thrown with Carp::croak(), so you can
     cath 'em with eval {};

from_race($domain_name)
     from_race() takes 'bq-' prefixed string and returns original UTF-16
     string.

     This function throws an exception such as 'String not begin with
     bq-', 'Decoded string includes no internationalized characters' and '
     Invalid format to decompress'. Exceptions are thrown with
     Carp::croak(), so you can cath 'em with eval {};

   See *Note Unicode/String: Unicode/String,, *Note Unicode/Map8:
Unicode/Map8,, *Note Jcode: Jcode, for Unicode conversions.

CLASS METHOD
============

   Following class methods are provided to change the behaviour of
Convert::RACE.

prefix_tag()
     Set and get the domain prefix tag. By default, 'bq-'.

EXAMPLES
========

     use Jcode;
     use Unicode::String 'latin1';
     use Convert::RACE 'to_race';

     # EUC-japanese here
     $name = to_race(Jcode->new('ÆüËÜ¸ì','euc')->ucs2);
     
     # or, Latin here
     $name = to_race(latin1($latin_string)->utf16);

     # in doubt of exception
     eval { $name = to_race($utf); };
     if ($@) {
         warn "Can't encode to RACE: $@";
     }

     # change the prefix
     Convert::RACE->prefix_tag('xx--');

TODO AND CAVEATS
================

   * Using XS would be by far efficient.

   * No validation is done for the input UTF-16 string in to_race(). The
     internet draft says checking for prohibited name parts must be done
     before doing the conversion.

AUTHOR
======

   Tatsuhiko Miyagawa <miyagawa@bulknews.net>, with much help from Eugen
SAVIN <seugen@serifu.com>, Philip Newton <pne@cpan.org>, Michael J Schout
<mschout@gkg.net>.

   This library is free software; you can redistribute it and/or modify it
under the same terms as Perl itself.

SEE ALSO
========

   http://www.i-d-n.net/,
http://www.ietf.org/internet-drafts/draft-ietf-idn-race-03.txt, RFC 1035,
*Note Unicode/String: Unicode/String,, *Note Jcode: Jcode,, *Note
Convert/Base32: Convert/Base32,.


File: pm.info,  Node: Convert/Recode,  Next: Convert/Scalar,  Prev: Convert/RACE,  Up: Module List

make mapping functions between character sets
*********************************************

NAME
====

   Convert::Recode - make mapping functions between character sets

SYNOPSIS
========

     use Convert::Recode qw(ebcdic_to_ascii);

     while (<>) {
        print ebcdic_to_ascii($_);
     }

DESCRIPTION
===========

   The Convert::Recode module can provide mapping functions between
character sets on demand.  It depends on GNU recode to provide the raw
mapping data, i.e. GNU recode must be installed first.  The names of the
mapping functions are found by taking the name of the two charsets and
then joining them with the string "_to_".  If you want to convert between
the "mac" and the "latin1" charsets, then you just import the
mac_to_latin1() function.

   If you prefix the function name with "strict_" then characters that can
not be mapped are removed during transformation.  For instance the
strict_mac_to_latin1() function will convert to a string to latin1 and
remove all mac characters that have not corresponding latin1 character.

   Running the command `recode -l' should give you the list of character
sets available.

AUTHOR
======

   © 1997 Gisle Aas.


File: pm.info,  Node: Convert/Scalar,  Next: Convert/SciEng,  Prev: Convert/Recode,  Up: Module List

convert between different representations of perl scalars
*********************************************************

NAME
====

   Convert::Scalar - convert between different representations of perl
scalars

SYNOPSIS
========

     use Convert::Scalar;

DESCRIPTION
===========

   This module exports various internal perl methods that change the
internal representation or state of a perl scalar. All of these work
in-place, that is, they modify their scalar argument. No functions are
exported by default.

   The following export tags exist:

     :utf8   all functions with utf8 in their names
     :taint  all functions with taint in their names

utf8 scalar[, mode]
     Returns true when the given scalar is marked as utf8, false
     otherwise. If the optional mode argument is given, also forces the
     interpretation of the string to utf8 (mode true) or plain bytes (mode
     false). The actual (byte-) content is not changed. The return value
     always reflects the state before any modification is done.

     This function is useful when you "import" utf8-data into perl, or when
     some external function (e.g. storing/retrieving from a database)
     removes the utf8-flag.

utf8_on scalar
     Similar to `utf8 scalar, 1', but additionally returns the scalar (the
     argument is still modified in-place).

utf8_off scalar
     Similar to `utf8 scalar, 0', but additionally returns the scalar (the
     argument is still modified in-place).

utf8_valid scalar [Perl 5.7]
     Returns true if the bytes inside the scalar form a valid utf8 string,
     false otherwise (the check is independent of the actual encoding perl
     thinks the string is in).

utf8_upgrade scalar
     Convert the string content of the scalar in-place to its UTF8-encoded
     form (and also returns it).

utf8_downgrade scalar[, fail_ok=0]
     Attempt to convert the string content of the scalar from UTF8-encoded
     to ISO-8859-1. This may not be possible if the string contains
     characters that cannot be represented in a single byte; if this is
     the case, it leaves the scalar unchanged and either returns false or,
     if `fail_ok' is not true (the default), croaks.

utf8_encode scalar
     Convert the string value of the scalar to UTF8-encoded, but then turn
     off the `SvUTF8' flag so that it looks like bytes to perl again.
     (Might be removed in future versions).

utf8_length scalar
     Returns the number of characters in the string, counting wide UTF8
     characters as a single character, independent of wether the scalar is
     marked as containing bytes or mulitbyte characters.

unmagic scalar
     Removes magic from the scalar.

weaken scalar
     Weaken a reference. (See also *Note WeakRef: WeakRef,).

taint scalar
     Taint the scalar.

tainted scalar
     returns true when the scalar is tainted, false otherwise.

untaint scalar, type
     Remove the specified magic from the scalar (DANGEROUS!), *Note
     Perlguts: (perl.info)perlguts,. *Note Untaint: Untaint,, for a
     similar but different interface.

grow scalar, newlen
     Sets the memory area used for the scalar to the given length, if the
     current length is less than the new value. This does not affect the
     contents of the scalar, but is only useful to "pre-allocate" memory
     space if you know the scalar will grow. The return value is the
     modified scalar (the scalar is modified in-place).

CANDIDATES FOR FUTURE RELEASES
------------------------------

   The following API functions (*Note Perlapi: (perl.info)perlapi,) are
considered for future inclusion in this module If you want them, write me.

     sv_upgrade
     sv_pvn_force
     sv_pvutf8n_force
     the sv2xx family

BUGS
====

   This module has not yet been extensively tested.

AUTHOR
======

     Marc Lehmann <pcg@goof.com>
     http://www.goof.com/pcg/marc/


File: pm.info,  Node: Convert/SciEng,  Next: Convert/TNEF,  Prev: Convert/Scalar,  Up: Module List

Convert 'numbers' with scientific postfixes
*******************************************

NAME
====

   Convert::SciEng - Convert 'numbers' with scientific postfixes

SYNOPSIS
========

     #!/usr/local/bin/perl -w

     use strict;
     use Convert::SciEng

     my $c = Convert::SciEng->new('spice');
     my $s = Convert::SciEng->new('si');

     print "Scalar\n";
     print $c->unfix('2.34u'), "\n\n";

     print "Array\n";
     print join "\n", $c->unfix(qw( 30.6k  10x  0.03456m  123n 45o)), "\n";

     ##Note, default format is 5.5g
     print "Default format is %5.5g\n";
     print join "\n", $c->fix(qw( 35e5 0.123e-4 200e3 )), "";
     $c->format('%8.2f');
     print "Change the format is %8.2g\n";
     print join "\n", $c->fix(qw( 35e5 0.123e-4 200e3 )), "";

     print "Check out the SI conversion\n";
     print join "\n", $s->unfix(qw( 30.6K  10M  0.03456m  123n 45o)), "";

REQUIRES
========

   perl5.004_04 or greater, Carp

   I'm sorry if you get bit by the 5.004_04 but I believe in the Cathedral
model.  Keep current or suffer the penalties.

DESCRIPTION
===========

   Convert::SciEng supplies an object for converting numbers to and from
scientific notation with user-defined formatting.  Two different styles of
fix are supported, standard SI and SPICE:

     SPICE  =    P    T   g   x   k  ''    m    u    n     p     f     a
     SI     =    P    T   G   M   K  ''    m    u    n     p     f     a
     Fix    = 1e15 1e12 1e9 1e6 1e3 1e0 1e-3 1e-6 1e-9 1e-12 1e-15 1e-18

   Methods are supplied for creating the object and defining which fix
style it will use, and defining for format of numbers as they are
converted to scientific notation.

METHODS
=======

Creation
--------

Convert::SciEng->new('style');
     Creates and returns a new Number::SI object of the appropiate style,
     either `'si'' or `'spice''. The styles aren't case sensitive

$fix->format(FORMAT);
     Sets the format of number converter TO fix to be FORMAT.  FORMAT is
     any valid format to sprintf, like `'%5.5g'' or `'%6.4e''.  The
     default format is `'%5.5g''.

Conversion
----------

$fix->fix(0.030405); # 30.405m
     Convert a number to scientific notation with fixes.  Returns a string
     in the format given to it with the fix appended to the end.  Also
     works with arrays, with an array of strings being returned.

$fix->unfix('12u'); # 12e-06
     Convert a string from scientific notation.  Returns a number in
     exponential format.  Also works with arrays, with an array of numbers
     being returned.

   Note, by examining the module it should be relatively easy to figure out
how to create an object for any other scientific notation abbreviations.
If you think it is something that might be useful to others, then email me
and I'll add it to the module.

DIAGNOSTICS
===========

Unrecognized mode: MODE
     (F) Generated when you try specify an illegal mode like so:

     $a = Convert::SciEng->new('foo');

Illegal printf format: FORMAT
     (F) An illegal format was specified.  Valid formats must match the
     following regexp:

     `/^\%\d+(\.\d+)?([scduxoefg]|l[duxo])$/'

AUTHOR
======

   Colin Kuskie, colink@latticesemi.com

KUDOS
=====

   Many thanks to Steven McDougall for his comments about the content and
style of my module and for sending me his templates for module creation.
They can be found at:

   http://world.std.com/~swmcd/steven/Perl/index.html

   and I highly recommend them for beginning module writers.

   Also thanks to Tom Christiansen for the perltoot podpage.


File: pm.info,  Node: Convert/TNEF,  Next: Convert/Translit,  Prev: Convert/SciEng,  Up: Module List

Perl module to read TNEF files
******************************

NAME
====

     Convert::TNEF - Perl module to read TNEF files

SYNOPSIS
========

     use Convert::TNEF;

     $tnef = Convert::TNEF->read($iohandle, \%parms)
      or die Convert::TNEF::errstr;

     $tnef = Convert::TNEF->read_in($filename, \%parms)
      or die Convert::TNEF::errstr;

     $tnef = Convert::TNEF->read_ent($mime_entity, \%parms)
      or die Convert::TNEF::errstr;

     $tnef->purge;

     $message = $tnef->message;

     @attachments = $tnef->attachments;

     $attribute_value      = $attachments[$i]->data($att_attribute_name);
     $attribute_value_size = $attachments[$i]->size($att_attribute_name);
     $attachment_name = $attachments[$i]->name;
     $long_attachment_name = $attachments[$i]->longname;

     $datahandle = $attachments[$i]->datahandle($att_attribute_name);

DESCRIPTION
===========

     TNEF stands for Transport Neutral Encapsulation Format, and if you've
     ever been unfortunate enough to receive one of these files as an email
     attachment, you may want to use this module.

     read() takes as its first argument any file handle open
     for reading. The optional second argument is a hash reference
     which contains one or more of the following keys:



     output_dir - Path for storing TNEF attribute data kept in files
     (default: current directory).

     output_prefix - File prefix for TNEF attribute data kept in files
     (default: 'tnef').

     output_to_core - TNEF attribute data will be saved in core memory unless
     it is greater than this many bytes (default: 4096). May also be set to
     'NONE' to keep all data in files, or 'ALL' to keep all data in core.

     buffer_size - Buffer size for reading in the TNEF file (default: 1024).

     debug - If true, outputs all sorts of info about what the read() function
     is reading, including the raw ascii data along with the data converted
     to hex (default: false).

     display_after_err - If debug is true and an error is encountered,
     reads and displays this many bytes of data following the error
     (default: 32).

     debug_max_display - If debug is true then read and display at most
     this many bytes of data for each TNEF attribute (default: 1024).

     debug_max_line_size - If debug is true then at most this many bytes of
     data will be displayed on each line for each TNEF attribute
     (default: 64).

     ignore_checksum - If true, will ignore checksum errors while parsing
     data (default: false).

     read() returns an object containing the TNEF 'attributes' read from the
     file and the data for those attributes. If all you want are the
     attachments, then this is mostly garbage, but if you're interested then
     you can see all the garbage by turning on debugging. If the garbage
     proves useful to you, then let me know how I can maybe make it more
     useful.

     If an error is encountered, an undefined value is returned and the
     package variable $errstr is set to some helpful message.

     read_in() is a convienient front end for read() which takes a filename
     instead of a handle.

     read_ent() is another convient front end for read() which can take a
     MIME::Entity object (or any object with like methods, specifically
     open("r"), read($buff,$num_bytes), and close ).

     purge() deletes any on-disk data that may be in the attachments of
     the TNEF object.

     message() returns the message portion of the tnef object, if any.
     The thing it returns is like an attachment, but its not an attachment.
     For instance, it more than likely does not have a name or any
     attachment data.

     attachments() returns a list of the attachments that the given TNEF
     object contains.

     data() takes a TNEF attribute name, and returns a string value for that
     attribute for that attachment. Its your own problem if the string is too
     big for memory. If no argument is given, then the 'AttachData' attribute
     is assumed, which is probably the data you're looking for.

     name() is the same as data(), except the attribute 'AttachTitle' is
     assumed, which returns the 8 character + 3 character extension name of
     the attachment.

     longname() returns the long filename and extension of an attachment. This
     is embedded in the 'Attachment' attribute data, so we attempt to extract
     the name out of that.

     size() takes an TNEF attribute name, and returns the size in bytes for
     the data for that attachment attribute.

     datahandle() is a method for attachments which takes a TNEF attribute
     name, and returns the data for that attribute as an object which is
     the same as a MIME::Body object.  See MIME::Body for all the applicable
     methods. If no argument is given, then 'AttachData' is assumed.

EXAMPLES
========

     # Here's a rather long example where mail is retrieved
     # from a POP3 server based on header information, then
     # it is MIME parsed, and then the TNEF contents
     # are extracted and converted.

     use strict;
     use Net::POP3;
     use MIME::Parser;
     use Convert::TNEF;

     my $mail_dir = "mailout";
     my $mail_prefix = "mail";

     my $pop = new Net::POP3 ( "pop3server_name" );
     my $num_msgs = $pop->login("user_name","password");
     die "Can't login: $!" unless defined $num_msgs;

     # Get mail by sender and subject
     my $mail_out_idx = 0;
     MESSAGE: for ( my $i=1; $i<= $num_msgs;  $i++ ) {
      my $header = join "", @{$pop->top($i)};

     for ($header) {
      next MESSAGE unless
       /^from:.*someone\@somewhere.net/im &&
       /^subject:\s*important stuff/im
     }

     my $fname = $mail_prefix."-".$$.++$mail_out_idx.".doc";
     open (MAILOUT, ">$mail_dir/$fname")
      or die "Can't open $mail_dir/$fname: $!";
     # If the get() complains, you need the new libnet bundle
     $pop->get($i, \*MAILOUT) or die "Can't read mail";
     close MAILOUT or die "Error closing $mail_dir/$fname";
     # If you want to delete the mail on the server
     # $pop->delete($i);
      }

     close MAILOUT;
     $pop->quit();

     # Parse the mail message into separate mime entities
     my $parser=new MIME::Parser;
     $parser->output_dir("mimemail");

     opendir(DIR, $mail_dir) or die "Can't open directory $mail_dir: $!";
     my @files = map { $mail_dir."/".$_ } sort
      grep { -f "$mail_dir/$_" and /$mail_prefix-$$-/o } readdir DIR;
     closedir DIR;

     for my $file ( @files ) {
      my $entity=$parser->parse_in($file) or die "Couldn't parse mail";
      print_tnef_parts($entity);
      # If you want to delete the working files
      # $entity->purge;
     }

     sub print_tnef_parts {
      my $ent = shift;

     if ( $ent->parts ) {
      for my $sub_ent ( $ent->parts ) {
       print_tnef_parts($sub_ent);
      }
     } elsif ( $ent->mime_type =~ /ms-tnef/i ) {

     # Create a tnef object
     my $tnef = Convert::TNEF->read_ent($ent,{output_dir=>"tnefmail"})
      or die $Convert::TNEF::errstr;
     for ($tnef->attachments) {
      print "Title:",$_->name,"\n";
      print "Data:\n",$_->data,"\n";
     }

     # If you want to delete the working files
     # $tnef->purge;
       }
      }

SEE ALSO
========

   perl(1), IO::Wrap(3), MIME::Parser(3), MIME::Entity(3), MIME::Body(3)

CAVEATS
=======

     The parsing may depend on the endianness (see perlport) and width of
     integers on the system where the TNEF file was created. If this proves
     to be the case (check the debug output), I'll see what I can do
     about it.

AUTHOR
======

     Douglas Wilson, dwilson@gtemail.net


