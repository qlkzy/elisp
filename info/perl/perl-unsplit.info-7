This is Info file perl.info, produced by Makeinfo version 1.68 from the
input file bigperl.texi.

   settitle perl


File: perl.info,  Node: perlre,  Next: perlrun,  Prev: perlop,  Up: Top

Perl regular expressions
************************

NAME
====

   perlre - Perl regular expressions

DESCRIPTION
===========

   This page describes the syntax of regular expressions in Perl.  For a
description of how to use regular expressions in matching operations, plus
various examples of the same, see discussions of m//, s///, `qr//' and
`??' in `"Regexp Quote-Like Operators"', *Note Perlop: perlop,.

   Matching operations can have various modifiers.  Modifiers that relate
to the interpretation of the regular expression inside are listed below.
Modifiers that alter the way a regular expression is used by Perl are
detailed in `"Regexp Quote-Like Operators"', *Note Perlop: perlop, and
`"Gory details of parsing quoted constructs"', *Note Perlop: perlop,.

i
     Do case-insensitive pattern matching.

     If `use locale' is in effect, the case map is taken from the current
     locale.  See *Note Perllocale: perllocale,.

m
     Treat string as multiple lines.  That is, change "^" and "$" from
     matching the start or end of the string to matching the start or end
     of any line anywhere within the string.

s
     Treat string as single line.  That is, change "." to match any
     character whatsoever, even a newline, which normally it would not
     match.

     The `/s' and `/m' modifiers both override the $* setting.  That is,
     no matter what $* contains, `/s' without `/m' will force "^" to match
     only at the beginning of the string and "$" to match only at the end
     (or just before a newline at the end) of the string.  Together, as
     /ms, they let the "." match any character whatsoever, while yet
     allowing "^" and "$" to match, respectively, just after and just
     before newlines within the string.

x
     Extend your pattern's legibility by permitting whitespace and
     comments.

   These are usually written as "the `/x' modifier", even though the
delimiter in question might not really be a slash.  Any of these modifiers
may also be embedded within the regular expression itself using the
`(?...)' construct.  See below.

   The `/x' modifier itself needs a little more explanation.  It tells the
regular expression parser to ignore whitespace that is neither backslashed
nor within a character class.  You can use this to break up your regular
expression into (slightly) more readable parts.  The `#' character is also
treated as a metacharacter introducing a comment, just as in ordinary Perl
code.  This also means that if you want real whitespace or `#' characters
in the pattern (outside a character class, where they are unaffected by
`/x'), that you'll either have to escape them or encode them using octal
or hex escapes.  Taken together, these features go a long way towards
making Perl's regular expressions more readable.  Note that you have to be
careful not to include the pattern delimiter in the comment-perl has no
way of knowing you did not intend to close the pattern early.  See the
C-comment deletion code in *Note Perlop: perlop,.

Regular Expressions
-------------------

   The patterns used in Perl pattern matching derive from supplied in the
Version 8 regex routines.  (The routines are derived (distantly) from
Henry Spencer's freely redistributable reimplementation of the V8
routines.)  See `Version 8 Regular Expressions' in this node for details.

   In particular the following metacharacters have their standard
*egrep*-ish meanings:

     \	Quote the next metacharacter
     ^	Match the beginning of the line
     .	Match any character (except newline)
     $	Match the end of the line (or before newline at the end)
     |	Alternation
     ()	Grouping
     []	Character class

   By default, the "^" character is guaranteed to match only the beginning
of the string, the "$" character only the end (or before the newline at
the end), and Perl does certain optimizations with the assumption that the
string contains only one line.  Embedded newlines will not be matched by
"^" or "$".  You may, however, wish to treat a string as a multi-line
buffer, such that the "^" will match after any newline within the string,
and "$" will match before any newline.  At the cost of a little more
overhead, you can do this by using the /m modifier on the pattern match
operator.  (Older programs did this by setting $*, but this practice is
now deprecated.)

   To simplify multi-line substitutions, the "." character never matches a
newline unless you use the `/s' modifier, which in effect tells Perl to
pretend the string is a single line-even if it isn't.  The `/s' modifier
also overrides the setting of $*, in case you have some (badly behaved)
older code that sets it in another module.

   The following standard quantifiers are recognized:

     *	   Match 0 or more times
     +	   Match 1 or more times
     ?	   Match 1 or 0 times
     {n}    Match exactly n times
     {n,}   Match at least n times
     {n,m}  Match at least n but not more than m times

   (If a curly bracket occurs in any other context, it is treated as a
regular character.)  The "*" modifier is equivalent to `{0,}', the "+"
modifier to `{1,}', and the "?" modifier to `{0,1}'.  n and m are limited
to integral values less than a preset limit defined when perl is built.
This is usually 32766 on the most common platforms.  The actual limit can
be seen in the error message generated by code such as this:

     $_ **= $_ , / {$_} / for 2 .. 42;

   By default, a quantified subpattern is "greedy", that is, it will match
as many times as possible (given a particular starting location) while
still allowing the rest of the pattern to match.  If you want it to match
the minimum number of times possible, follow the quantifier with a "?".
Note that the meanings don't change, just the "greediness":

     *?	   Match 0 or more times
     +?	   Match 1 or more times
     ??	   Match 0 or 1 time
     {n}?   Match exactly n times
     {n,}?  Match at least n times
     {n,m}? Match at least n but not more than m times

   Because patterns are processed as double quoted strings, the following
also work:

     \t		tab                   (HT, TAB)
     \n		newline               (LF, NL)
     \r		return                (CR)
     \f		form feed             (FF)
     \a		alarm (bell)          (BEL)
     \e		escape (think troff)  (ESC)
     \033	octal char (think of a PDP-11)
     \x1B	hex char
     \x{263a}	wide hex char         (Unicode SMILEY)
     \c[		control char
     \N{name}	named char
     \l		lowercase next char (think vi)
     \u		uppercase next char (think vi)
     \L		lowercase till \E (think vi)
     \U		uppercase till \E (think vi)
     \E		end case modification (think vi)
     \Q		quote (disable) pattern metacharacters till \E

   If `use locale' is in effect, the case map used by `\l', `\L', `\u' and
`\U' is taken from the current locale.  See *Note Perllocale: perllocale,.
For documentation of `\N{name}', see *Note Charnames: (pm.info)charnames,.

   You cannot include a literal `$' or `@' within a `\Q' sequence.  An
unescaped `$' or `@' interpolates the corresponding variable, while
escaping will cause the literal string `\$' to be matched.  You'll need to
write something like `m/\Quser\E\@\Qhost/'.

   In addition, Perl defines the following:

     \w	Match a "word" character (alphanumeric plus "_")
     \W	Match a non-word character
     \s	Match a whitespace character
     \S	Match a non-whitespace character
     \d	Match a digit character
     \D	Match a non-digit character
     \pP	Match P, named property.  Use \p{Prop} for longer names.
     \PP	Match non-P
     \X	Match eXtended Unicode "combining character sequence",
         equivalent to C<(?:\PM\pM*)>
     \C	Match a single C char (octet) even under utf8.

   A `\w' matches a single alphanumeric character, not a whole word.  Use
`\w+' to match a string of Perl-identifier characters (which isn't the
same as matching an English word).  If `use locale' is in effect, the list
of alphabetic characters generated by `\w' is taken from the current
locale.  See *Note Perllocale: perllocale,.  You may use `\w', `\W', `\s',
`\S', `\d', and `\D' within character classes, but if you try to use them
as endpoints of a range, that's not a range, the "-" is understood
literally.  See *Note Utf8: (pm.info)utf8, for details about `\pP', `\PP',
and `\X'.

   The POSIX character class syntax

     [:class:]

   is also available.  The available classes and their backslash
equivalents (if available) are as follows:

     alpha
     alnum
     ascii
     cntrl
     digit       \d
     graph
     lower
     print
     punct
     space       \s
     upper
     word        \w
     xdigit

   For example use `[:upper:]' to match all the uppercase characters.
Note that the [] are part of the `[::]' construct, not part of the whole
character class.  For example:

     [01[:alpha:]%]

   matches one, zero, any alphabetic character, and the percentage sign.

   If the utf8 pragma is used, the following equivalences to Unicode \p{}
constructs hold:

     alpha       IsAlpha
     alnum       IsAlnum
     ascii       IsASCII
     cntrl       IsCntrl
     digit       IsDigit
     graph       IsGraph
     lower       IsLower
     print       IsPrint
     punct       IsPunct
     space       IsSpace
     upper       IsUpper
     word        IsWord
     xdigit      IsXDigit

   For example `[:lower:]' and `\p{IsLower}' are equivalent.

   If the utf8 pragma is not used but the locale pragma is, the classes
correlate with the isalpha(3) interface (except for `word', which is a
Perl extension, mirroring `\w').

   The assumedly non-obviously named classes are:

cntrl
     Any control character.  Usually characters that don't produce output
     as such but instead control the terminal somehow: for example newline
     and backspace are control characters.  All characters with ord() less
     than 32 are most often classified as control characters.

graph
     Any alphanumeric or punctuation character.

print
     Any alphanumeric or punctuation character or space.

punct
     Any punctuation character.

xdigit
     Any hexadecimal digit.  Though this may feel silly (/0-9a-f/i would
     work just fine) it is included for completeness.

   You can negate the [::] character classes by prefixing the class name
with a '^'. This is a Perl extension.  For example:

* Menu:

* perl:: 	Perl overview (this section)
* perldelta:: 	Perl changes since previous version
* perl5005delta:: Perl changes in version 5.005
* perl5004delta:: Perl changes in version 5.004
* perlfaq:: 	Perl frequently asked questions
* perltoc:: 	Perl documentation table of contents

* perldata:: 	Perl data structures
* perlsyn:: 	Perl syntax
* perlop:: 	Perl operators and precedence
* perlre:: 	Perl regular expressions
* perlrun:: 	Perl execution and options
* perlfunc:: 	Perl builtin functions
* perlopentut:: 	Perl open() tutorial
* perlvar:: 	Perl predefined variables
* perlsub:: 	Perl subroutines
* perlmod:: 	Perl modules: how they work
* perlmodlib:: 	Perl modules: how to write and use
* perlmodinstall:: Perl modules: how to install from CPAN
* perlform:: 	Perl formats
* perlunicode:: 	Perl unicode support
* perllocale:: 	Perl locale support

* perlreftut:: 	Perl references short introduction
* perlref:: 	Perl references, the rest of the story
* perldsc:: 	Perl data structures intro
* perllol:: 	Perl data structures: arrays of arrays
* perlboot:: 	Perl OO tutorial for beginners
* perltoot:: 	Perl OO tutorial, part 1
* perltootc:: 	Perl OO tutorial, part 2
* perlobj:: 	Perl objects
* perltie:: 	Perl objects hidden behind simple variables
* perlbot:: 	Perl OO tricks and examples
* perlipc:: 	Perl interprocess communication
* perlfork:: 	Perl fork() information
* perlthrtut:: 	Perl threads tutorial
* perllexwarn:: 	Perl warnings and their control
* perlfilter:: 	Perl source filters
* perldbmfilter:: Perl DBM filters

* perlcompile:: 	Perl compiler suite intro
* perldebug:: 	Perl debugging
* perldiag:: 	Perl diagnostic messages
* perlnumber:: 	Perl number semantics
* perlsec:: 	Perl security
* perltrap:: 	Perl traps for the unwary
* perlport:: 	Perl portability guide
* perlstyle:: 	Perl style guide

* perlpod:: 	Perl plain old documentation
* perlbook:: 	Perl book information

* perlembed:: 	Perl ways to embed perl in your C or C++ application
* perlapio:: 	Perl internal IO abstraction interface
* perldebguts:: 	Perl debugging guts and tips
* perlxs:: 	Perl XS application programming interface
* perlxstut:: 	Perl XS tutorial
* perlguts:: 	Perl internal functions for those doing extensions
* perlcall:: 	Perl calling conventions from C
* perlapi:: 	Perl API listing (autogenerated)
* perlintern:: 	Perl internal functions (autogenerated)

* perltodo:: 	Perl things to do
* perlhack:: 	Perl hackers guide
* perlhist:: 	Perl history records

* perlamiga:: 	Perl notes for Amiga
* perlcygwin:: 	Perl notes for Cygwin
* perldos:: 	Perl notes for DOS
* perlhpux:: 	Perl notes for HP-UX
* perlmachten:: 	Perl notes for Power MachTen
* perlos2:: 	Perl notes for OS/2
* perlos390:: 	Perl notes for OS/390
* perlvms:: 	Perl notes for VMS
* perlwin32:: 	Perl notes for Windows

* Tk:: 			CPAN

* POSIX:: trad. Perl  utf8 Perl


* Module List:(pm.info)Module List. Got your modules, right here
* Function Index:: Perl functions and operators
* Predefined Variable Index:: Perl predefined variables
* Diagnostics Index:: Perl diagnostic messages

     [:^digit:]      \D      \P{IsDigit}
     [:^space:]	    \S	    \P{IsSpace}
     [:^word:]	    \W	    \P{IsWord}

   The POSIX character classes [.cc.] and [=cc=] are recognized but not
supported and trying to use them will cause an error.

   Perl defines the following zero-width assertions:

     \b	Match a word boundary
     \B	Match a non-(word boundary)
     \A	Match only at beginning of string
     \Z	Match only at end of string, or before newline at the end
     \z	Match only at end of string
     \G	Match only at pos() (e.g. at the end-of-match position
         of prior m//g)

   A word boundary (`\b') is a spot between two characters that has a `\w'
on one side of it and a `\W' on the other side of it (in either order),
counting the imaginary characters off the beginning and end of the string
as matching a `\W'.  (Within character classes `\b' represents backspace
rather than a word boundary, just as it normally does in any double-quoted
string.)  The `\A' and `\Z' are just like "^" and "$", except that they
won't match multiple times when the `/m' modifier is used, while "^" and
"$" will match at every internal line boundary.  To match the actual end
of the string and not ignore an optional trailing newline, use `\z'.

   The `\G' assertion can be used to chain global matches (using `m//g'),
as described in `"Regexp Quote-Like Operators"', *Note Perlop: perlop,.
It is also useful when writing lex-like scanners, when you have several
patterns that you want to match against consequent substrings of your
string, see the previous reference.  The actual location where `\G' will
match can also be influenced by using `pos()' as an lvalue.  See `pos',
*Note Perlfunc: perlfunc,.

   The bracketing construct `( ... )' creates capture buffers.  To refer
to the digit'th buffer use \<digit> within the match.  Outside the match
use "$" instead of "\".  (The \<digit> notation works in certain
circumstances outside the match.  See the warning below about \1 vs $1 for
details.)  Referring back to another part of the match is called a
*backreference*.

   There is no limit to the number of captured substrings that you may
use.  However Perl also uses \10, \11, etc. as aliases for \010, \011,
etc.  (Recall that 0 means octal, so \011 is the 9'th ASCII character, a
tab.)  Perl resolves this ambiguity by interpreting \10 as a backreference
only if at least 10 left parentheses have opened before it.  Likewise \11
is a backreference only if at least 11 left parentheses have opened before
it.  And so on.  \1 through \9 are always interpreted as backreferences."

   Examples:

     s/^([^ ]*) *([^ ]*)/$2 $1/;     # swap first two words

     if (/(.)\1/) {                 # find first doubled char
         print "'$1' is the first doubled character\n";
     }

     if (/Time: (..):(..):(..)/) {   # parse out values
     	$hours = $1;
     	$minutes = $2;
     	$seconds = $3;
     }

   Several special variables also refer back to portions of the previous
match.  $+ returns whatever the last bracket match matched.  $& returns
the entire matched string.  (At one point $0 did also, but now it returns
the name of the program.)  $` returns everything before the matched
string.  And $' returns everything after the matched string.

   The numbered variables ($1, $2, $3, etc.) and the related punctuation
set (`<$+', $&, $`, and $') are all dynamically scoped until the end of
the enclosing block or until the next successful match, whichever comes
first.  (See `"Compound Statements"', *Note Perlsyn: perlsyn,.)

   WARNING: Once Perl sees that you need one of $&, $`, or $' anywhere in
the program, it has to provide them for every pattern match.  This may
substantially slow your program.  Perl uses the same mechanism to produce
$1, $2, etc, so you also pay a price for each pattern that contains
capturing parentheses.  (To avoid this cost while retaining the grouping
behaviour, use the extended regular expression `(?: ... )' instead.)  But
if you never use $&, $` or $', then patterns *without* capturing
parentheses will not be penalized.  So avoid $&, $', and $` if you can,
but if you can't (and some algorithms really appreciate them), once you've
used them once, use them at will, because you've already paid the price.
As of 5.005, $& is not so costly as the other two.

   Backslashed metacharacters in Perl are alphanumeric, such as `\b',
`\w', \n.  Unlike some other regular expression languages, there are no
backslashed symbols that aren't alphanumeric.  So anything that looks like
\\, \(, \), \<, \>, \{, or \} is always interpreted as a literal
character, not a metacharacter.  This was once used in a common idiom to
disable or quote the special meanings of regular expression metacharacters
in a string that you want to use for a pattern. Simply quote all
non-alphanumeric characters:

     $pattern =~ s/(\W)/\\$1/g;

   Today it is more common to use the quotemeta() function or the `\Q'
metaquoting escape sequence to disable all metacharacters' special
meanings like this:

     /$unquoted\Q$quoted\E$unquoted/

   Beware that if you put literal backslashes (those not inside
interpolated variables) between `\Q' and `\E', double-quotish backslash
interpolation may lead to confusing results.  If you *need* to use literal
backslashes within `\Q...\E', consult `"Gory details of parsing quoted
constructs"', *Note Perlop: perlop,.

Extended Patterns
-----------------

   Perl also defines a consistent extension syntax for features not found
in standard tools like *awk* and lex.  The syntax is a pair of parentheses
with a question mark as the first thing within the parentheses.  The
character after the question mark indicates the extension.

   The stability of these extensions varies widely.  Some have been part
of the core language for many years.  Others are experimental and may
change without warning or be completely removed.  Check the documentation
on an individual feature to verify its current status.

   A question mark was chosen for this and for the minimal-matching
construct because 1) question marks are rare in older regular expressions,
and 2) whenever you see one, you should stop and "question" exactly what
is going on.  That's psychology...

`(?#text)'
     A comment.  The text is ignored.  If the `/x' modifier enables
     whitespace formatting, a simple `#' will suffice.  Note that Perl
     closes the comment as soon as it sees a ), so there is no way to put
     a literal ) in the comment.

`(?imsx-imsx)'
     One or more embedded pattern-match modifiers.  This is particularly
     useful for dynamic patterns, such as those read in from a
     configuration file, read in as an argument, are specified in a table
     somewhere, etc.  Consider the case that some of which want to be case
     sensitive and some do not.  The case insensitive ones need to include
     merely `(?i)' at the front of the pattern.  For example:

          $pattern = "foobar";
          if ( /$pattern/i ) { }

          # more flexible:

          $pattern = "(?i)foobar";
          if ( /$pattern/ ) { }

     Letters after a - turn those modifiers off.  These modifiers are
     localized inside an enclosing group (if any).  For example,

          ( (?i) blah ) \s+ \1

     will match a repeated (*including the case*!) word `blah' in any
     case, assuming x modifier, and no i modifier outside this group.

`(?:pattern)'
`(?imsx-imsx:pattern)'
     This is for clustering, not capturing; it groups subexpressions like
     "()", but doesn't make backreferences as "()" does.  So

          @fields = split(/\b(?:a|b|c)\b/)

     is like

          @fields = split(/\b(a|b|c)\b/)

     but doesn't spit out extra fields.  It's also cheaper not to capture
     characters if you don't need to.

     Any letters between ? and : act as flags modifiers as with
     `(?imsx-imsx)'.  For example,

          /(?s-i:more.*than).*million/i

     is equivalent to the more verbose

          /(?:(?s-i)more.*than).*million/i

`(?=pattern)'
     A zero-width positive look-ahead assertion.  For example,
     `/\w+(?=\t)/' matches a word followed by a tab, without including the
     tab in $&.

`(?!pattern)'
     A zero-width negative look-ahead assertion.  For example
     `/foo(?!bar)/' matches any occurrence of "foo" that isn't followed by
     "bar".  Note however that look-ahead and look-behind are NOT the same
     thing.  You cannot use this for look-behind.

     If you are looking for a "bar" that isn't preceded by a "foo",
     `/(?!foo)bar/' will not do what you want.  That's because the
     `(?!foo)' is just saying that the next thing cannot be "foo"-and it's
     not, it's a "bar", so "foobar" will match.  You would have to do
     something like `/(?!foo)...bar/' for that.   We say "like" because
     there's the case of your "bar" not having three characters before it.
     You could cover that this way: `/(?:(?!foo)...|^.{0,2})bar/'.
     Sometimes it's still easier just to say:

          if (/bar/ && $` !~ /foo$/)

     For look-behind see below.

`(?<=pattern)'
     A zero-width positive look-behind assertion.  For example,
     `/(?<=\t)\w+/' matches a word that follows a tab, without including
     the tab in $&.  Works only for fixed-width look-behind.

`(?<!pattern)'
     A zero-width negative look-behind assertion.  For example
     `/(?<!bar)foo/' matches any occurrence of "foo" that does not follow
     "bar".  Works only for fixed-width look-behind.

`(?{ code })'
     WARNING: This extended regular expression feature is considered
     highly experimental, and may be changed or deleted without notice.

     This zero-width assertion evaluate any embedded Perl code.  It always
     succeeds, and its code is not interpolated.  Currently, the rules to
     determine where the code ends are somewhat convoluted.

     The code is properly scoped in the following sense: If the assertion
     is backtracked (compare `"Backtracking"' in this node), all changes
     introduced after localization are undone, so that

          $_ = 'a' x 8;
          m<
             (?{ $cnt = 0 })			# Initialize $cnt.
             (
               a
               (?{
                   local $cnt = $cnt + 1;	# Update $cnt, backtracking-safe.
               })
             )*
             aaaa
             (?{ $res = $cnt })			# On success copy to non-localized
          					# location.
           >x;

     will set `$res = 4'.  Note that after the match, $cnt returns to the
     globally introduced value, because the scopes that restrict local
     operators are unwound.

     This assertion may be used as a `(?(condition)yes-pattern|no-pattern)'
     switch.  If not used in this way, the result of evaluation of code is
     put into the special variable $^R.  This happens immediately, so $^R
     can be used from other `(?{ code })' assertions inside the same
     regular expression.

     The assignment to $^R above is properly localized, so the old value
     of $^R is restored if the assertion is backtracked; compare
     `"Backtracking"' in this node.

     For reasons of security, this construct is forbidden if the regular
     expression involves run-time interpolation of variables, unless the
     perilous `use re 'eval'' pragma has been used (see *Note Re:
     (pm.info)re,), or the variables contain results of `qr//' operator
     (see `"qr', *Note Perlop: perlop,).

     This restriction is because of the wide-spread and remarkably
     convenient custom of using run-time determined strings as patterns.
     For example:

          $re = <>;
          chomp $re;
          $string =~ /$re/;

     Before Perl knew how to execute interpolated code within a pattern,
     this operation was completely safe from a security point of view,
     although it could raise an exception from an illegal pattern.  If you
     turn on the `use re 'eval'', though, it is no longer secure, so you
     should only do so if you are also using taint checking.  Better yet,
     use the carefully constrained evaluation within a Safe module.  See
     *Note Perlsec: perlsec, for details about both these mechanisms.

`(??{ code })'
     WARNING: This extended regular expression feature is considered
     highly experimental, and may be changed or deleted without notice.  A
     simplified version of the syntax may be introduced for commonly used
     idioms.

     This is a "postponed" regular subexpression.  The code is evaluated
     at run time, at the moment this subexpression may match.  The result
     of evaluation is considered as a regular expression and matched as if
     it were inserted instead of this construct.

     The code is not interpolated.  As before, the rules to determine
     where the code ends are currently somewhat convoluted.

     The following pattern matches a parenthesized group:

          $re = qr{
          	     \(
          	     (?:
          		(?> [^()]+ )	# Non-parens without backtracking
          	      |
          		(??{ $re })	# Group with matching parens
          	     )*
          	     \)
          	  }x;

`< (?'pattern) >>
     WARNING: This extended regular expression feature is considered
     highly experimental, and may be changed or deleted without notice.

     An "independent" subexpression, one which matches the substring that
     a *standalone* pattern would match if anchored at the given position,
     and it matches *nothing other than this substring*.  This construct
     is useful for optimizations of what would otherwise be "eternal"
     matches, because it will not backtrack (see `"Backtracking"' in this
     node).  It may also be useful in places where the "grab all you can,
     and do not give anything back" semantic is desirable.

     For example: `< ^(?'a*)ab >> will never match, since `< (?'a*) >>
     (anchored at the beginning of string, as above) will match all
     characters a at the beginning of string, leaving no a for `ab' to
     match.  In contrast, `a*ab' will match the same as `a+b', since the
     match of the subgroup `a*' is influenced by the following group `ab'
     (see `"Backtracking"' in this node).  In particular, `a*' inside
     `a*ab' will match fewer characters than a standalone `a*', since this
     makes the tail match.

     An effect similar to `< (?'pattern) >> may be achieved by writing
     `(?=(pattern))\1'.  This matches the same substring as a standalone
     `a+', and the following \1 eats the matched string; it therefore
     makes a zero-length assertion into an analogue of `< (?'...) >>.
     (The difference between these two constructs is that the second one
     uses a capturing group, thus shifting ordinals of backreferences in
     the rest of a regular expression.)

     Consider this pattern:

          m{ \(
          	  (
          	    [^()]+		# x+
                |
                  \( [^()]* \)
                )+
             \)
           }x

     That will efficiently match a nonempty group with matching parentheses
     two levels deep or less.  However, if there is no such group, it will
     take virtually forever on a long string.  That's because there are so
     many different ways to split a long string into several substrings.
     This is what `(.+)+' is doing, and `(.+)+' is similar to a subpattern
     of the above pattern.  Consider how the pattern above detects
     no-match on `((()aaaaaaaaaaaaaaaaaa' in several seconds, but that
     each extra letter doubles this time.  This exponential performance
     will make it appear that your program has hung.  However, a tiny
     change to this pattern

          m{ \(
          	  (
          	    (?> [^()]+ )	# change x+ above to (?> x+ )
                |
                  \( [^()]* \)
                )+
             \)
           }x

     which uses `< (?'...) >> matches exactly when the one above does
     (verifying this yourself would be a productive exercise), but
     finishes in a fourth the time when used on a similar string with
     1000000 as.  Be aware, however, that this pattern currently triggers
     a warning message under the `use warnings' pragma or -w switch saying
     it `"matches the null string many times"'):

     On simple groups, such as the pattern `< (?' [^()]+ ) >>, a comparable
     effect may be achieved by negative look-ahead, as in `[^()]+ (?!
     [^()] )'.  This was only 4 times slower on a string with 1000000 as.

     The "grab all you can, and do not give anything back" semantic is
     desirable in many situations where on the first sight a simple `()*'
     looks like the correct solution.  Suppose we parse text with comments
     being delimited by `#' followed by some optional (horizontal)
     whitespace.  Contrary to its appearence, `#[ \t]*' *is not* the
     correct subexpression to match the comment delimiter, because it may
     "give up" some whitespace if the remainder of the pattern can be made
     to match that way.  The correct answer is either one of these:

          (?>#[ \t]*)
          #[ \t]*(?![ \t])

     For example, to grab non-empty comments into $1, one should use either
     one of these:

          / (?> \# [ \t]* ) (        .+ ) /x;
          /     \# [ \t]*   ( [^ \t] .* ) /x;

     Which one you pick depends on which of these expressions better
     reflects the above specification of comments.

`(?(condition)yes-pattern|no-pattern)'
`(?(condition)yes-pattern)'
     WARNING: This extended regular expression feature is considered
     highly experimental, and may be changed or deleted without notice.

     Conditional expression.  `(condition)' should be either an integer in
     parentheses (which is valid if the corresponding pair of parentheses
     matched), or look-ahead/look-behind/evaluate zero-width assertion.

     For example:

          m{ ( \( )?
             [^()]+
             (?(1) \) )
           }x

     matches a chunk of non-parentheses, possibly included in parentheses
     themselves.

Backtracking
------------

   NOTE: This section presents an abstract approximation of regular
expression behavior.  For a more rigorous (and complicated) view of the
rules involved in selecting a match among possible alternatives, see
`Combining pieces together' in this node.

   A fundamental feature of regular expression matching involves the
notion called *backtracking*, which is currently used (when needed) by all
regular expression quantifiers, namely *, `*?', +, `+?', `{n,m}', and
`{n,m}?'.  Backtracking is often optimized internally, but the general
principle outlined here is valid.

   For a regular expression to match, the *entire* regular expression must
match, not just part of it.  So if the beginning of a pattern containing a
quantifier succeeds in a way that causes later parts in the pattern to
fail, the matching engine backs up and recalculates the beginning
part-that's why it's called backtracking.

   Here is an example of backtracking:  Let's say you want to find the
word following "foo" in the string "Food is on the foo table.":

     $_ = "Food is on the foo table.";
     if ( /\b(foo)\s+(\w+)/i ) {
     	print "$2 follows $1.\n";
     }

   When the match runs, the first part of the regular expression
(`\b(foo)') finds a possible match right at the beginning of the string,
and loads up $1 with "Foo".  However, as soon as the matching engine sees
that there's no whitespace following the "Foo" that it had saved in $1, it
realizes its mistake and starts over again one character after where it
had the tentative match.  This time it goes all the way until the next
occurrence of "foo". The complete regular expression matches this time,
and you get the expected output of "table follows foo."

   Sometimes minimal matching can help a lot.  Imagine you'd like to match
everything between "foo" and "bar".  Initially, you write something like
this:

     $_ =  "The food is under the bar in the barn.";
     if ( /foo(.*)bar/ ) {
     	print "got <$1>\n";
     }

   Which perhaps unexpectedly yields:

     got <d is under the bar in the >

   That's because `.*' was greedy, so you get everything between the first
"foo" and the last "bar".  Here it's more effective to use minimal
matching to make sure you get the text between a "foo" and the first "bar"
thereafter.

     if ( /foo(.*?)bar/ ) { print "got <$1>\n" }
       got <d is under the >

   Here's another example: let's say you'd like to match a number at the
end of a string, and you also want to keep the preceding part the match.
So you write this:

     $_ = "I have 2 numbers: 53147";
     if ( /(.*)(\d*)/ ) {				# Wrong!
     	print "Beginning is <$1>, number is <$2>.\n";
     }

   That won't work at all, because `.*' was greedy and gobbled up the
whole string. As `\d*' can match on an empty string the complete regular
expression matched successfully.

     Beginning is <I have 2 numbers: 53147>, number is <>.

   Here are some variants, most of which don't work:

     $_ = "I have 2 numbers: 53147";
     @pats = qw{
     	(.*)(\d*)
     	(.*)(\d+)
     	(.*?)(\d*)
     	(.*?)(\d+)
     	(.*)(\d+)$
     	(.*?)(\d+)$
     	(.*)\b(\d+)$
     	(.*\D)(\d+)$
     };

     for $pat (@pats) {
     	printf "%-12s ", $pat;
     	if ( /$pat/ ) {
     	    print "<$1> <$2>\n";
     	} else {
     	    print "FAIL\n";
     	}
     }

   That will print out:

     (.*)(\d*)    <I have 2 numbers: 53147> <>
     (.*)(\d+)    <I have 2 numbers: 5314> <7>
     (.*?)(\d*)   <> <>
     (.*?)(\d+)   <I have > <2>
     (.*)(\d+)$   <I have 2 numbers: 5314> <7>
     (.*?)(\d+)$  <I have 2 numbers: > <53147>
     (.*)\b(\d+)$ <I have 2 numbers: > <53147>
     (.*\D)(\d+)$ <I have 2 numbers: > <53147>

   As you see, this can be a bit tricky.  It's important to realize that a
regular expression is merely a set of assertions that gives a definition
of success.  There may be 0, 1, or several different ways that the
definition might succeed against a particular string.  And if there are
multiple ways it might succeed, you need to understand backtracking to
know which variety of success you will achieve.

   When using look-ahead assertions and negations, this can all get even
tricker.  Imagine you'd like to find a sequence of non-digits not followed
by "123".  You might try to write that as

     $_ = "ABC123";
     if ( /^\D*(?!123)/ ) {		# Wrong!
     	print "Yup, no 123 in $_\n";
     }

   But that isn't going to match; at least, not the way you're hoping.  It
claims that there is no 123 in the string.  Here's a clearer picture of
why it that pattern matches, contrary to popular expectations:

     $x = 'ABC123' ;
     $y = 'ABC445' ;

     print "1: got $1\n" if $x =~ /^(ABC)(?!123)/ ;
     print "2: got $1\n" if $y =~ /^(ABC)(?!123)/ ;

     print "3: got $1\n" if $x =~ /^(\D*)(?!123)/ ;
     print "4: got $1\n" if $y =~ /^(\D*)(?!123)/ ;

   This prints

     2: got ABC
     3: got AB
     4: got ABC

   You might have expected test 3 to fail because it seems to a more
general purpose version of test 1.  The important difference between them
is that test 3 contains a quantifier (`\D*') and so can use backtracking,
whereas test 1 will not.  What's happening is that you've asked "Is it
true that at the start of $x, following 0 or more non-digits, you have
something that's not 123?"  If the pattern matcher had let `\D*' expand to
"ABC", this would have caused the whole pattern to fail.

   The search engine will initially match `\D*' with "ABC".  Then it will
try to match `(?!123' with "123", which fails.  But because a quantifier
(`\D*') has been used in the regular expression, the search engine can
backtrack and retry the match differently in the hope of matching the
complete regular expression.

   The pattern really, *really* wants to succeed, so it uses the standard
pattern back-off-and-retry and lets `\D*' expand to just "AB" this time.
Now there's indeed something following "AB" that is not "123".  It's
"C123", which suffices.

   We can deal with this by using both an assertion and a negation.  We'll
say that the first part in $1 must be followed both by a digit and by
something that's not "123".  Remember that the look-aheads are zero-width
expressions-they only look, but don't consume any of the string in their
match.  So rewriting this way produces what you'd expect; that is, case 5
will fail, but case 6 succeeds:

     print "5: got $1\n" if $x =~ /^(\D*)(?=\d)(?!123)/ ;
     print "6: got $1\n" if $y =~ /^(\D*)(?=\d)(?!123)/ ;

     6: got ABC

   In other words, the two zero-width assertions next to each other work
as though they're ANDed together, just as you'd use any built-in
assertions:  `/^$/' matches only if you're at the beginning of the line
AND the end of the line simultaneously.  The deeper underlying truth is
that juxtaposition in regular expressions always means AND, except when
you write an explicit OR using the vertical bar.  `/ab/' means match "a"
AND (then) match "b", although the attempted matches are made at different
positions because "a" is not a zero-width assertion, but a one-width
assertion.

   WARNING: particularly complicated regular expressions can take
exponential time to solve because of the immense number of possible ways
they can use backtracking to try match.  For example, without internal
optimizations done by the regular expression engine, this will take a
painfully long time to run:

     'aaaaaaaaaaaa' =~ /((a{0,5}){0,5}){0,5}[c]/

   And if you used *'s instead of limiting it to 0 through 5 matches, then
it would take forever-or until you ran out of stack space.

   A powerful tool for optimizing such beasts is what is known as an
"independent group", which does not backtrack (see ``< (?' in this
nodepattern) '>>).  Note also that zero-length look-ahead/look-behind
assertions will not backtrack to make the tail match, since they are in
"logical" context: only whether they match is considered relevant.  For an
example where side-effects of look-ahead *might* have influenced the
following match, see ``< (?' in this nodepattern) '>>.

Version 8 Regular Expressions
-----------------------------

   In case you're not familiar with the "regular" Version 8 regex
routines, here are the pattern-matching rules not described above.

   Any single character matches itself, unless it is a *metacharacter*
with a special meaning described here or above.  You can cause characters
that normally function as metacharacters to be interpreted literally by
prefixing them with a "\" (e.g., "\." matches a ".", not any character;
"\\" matches a "\").  A series of characters matches that series of
characters in the target string, so the pattern `blurfl' would match
"blurfl" in the target string.

   You can specify a character class, by enclosing a list of characters in
[], which will match any one character from the list.  If the first
character after the "[" is "^", the class matches any character not in the
list.  Within a list, the "-" character specifies a range, so that `a-z'
represents all characters between "a" and "z", inclusive.  If you want
either "-" or "]" itself to be a member of a class, put it at the start of
the list (possibly after a "^"), or escape it with a backslash.  "-" is
also taken literally when it is at the end of the list, just before the
closing "]".  (The following all specify the same class of three
characters: `[-az]', `[az-]', and `[a\-z]'.  All are different from
`[a-z]', which specifies a class containing twenty-six characters.)  Also,
if you try to use the character classes `\w', `\W', `\s', `\S', `\d', or
`\D' as endpoints of a range, that's not a range, the "-" is understood
literally.

   Note also that the whole range idea is rather unportable between
character sets-and even within character sets they may cause results you
probably didn't expect.  A sound principle is to use only ranges that
begin from and end at either alphabets of equal case ([a-e], [A-E]), or
digits ([0-9]).  Anything else is unsafe.  If in doubt, spell out the
character sets in full.

   Characters may be specified using a metacharacter syntax much like that
used in C: "\n" matches a newline, "\t" a tab, "\r" a carriage return,
"\f" a form feed, etc.  More generally, \*nnn*, where *nnn* is a string of
octal digits, matches the character whose ASCII value is *nnn*.
Similarly, \x*nn*, where *nn* are hexadecimal digits, matches the
character whose ASCII value is *nn*. The expression \cx matches the ASCII
character control-x.  Finally, the "." metacharacter matches any character
except "\n" (unless you use `/s').

   You can specify a series of alternatives for a pattern using "|" to
separate them, so that `fee|fie|foe' will match any of "fee", "fie", or
"foe" in the target string (as would `f(e|i|o)e').  The first alternative
includes everything from the last pattern delimiter ("(", "[", or the
beginning of the pattern) up to the first "|", and the last alternative
contains everything from the last "|" to the next pattern delimiter.
That's why it's common practice to include alternatives in parentheses: to
minimize confusion about where they start and end.

   Alternatives are tried from left to right, so the first alternative
found for which the entire expression matches, is the one that is chosen.
This means that alternatives are not necessarily greedy. For example: when
matching `foo|foot' against "barefoot", only the "foo" part will match, as
that is the first alternative tried, and it successfully matches the
target string. (This might not seem important, but it is important when
you are capturing matched text using parentheses.)

   Also remember that "|" is interpreted as a literal within square
brackets, so if you write `[fee|fie|foe]' you're really only matching
`[feio|]'.

   Within a pattern, you may designate subpatterns for later reference by
enclosing them in parentheses, and you may refer back to the nth
subpattern later in the pattern using the metacharacter \n.  Subpatterns
are numbered based on the left to right order of their opening
parenthesis.  A backreference matches whatever actually matched the
subpattern in the string being examined, not the rules for that
subpattern.  Therefore, `(0|0x)\d*\s\1\d*' will match "0x1234 0x4321", but
not "0x1234 01234", because subpattern 1 matched "0x", even though the
rule `0|0x' could potentially match the leading 0 in the second number.

Warning on \1 vs $1
-------------------

   Some people get too used to writing things like:

     $pattern =~ s/(\W)/\\\1/g;

   This is grandfathered for the RHS of a substitute to avoid shocking the
*sed* addicts, but it's a dirty habit to get into.  That's because in
PerlThink, the righthand side of a s/// is a double-quoted string.  \1 in
the usual double-quoted string means a control-A.  The customary Unix
meaning of \1 is kludged in for s///.  However, if you get into the habit
of doing that, you get yourself into trouble if you then add an `/e'
modifier.

     s/(\d+)/ \1 + 1 /eg;    	# causes warning under -w

   Or if you try to do

     s/(\d+)/\1000/;

   You can't disambiguate that by saying `\{1}000', whereas you can fix it
with `${1}000'.  The operation of interpolation should not be confused
with the operation of matching a backreference.  Certainly they mean two
different things on the left side of the s///.

Repeated patterns matching zero-length substring
------------------------------------------------

   WARNING: Difficult material (and prose) ahead.  This section needs a
rewrite.

   Regular expressions provide a terse and powerful programming language.
As with most other power tools, power comes together with the ability to
wreak havoc.

   A common abuse of this power stems from the ability to make infinite
loops using regular expressions, with something as innocuous as:

     'foo' =~ m{ ( o? )* }x;

   The `o?' can match at the beginning of `'foo'', and since the position
in the string is not moved by the match, `o?' would match again and again
because of the * modifier.  Another common way to create a similar cycle
is with the looping modifier `//g':

     @matches = ( 'foo' =~ m{ o? }xg );

   or

     print "match: <$&>\n" while 'foo' =~ m{ o? }xg;

   or the loop implied by split().

   However, long experience has shown that many programming tasks may be
significantly simplified by using repeated subexpressions that may match
zero-length substrings.  Here's a simple example being:

     @chars = split //, $string;		  # // is not magic in split
     ($whitewashed = $string) =~ s/()/ /g; # parens avoid magic s// /

   Thus Perl allows such constructs, by *forcefully breaking the infinite
loop*.  The rules for this are different for lower-level loops given by
the greedy modifiers `*+{}', and for higher-level ones like the `/g'
modifier or split() operator.

   The lower-level loops are *interrupted* (that is, the loop is broken)
when Perl detects that a repeated expression matched a zero-length
substring.   Thus

     m{ (?: NON_ZERO_LENGTH | ZERO_LENGTH )* }x;

   is made equivalent to

     m{   (?: NON_ZERO_LENGTH )*
        |
          (?: ZERO_LENGTH )?
      }x;

   The higher level-loops preserve an additional state between iterations:
whether the last match was zero-length.  To break the loop, the following
match after a zero-length match is prohibited to have a length of zero.
This prohibition interacts with backtracking (see `"Backtracking"' in this
node), and so the *second best* match is chosen if the best match is of
zero length.

   For example:

     $_ = 'bar';
     s/\w??/<$&>/g;

   results in `"<'<b><><a><><r><>">.  At each position of the string the
best match given by non-greedy `??' is the zero-length match, and the
*second best* match is what is matched by `\w'.  Thus zero-length matches
alternate with one-character-long matches.

   Similarly, for repeated `m/()/g' the second-best match is the match at
the position one notch further in the string.

   The additional state of being *matched with zero-length* is associated
with the matched string, and is reset by each assignment to pos().
Zero-length matches at the end of the previous match are ignored during
split.

Combining pieces together
-------------------------

   Each of the elementary pieces of regular expressions which were
described before (such as `ab' or `\Z') could match at most one substring
at the given position of the input string.  However, in a typical regular
expression these elementary pieces are combined into more complicated
patterns using combining operators ST, `S|T', `S*' etc (in these examples
S and T are regular subexpressions).

   Such combinations can include alternatives, leading to a problem of
choice: if we match a regular expression `a|ab' against `"abc"', will it
match substring `"a"' or `"ab"'?  One way to describe which substring is
actually matched is the concept of backtracking (see `"Backtracking"' in
this node).  However, this description is too low-level and makes you think
in terms of a particular implementation.

   Another description starts with notions of "better"/"worse".  All the
substrings which may be matched by the given regular expression can be
sorted from the "best" match to the "worst" match, and it is the "best"
match which is chosen.  This substitutes the question of "what is chosen?"
by the question of "which matches are better, and which are worse?".

   Again, for elementary pieces there is no such question, since at most
one match at a given position is possible.  This section describes the
notion of better/worse for combining operators.  In the description below
S and T are regular subexpressions.

ST
     Consider two possible matches, `AB' and `A'B'', A and `A'' are
     substrings which can be matched by S, B and `B'' are substrings which
     can be matched by T.

     If A is better match for S than `A'', `AB' is a better match than
     `A'B''.

     If A and `A'' coincide: `AB' is a better match than `AB'' if B is
     better match for T than `B''.

`S|T'
     When S can match, it is a better match than when only T can match.

     Ordering of two matches for S is the same as for S.  Similar for two
     matches for T.

`S{REPEAT_COUNT}'
     Matches as `SSS...S' (repeated as many times as necessary).

`S{min,max}'
     Matches as `S{max}|S{max-1}|...|S{min+1}|S{min}'.

`S{min,max}?'
     Matches as `S{min}|S{min+1}|...|S{max-1}|S{max}'.

`S?', `S*', `S+'
     Same as `S{0,1}', `S{0,BIG_NUMBER}', `S{1,BIG_NUMBER}' respectively.

`S??', `S*?', `S+?'
     Same as `S{0,1}?', `S{0,BIG_NUMBER}?', `S{1,BIG_NUMBER}?'
     respectively.

`< (?'S) >>
     Matches the best match for S and only that.

`(?=S)', `(?<=S)'
     Only the best match for S is considered.  (This is important only if
     S has capturing parentheses, and backreferences are used somewhere
     else in the whole regular expression.)

`(?!S)', `(?<!S)'
     For this grouping operator there is no need to describe the ordering,
     since only whether or not S can match is important.

`(??{ EXPR })'
     The ordering is the same as for the regular expression which is the
     result of EXPR.

`(?(condition)yes-pattern|no-pattern)'
     Recall that which of `yes-pattern' or `no-pattern' actually matches is
     already determined.  The ordering of the matches is the same as for
     the chosen subexpression.

   The above recipes describe the ordering of matches *at a given
position*.  One more rule is needed to understand how a match is
determined for the whole regular expression: a match at an earlier
position is always better than a match at a later position.

Creating custom RE engines
--------------------------

   Overloaded constants (see *Note Overload: (pm.info)overload,) provide a
simple way to extend the functionality of the RE engine.

   Suppose that we want to enable a new RE escape-sequence `\Y|' which
matches at boundary between white-space characters and non-whitespace
characters.  Note that `(?=\S)(?<!\S)|(?!\S)(?<=\S)' matches exactly at
these positions, so we want to have each `\Y|' in the place of the more
complicated version.  We can create a module `customre' to do this:

     package customre;
     use overload;

     sub import {
       shift;
       die "No argument to customre::import allowed" if @_;
       overload::constant 'qr' => \&convert;
     }

     sub invalid { die "/$_[0]/: invalid escape '\\$_[1]'"}

     my %rules = ( '\\' => '\\',
     		  'Y|' => qr/(?=\S)(?<!\S)|(?!\S)(?<=\S)/ );
     sub convert {
       my $re = shift;
       $re =~ s{
                 \\ ( \\ | Y . )
               }
               { $rules{$1} or invalid($re,$1) }sgex;
       return $re;
     }

   Now `use customre' enables the new escape in constant regular
expressions, i.e., those without any runtime variable interpolations.  As
documented in *Note Overload: (pm.info)overload,, this conversion will
work only over literal parts of regular expressions.  For `\Y|$re\Y|' the
variable part of this regular expression needs to be converted explicitly
(but only if the special meaning of `\Y|' should be enabled inside $re):

     use customre;
     $re = <>;
     chomp $re;
     $re = customre::convert $re;
     /\Y|$re\Y|/;

BUGS
====

   This document varies from difficult to understand to completely and
utterly opaque.  The wandering prose riddled with jargon is hard to fathom
in several places.

   This document needs a rewrite that separates the tutorial content from
the reference content.

SEE ALSO
========

   `"Regexp Quote-Like Operators"', *Note Perlop: perlop,.

   `"Gory details of parsing quoted constructs"', *Note Perlop: perlop,.

   *Note Perlfaq6: perlfaq6,.

   `pos', *Note Perlfunc: perlfunc,.

   *Note Perllocale: perllocale,.

   *Mastering Regular Expressions* by Jeffrey Friedl, published by
O'Reilly and Associates.


File: perl.info,  Node: perlref,  Next: perldsc,  Prev: perlreftut,  Up: Top

Perl references and nested data structures
******************************************

NAME
====

   perlref - Perl references and nested data structures

NOTE
====

   This is complete documentation about all aspects of references.  For a
shorter, tutorial introduction to just the essential features, see *Note
Perlreftut: perlreftut,.

DESCRIPTION
===========

   Before release 5 of Perl it was difficult to represent complex data
structures, because all references had to be symbolic-and even then it was
difficult to refer to a variable instead of a symbol table entry.  Perl
now not only makes it easier to use symbolic references to variables, but
also lets you have "hard" references to any piece of data or code.  Any
scalar may hold a hard reference.  Because arrays and hashes contain
scalars, you can now easily build arrays of arrays, arrays of hashes,
hashes of arrays, arrays of hashes of functions, and so on.

   Hard references are smart-they keep track of reference counts for you,
automatically freeing the thing referred to when its reference count goes
to zero.  (Reference counts for values in self-referential or cyclic data
structures may not go to zero without a little help; see `"Two-Phased
Garbage Collection"', *Note Perlobj: perlobj, for a detailed explanation.)
If that thing happens to be an object, the object is destructed.  See
`"Two-Phased Garbage Collection"', *Note Perlobj: perlobj, for more about
objects.  (In a sense, everything in Perl is an object, but we usually
reserve the word for references to objects that have been officially
"blessed" into a class package.)

   Symbolic references are names of variables or other objects, just as a
symbolic link in a Unix filesystem contains merely the name of a file.
The `*glob' notation is something of a of symbolic reference.  (Symbolic
references are sometimes called "soft references", but please don't call
them that; references are confusing enough without useless synonyms.)

   In contrast, hard references are more like hard links in a Unix file
system: They are used to access an underlying object without concern for
what its (other) name is.  When the word "reference" is used without an
adjective, as in the following paragraph, it is usually talking about a
hard reference.

   References are easy to use in Perl.  There is just one overriding
principle: Perl does no implicit referencing or dereferencing.  When a
scalar is holding a reference, it always behaves as a simple scalar.  It
doesn't magically start being an array or hash or subroutine; you have to
tell it explicitly to do so, by dereferencing it.

Making References
-----------------

   References can be created in several ways.

  1. By using the backslash operator on a variable, subroutine, or value.
     (This works much like the & (address-of) operator in C.)  This
     typically creates *another* reference to a variable, because there's
     already a reference to the variable in the symbol table.  But the
     symbol table reference might go away, and you'll still have the
     reference that the backslash returned.  Here are some examples:

          $scalarref = \$foo;
          $arrayref  = \@ARGV;
          $hashref   = \%ENV;
          $coderef   = \&handler;
          $globref   = \*foo;

     It isn't possible to create a true reference to an IO handle
     (filehandle or dirhandle) using the backslash operator.  The most you
     can get is a reference to a typeglob, which is actually a complete
     symbol table entry.  But see the explanation of the `*foo{THING}'
     syntax below.  However, you can still use type globs and globrefs as
     though they were IO handles.

  2. A reference to an anonymous array can be created using square
     brackets:

          $arrayref = [1, 2, ['a', 'b', 'c']];

     Here we've created a reference to an anonymous array of three elements
     whose final element is itself a reference to another anonymous array
     of three elements.  (The multidimensional syntax described later can
     be used to access this.  For example, after the above, `<
     $arrayref-'[2][1] >> would have the value "b".)

     Taking a reference to an enumerated list is not the same as using
     square brackets-instead it's the same as creating a list of
     references!

          @list = (\$a, \@b, \%c);
          @list = \($a, @b, %c);	# same thing!

     As a special case, `\(@foo)' returns a list of references to the
     contents of `@foo', not a reference to `@foo' itself.  Likewise for
     `%foo', except that the key references are to copies (since the keys
     are just strings rather than full-fledged scalars).

  3. A reference to an anonymous hash can be created using curly brackets:

          $hashref = {
          	'Adam'  => 'Eve',
          	'Clyde' => 'Bonnie',
          };

     Anonymous hash and array composers like these can be intermixed
     freely to produce as complicated a structure as you want.  The
     multidimensional syntax described below works for these too.  The
     values above are literals, but variables and expressions would work
     just as well, because assignment operators in Perl (even within
     local() or my()) are executable statements, not compile-time
     declarations.

     Because curly brackets (braces) are used for several other things
     including BLOCKs, you may occasionally have to disambiguate braces at
     the beginning of a statement by putting a + or a return in front so
     that Perl realizes the opening brace isn't starting a BLOCK.  The
     economy and mnemonic value of using curlies is deemed worth this
     occasional extra hassle.

     For example, if you wanted a function to make a new hash and return a
     reference to it, you have these options:

          sub hashem {        { @_ } }   # silently wrong
          sub hashem {       +{ @_ } }   # ok
          sub hashem { return { @_ } }   # ok

     On the other hand, if you want the other meaning, you can do this:

          sub showem {        { @_ } }   # ambiguous (currently ok, but may change)
          sub showem {       {; @_ } }   # ok
          sub showem { { return @_ } }   # ok

     The leading `+{' and `{;' always serve to disambiguate the expression
     to mean either the HASH reference, or the BLOCK.

  4. A reference to an anonymous subroutine can be created by using sub
     without a subname:

          $coderef = sub { print "Boink!\n" };

     Note the semicolon.  Except for the code inside not being immediately
     executed, a `sub {}' is not so much a declaration as it is an
     operator, like `do{}' or `eval{}'.  (However, no matter how many
     times you execute that particular line (unless you're in an
     `eval("...")'), $coderef will still have a reference to the *same*
     anonymous subroutine.)

     Anonymous subroutines act as closures with respect to my() variables,
     that is, variables lexically visible within the current scope.
     Closure is a notion out of the Lisp world that says if you define an
     anonymous function in a particular lexical context, it pretends to
     run in that context even when it's called outside the context.

     In human terms, it's a funny way of passing arguments to a subroutine
     when you define it as well as when you call it.  It's useful for
     setting up little bits of code to run later, such as callbacks.  You
     can even do object-oriented stuff with it, though Perl already
     provides a different mechanism to do that-see *Note Perlobj: perlobj,.

     You might also think of closure as a way to write a subroutine
     template without using eval().  Here's a small example of how
     closures work:

          sub newprint {
          	my $x = shift;
          	return sub { my $y = shift; print "$x, $y!\n"; };
          }
          $h = newprint("Howdy");
          $g = newprint("Greetings");

          # Time passes...

          &$h("world");
          &$g("earthlings");

     This prints

          Howdy, world!
          Greetings, earthlings!

     Note particularly that $x continues to refer to the value passed into
     newprint() *despite* "my $x" having gone out of scope by the time the
     anonymous subroutine runs.  That's what a closure is all about.

     This applies only to lexical variables, by the way.  Dynamic variables
     continue to work as they have always worked.  Closure is not something
     that most Perl programmers need trouble themselves about to begin
     with.

  5. References are often returned by special subroutines called
     constructors.  Perl objects are just references to a special type of
     object that happens to know which package it's associated with.
     Constructors are just special subroutines that know how to create
     that association.  They do so by starting with an ordinary reference,
     and it remains an ordinary reference even while it's also being an
     object.  Constructors are often named new() and called indirectly:

          $objref = new Doggie (Tail => 'short', Ears => 'long');

     But don't have to be:

          $objref   = Doggie->new(Tail => 'short', Ears => 'long');

          use Term::Cap;
          $terminal = Term::Cap->Tgetent( { OSPEED => 9600 });

          use Tk;
          $main    = MainWindow->new();
          $menubar = $main->Frame(-relief              => "raised",
                                  -borderwidth         => 2)

  6. References of the appropriate type can spring into existence if you
     dereference them in a context that assumes they exist.  Because we
     haven't talked about dereferencing yet, we can't show you any
     examples yet.

  7. A reference can be created by using a special syntax, lovingly known
     as the *foo{THING} syntax.  *foo{THING} returns a reference to the
     THING slot in *foo (which is the symbol table entry which holds
     everything known as foo).

          $scalarref = *foo{SCALAR};
          $arrayref  = *ARGV{ARRAY};
          $hashref   = *ENV{HASH};
          $coderef   = *handler{CODE};
          $ioref     = *STDIN{IO};
          $globref   = *foo{GLOB};

     All of these are self-explanatory except for `*foo{IO}'.  It returns
     the IO handle, used for file handles (`open', *Note Perlfunc:
     perlfunc,), sockets (`socket', *Note Perlfunc: perlfunc, and
     `socketpair', *Note Perlfunc: perlfunc,), and directory handles
     (`opendir', *Note Perlfunc: perlfunc,).  For compatibility with
     previous versions of Perl, `*foo{FILEHANDLE}' is a synonym for
     `*foo{IO}'.

     `*foo{THING}' returns undef if that particular THING hasn't been used
     yet, except in the case of scalars.  `*foo{SCALAR}' returns a
     reference to an anonymous scalar if $foo hasn't been used yet.  This
     might change in a future release.

     `*foo{IO}' is an alternative to the `*HANDLE' mechanism given in
     `"Typeglobs and Filehandles"', *Note Perldata: perldata, for passing
     filehandles into or out of subroutines, or storing into larger data
     structures.  Its disadvantage is that it won't create a new
     filehandle for you.  Its advantage is that you have less risk of
     clobbering more than you want to with a typeglob assignment.  (It
     still conflates file and directory handles, though.)  However, if you
     assign the incoming value to a scalar instead of a typeglob as we do
     in the examples below, there's no risk of that happening.

          splutter(*STDOUT);		# pass the whole glob
          splutter(*STDOUT{IO});	# pass both file and dir handles

          sub splutter {
          	my $fh = shift;
          	print $fh "her um well a hmmm\n";
          }

          $rec = get_rec(*STDIN);	# pass the whole glob
          $rec = get_rec(*STDIN{IO}); # pass both file and dir handles

          sub get_rec {
          	my $fh = shift;
          	return scalar <$fh>;
          }


Using References
----------------

   That's it for creating references.  By now you're probably dying to
know how to use references to get back to your long-lost data.  There are
several basic methods.

  1. Anywhere you'd put an identifier (or chain of identifiers) as part of
     a variable or subroutine name, you can replace the identifier with a
     simple scalar variable containing a reference of the correct type:

          $bar = $$scalarref;
          push(@$arrayref, $filename);
          $$arrayref[0] = "January";
          $$hashref{"KEY"} = "VALUE";
          &$coderef(1,2,3);
          print $globref "output\n";

     It's important to understand that we are specifically not
     dereferencing `$arrayref[0]' or `$hashref{"KEY"}' there.  The
     dereference of the scalar variable happens before it does any key
     lookups.  Anything more complicated than a simple scalar variable
     must use methods 2 or 3 below.  However, a "simple scalar" includes
     an identifier that itself uses method 1 recursively.  Therefore, the
     following prints "howdy".

          $refrefref = \\\"howdy";
          print $$$$refrefref;

  2. Anywhere you'd put an identifier (or chain of identifiers) as part of
     a variable or subroutine name, you can replace the identifier with a
     BLOCK returning a reference of the correct type.  In other words, the
     previous examples could be written like this:

          $bar = ${$scalarref};
          push(@{$arrayref}, $filename);
          ${$arrayref}[0] = "January";
          ${$hashref}{"KEY"} = "VALUE";
          &{$coderef}(1,2,3);
          $globref->print("output\n");  # iff IO::Handle is loaded

     Admittedly, it's a little silly to use the curlies in this case, but
     the BLOCK can contain any arbitrary expression, in particular,
     subscripted expressions:

          &{ $dispatch{$index} }(1,2,3);	# call correct routine

     Because of being able to omit the curlies for the simple case of
     `$$x', people often make the mistake of viewing the dereferencing
     symbols as proper operators, and wonder about their precedence.  If
     they were, though, you could use parentheses instead of braces.
     That's not the case.  Consider the difference below; case 0 is a
     short-hand version of case 1, not case 2:

          $$hashref{"KEY"}   = "VALUE";	# CASE 0
          ${$hashref}{"KEY"} = "VALUE";	# CASE 1
          ${$hashref{"KEY"}} = "VALUE";	# CASE 2
          ${$hashref->{"KEY"}} = "VALUE";	# CASE 3

     Case 2 is also deceptive in that you're accessing a variable called
     %hashref, not dereferencing through $hashref to the hash it's
     presumably referencing.  That would be case 3.

  3. Subroutine calls and lookups of individual array elements arise often
     enough that it gets cumbersome to use method 2.  As a form of
     syntactic sugar, the examples for method 2 may be written:

          $arrayref->[0] = "January";   # Array element
          $hashref->{"KEY"} = "VALUE";  # Hash element
          $coderef->(1,2,3);            # Subroutine call

     The left side of the arrow can be any expression returning a
     reference, including a previous dereference.  Note that `$array[$x]'
     is not the same thing as `< $array-'[$x] >> here:

          $array[$x]->{"foo"}->[0] = "January";

     This is one of the cases we mentioned earlier in which references
     could spring into existence when in an lvalue context.  Before this
     statement, `$array[$x]' may have been undefined.  If so, it's
     automatically defined with a hash reference so that we can look up
     `{"foo"}' in it.  Likewise `< $array[$x]-'{"foo"} >> will
     automatically get defined with an array reference so that we can look
     up [0] in it.  This process is called *autovivification*.

     One more thing here.  The arrow is optional *between* brackets
     subscripts, so you can shrink the above down to

          $array[$x]{"foo"}[0] = "January";

     Which, in the degenerate case of using only ordinary arrays, gives you
     multidimensional arrays just like C's:

          $score[$x][$y][$z] += 42;

     Well, okay, not entirely like C's arrays, actually.  C doesn't know
     how to grow its arrays on demand.  Perl does.

  4. If a reference happens to be a reference to an object, then there are
     probably methods to access the things referred to, and you should
     probably stick to those methods unless you're in the class package
     that defines the object's methods.  In other words, be nice, and
     don't violate the object's encapsulation without a very good reason.
     Perl does not enforce encapsulation.  We are not totalitarians here.
     We do expect some basic civility though.

        Using a string or number as a reference produces a symbolic
reference, as explained above.  Using a reference as a number produces an
integer representing its storage location in memory.  The only useful
thing to be done with this is to compare two references numerically to see
whether they refer to the same location.

     if ($ref1 == $ref2) {  # cheap numeric compare of references
     	print "refs 1 and 2 refer to the same thing\n";
     }

   Using a reference as a string produces both its referent's type,
including any package blessing as described in *Note Perlobj: perlobj,, as
well as the numeric address expressed in hex.  The ref() operator returns
just the type of thing the reference is pointing to, without the address.
See `ref', *Note Perlfunc: perlfunc, for details and examples of its use.

   The bless() operator may be used to associate the object a reference
points to with a package functioning as an object class.  See *Note
Perlobj: perlobj,.

   A typeglob may be dereferenced the same way a reference can, because
the dereference syntax always indicates the type of reference desired.  So
`${*foo}' and `${\$foo}' both indicate the same scalar variable.

   Here's a trick for interpolating a subroutine call into a string:

     print "My sub returned @{[mysub(1,2,3)]} that time.\n";

   The way it works is that when the `@{...}' is seen in the double-quoted
string, it's evaluated as a block.  The block creates a reference to an
anonymous array containing the results of the call to `mysub(1,2,3)'.  So
the whole block returns a reference to an array, which is then
dereferenced by `@{...}' and stuck into the double-quoted string. This
chicanery is also useful for arbitrary expressions:

     print "That yields @{[$n + 5]} widgets\n";

Symbolic references
-------------------

   We said that references spring into existence as necessary if they are
undefined, but we didn't say what happens if a value used as a reference
is already defined, but *isn't* a hard reference.  If you use it as a
reference, it'll be treated as a symbolic reference.  That is, the value
of the scalar is taken to be the name of a variable, rather than a direct
link to a (possibly) anonymous value.

   People frequently expect it to work like this.  So it does.

     $name = "foo";
     $$name = 1;			# Sets $foo
     ${$name} = 2;		# Sets $foo
     ${$name x 2} = 3;		# Sets $foofoo
     $name->[0] = 4;		# Sets $foo[0]
     @$name = ();		# Clears @foo
     &$name();			# Calls &foo() (as in Perl 4)
     $pack = "THAT";
     ${"${pack}::$name"} = 5;	# Sets $THAT::foo without eval

   This is powerful, and slightly dangerous, in that it's possible to
intend (with the utmost sincerity) to use a hard reference, and
accidentally use a symbolic reference instead.  To protect against that,
you can say

     use strict 'refs';

   and then only hard references will be allowed for the rest of the
enclosing block.  An inner block may countermand that with

     no strict 'refs';

   Only package variables (globals, even if localized) are visible to
symbolic references.  Lexical variables (declared with my()) aren't in a
symbol table, and thus are invisible to this mechanism.  For example:

     local $value = 10;
     $ref = "value";
     {
     	my $value = 20;
     	print $$ref;
     }

   This will still print 10, not 20.  Remember that local() affects package
variables, which are all "global" to the package.

Not-so-symbolic references
--------------------------

   A new feature contributing to readability in perl version 5.001 is that
the brackets around a symbolic reference behave more like quotes, just as
they always have within a string.  That is,

     $push = "pop on ";
     print "${push}over";

   has always meant to print "pop on over", even though push is a reserved
word.  This has been generalized to work the same outside of quotes, so
that

     print ${push} . "over";

   and even

     print ${ push } . "over";

   will have the same effect.  (This would have been a syntax error in
Perl 5.000, though Perl 4 allowed it in the spaceless form.)  This
construct is not considered to be a symbolic reference when you're using
strict refs:

     use strict 'refs';
     ${ bareword };	# Okay, means $bareword.
     ${ "bareword" };	# Error, symbolic reference.

   Similarly, because of all the subscripting that is done using single
words, we've applied the same rule to any bareword that is used for
subscripting a hash.  So now, instead of writing

     $array{ "aaa" }{ "bbb" }{ "ccc" }

   you can write just

     $array{ aaa }{ bbb }{ ccc }

   and not worry about whether the subscripts are reserved words.  In the
rare event that you do wish to do something like

     $array{ shift }

   you can force interpretation as a reserved word by adding anything that
makes it more than a bareword:

     $array{ shift() }
     $array{ +shift }
     $array{ shift @_ }

   The `use warnings' pragma or the -w switch will warn you if it
interprets a reserved word as a string.  But it will no longer warn you
about using lowercase words, because the string is effectively quoted.

Pseudo-hashes: Using an array as a hash
---------------------------------------

   WARNING:  This section describes an experimental feature.  Details may
change without notice in future versions.

   Beginning with release 5.005 of Perl, you may use an array reference in
some contexts that would normally require a hash reference.  This allows
you to access array elements using symbolic names, as if they were fields
in a structure.

   For this to work, the array must contain extra information.  The first
element of the array has to be a hash reference that maps field names to
array indices.  Here is an example:

     $struct = [{foo => 1, bar => 2}, "FOO", "BAR"];

     $struct->{foo};  # same as $struct->[1], i.e. "FOO"
     $struct->{bar};  # same as $struct->[2], i.e. "BAR"

     keys %$struct;   # will return ("foo", "bar") in some order
     values %$struct; # will return ("FOO", "BAR") in same some order

     while (my($k,$v) = each %$struct) {
        print "$k => $v\n";
     }

   Perl will raise an exception if you try to access nonexistent fields.
To avoid inconsistencies, always use the fields::phash() function provided
by the fields pragma.

     use fields;
     $pseudohash = fields::phash(foo => "FOO", bar => "BAR");

   For better performance, Perl can also do the translation from field
names to array indices at compile time for typed object references.  See
*Note Fields: (pm.info)fields,.

   There are two ways to check for the existence of a key in a
pseudo-hash.  The first is to use exists().  This checks to see if the
given field has ever been set.  It acts this way to match the behavior of
a regular hash.  For instance:

     use fields;
     $phash = fields::phash([qw(foo bar pants)], ['FOO']);
     $phash->{pants} = undef;

     print exists $phash->{foo};    # true, 'foo' was set in the declaration
     print exists $phash->{bar};    # false, 'bar' has not been used.
     print exists $phash->{pants};  # true, your 'pants' have been touched

   The second is to use exists() on the hash reference sitting in the
first array element.  This checks to see if the given key is a valid field
in the pseudo-hash.

     print exists $phash->[0]{bar};	# true, 'bar' is a valid field
     print exists $phash->[0]{shoes};# false, 'shoes' can't be used

   delete() on a pseudo-hash element only deletes the value corresponding
to the key, not the key itself.  To delete the key, you'll have to
explicitly delete it from the first hash element.

     print delete $phash->{foo};     # prints $phash->[1], "FOO"
     print exists $phash->{foo};     # false
     print exists $phash->[0]{foo};  # true, key still exists
     print delete $phash->[0]{foo};  # now key is gone
     print $phash->{foo};            # runtime exception

Function Templates
------------------

   As explained above, a closure is an anonymous function with access to
the lexical variables visible when that function was compiled.  It retains
access to those variables even though it doesn't get run until later, such
as in a signal handler or a Tk callback.

   Using a closure as a function template allows us to generate many
functions that act similarly.  Suppose you wanted functions named after
the colors that generated HTML font changes for the various colors:

     print "Be ", red("careful"), "with that ", green("light");

   The red() and green() functions would be similar.  To create these,
we'll assign a closure to a typeglob of the name of the function we're
trying to build.

     @colors = qw(red blue green yellow orange purple violet);
     for my $name (@colors) {
         no strict 'refs';	# allow symbol table manipulation
         *$name = *{uc $name} = sub { "<FONT COLOR='$name'>@_</FONT>" };
     }

   Now all those different functions appear to exist independently.  You
can call red(), RED(), blue(), BLUE(), green(), etc.  This technique saves
on both compile time and memory use, and is less error-prone as well, since
syntax checks happen at compile time.  It's critical that any variables in
the anonymous subroutine be lexicals in order to create a proper closure.
That's the reasons for the my on the loop iteration variable.

   This is one of the only places where giving a prototype to a closure
makes much sense.  If you wanted to impose scalar context on the arguments
of these functions (probably not a wise idea for this particular example),
you could have written it this way instead:

     *$name = sub ($) { "<FONT COLOR='$name'>$_[0]</FONT>" };

   However, since prototype checking happens at compile time, the
assignment above happens too late to be of much use.  You could address
this by putting the whole loop of assignments within a BEGIN block,
forcing it to occur during compilation.

   Access to lexicals that change over type-like those in the for loop
above-only works with closures, not general subroutines.  In the general
case, then, named subroutines do not nest properly, although anonymous
ones do.  If you are accustomed to using nested subroutines in other
programming languages with their own private variables, you'll have to
work at it a bit in Perl.  The intuitive coding of this type of thing
incurs mysterious warnings about "will not stay shared".  For example,
this won't work:

     sub outer {
         my $x = $_[0] + 35;
         sub inner { return $x * 19 }   # WRONG
         return $x + inner();
     }

   A work-around is the following:

     sub outer {
         my $x = $_[0] + 35;
         local *inner = sub { return $x * 19 };
         return $x + inner();
     }

   Now inner() can only be called from within outer(), because of the
temporary assignments of the closure (anonymous subroutine).  But when it
does, it has normal access to the lexical variable $x from the scope of
outer().

   This has the interesting effect of creating a function local to another
function, something not normally supported in Perl.

WARNING
=======

   You may not (usefully) use a reference as the key to a hash.  It will be
converted into a string:

     $x{ \$a } = $a;

   If you try to dereference the key, it won't do a hard dereference, and
you won't accomplish what you're attempting.  You might want to do
something more like

     $r = \@a;
     $x{ $r } = $r;

   And then at least you can use the values(), which will be real refs,
instead of the keys(), which won't.

   The standard Tie::RefHash module provides a convenient workaround to
this.

SEE ALSO
========

   Besides the obvious documents, source code can be instructive.  Some
pathological examples of the use of references can be found in the
`t/op/ref.t' regression test in the Perl source directory.

   See also *Note Perldsc: perldsc, and *Note Perllol: perllol, for how to
use references to create complex data structures, and *Note Perltoot:
perltoot,, *Note Perlobj: perlobj,, and *Note Perlbot: perlbot, for how to
use them to create objects.


File: perl.info,  Node: perlreftut,  Next: perlref,  Prev: perllocale,  Up: Top

Mark's very short tutorial about references
*******************************************

NAME
====

   perlreftut - Mark's very short tutorial about references

DESCRIPTION
===========

   One of the most important new features in Perl 5 was the capability to
manage complicated data structures like multidimensional arrays and nested
hashes.  To enable these, Perl 5 introduced a feature called `references',
and using references is the key to managing complicated, structured data
in Perl.  Unfortunately, there's a lot of funny syntax to learn, and the
main manual page can be hard to follow.  The manual is quite complete, and
sometimes people find that a problem, because it can be hard to tell what
is important and what isn't.

   Fortunately, you only need to know 10% of what's in the main page to get
90% of the benefit.  This page will show you that 10%.

Who Needs Complicated Data Structures?
======================================

   One problem that came up all the time in Perl 4 was how to represent a
hash whose values were lists.  Perl 4 had hashes, of course, but the
values had to be scalars; they couldn't be lists.

   Why would you want a hash of lists?  Let's take a simple example: You
have a file of city and country names, like this:

     Chicago, USA
     Frankfurt, Germany
     Berlin, Germany
     Washington, USA
     Helsinki, Finland
     New York, USA

   and you want to produce an output like this, with each country mentioned
once, and then an alphabetical list of the cities in that country:

     Finland: Helsinki.
     Germany: Berlin, Frankfurt.
     USA:  Chicago, New York, Washington.

   The natural way to do this is to have a hash whose keys are country
names.  Associated with each country name key is a list of the cities in
that country.  Each time you read a line of input, split it into a country
and a city, look up the list of cities already known to be in that
country, and append the new city to the list.  When you're done reading
the input, iterate over the hash as usual, sorting each list of cities
before you print it out.

   If hash values can't be lists, you lose.  In Perl 4, hash values can't
be lists; they can only be strings.  You lose.  You'd probably have to
combine all the cities into a single string somehow, and then when time
came to write the output, you'd have to break the string into a list, sort
the list, and turn it back into a string.  This is messy and error-prone.
And it's frustrating, because Perl already has perfectly good lists that
would solve the problem if only you could use them.

The Solution
============

   By the time Perl 5 rolled around, we were already stuck with this
design: Hash values must be scalars.  The solution to this is references.

   A reference is a scalar value that *refers to* an entire array or an
entire hash (or to just about anything else).  Names are one kind of
reference that you're already familiar with.  Think of the President: a
messy, inconvenient bag of blood and bones.  But to talk about him, or to
represent him in a computer program, all you need is the easy, convenient
scalar string "Bill Clinton".

   References in Perl are like names for arrays and hashes.  They're
Perl's private, internal names, so you can be sure they're unambiguous.
Unlike "Bill Clinton", a reference only refers to one thing, and you
always know what it refers to.  If you have a reference to an array, you
can recover the entire array from it.  If you have a reference to a hash,
you can recover the entire hash.  But the reference is still an easy,
compact scalar value.

   You can't have a hash whose values are arrays; hash values can only be
scalars.  We're stuck with that.  But a single reference can refer to an
entire array, and references are scalars, so you can have a hash of
references to arrays, and it'll act a lot like a hash of arrays, and it'll
be just as useful as a hash of arrays.

   We'll come back to this city-country problem later, after we've seen
some syntax for managing references.

Syntax
======

   There are just two ways to make a reference, and just two ways to use
it once you have it.

Making References
-----------------

   *Make Rule 1*

   If you put a \ in front of a variable, you get a reference to that
variable.

     $aref = \@array;         # $aref now holds a reference to @array
     $href = \%hash;          # $href now holds a reference to %hash

   Once the reference is stored in a variable like $aref or $href, you can
copy it or store it just the same as any other scalar value:

     $xy = $aref;             # $xy now holds a reference to @array
     $p[3] = $href;           # $p[3] now holds a reference to %hash
     $z = $p[3];              # $z now holds a reference to %hash

   These examples show how to make references to variables with names.
Sometimes you want to make an array or a hash that doesn't have a name.
This is analogous to the way you like to be able to use the string `"\n"'
or the number 80 without having to store it in a named variable first.

   *Make Rule 2*

   `[ ITEMS ]' makes a new, anonymous array, and returns a reference to
that array. `{ ITEMS }' makes a new, anonymous hash. and returns a
reference to that hash.

     $aref = [ 1, "foo", undef, 13 ];
     # $aref now holds a reference to an array

     $href = { APR => 4, AUG => 8 };
     # $href now holds a reference to a hash

   The references you get from rule 2 are the same kind of references that
you get from rule 1:

     # This:
     $aref = [ 1, 2, 3 ];

     # Does the same as this:
     @array = (1, 2, 3);
     $aref = \@array;

   The first line is an abbreviation for the following two lines, except
that it doesn't create the superfluous array variable `@array'.

Using References
----------------

   What can you do with a reference once you have it?  It's a scalar
value, and we've seen that you can store it as a scalar and get it back
again just like any scalar.  There are just two more ways to use it:

   *Use Rule 1*

   If `$aref' contains a reference to an array, then you can put `{$aref}'
anywhere you would normally put the name of an array.  For example,
`@{$aref}' instead of `@array'.

   Here are some examples of that:

   Arrays:

     @a		@{$aref}		An array
     reverse @a	reverse @{$aref}	Reverse the array
     $a[3]		${$aref}[3]		An element of the array
     $a[3] = 17;	${$aref}[3] = 17	Assigning an element

   On each line are two expressions that do the same thing.  The left-hand
versions operate on the array `@a', and the right-hand versions operate on
the array that is referred to by `$aref', but once they find the array
they're operating on, they do the same things to the arrays.

   Using a hash reference is *exactly* the same:

     %h		%{$href}	      A hash
     keys %h		keys %{$href}	      Get the keys from the hash
     $h{'red'}	${$href}{'red'}	      An element of the hash
     $h{'red'} = 17	${$href}{'red'} = 17  Assigning an element

   *Use Rule 2*

   `${$aref}[3]' is too hard to read, so you can write `< $aref-'[3] >>
instead.

   `${$href}{red}' is too hard to read, so you can write `< $href-'{red}
>> instead.

   Most often, when you have an array or a hash, you want to get or set a
single element from it.  `${$aref}[3]' and `${$href}{'red'}' have too much
punctuation, and Perl lets you abbreviate.

   If `$aref' holds a reference to an array, then `< $aref-'[3] >> is the
fourth element of the array.  Don't confuse this with `$aref[3]', which is
the fourth element of a totally different array, one deceptively named
`@aref'.  `$aref' and `@aref' are unrelated the same way that $item and
`@item' are.

   Similarly, `< $href-'{'red'} >> is part of the hash referred to by the
scalar variable $href, perhaps even one with no name.  `$href{'red'}' is
part of the deceptively named `%href' hash.  It's easy to forget to leave
out the `< -' >>, and if you do, you'll get bizarre results when your
program gets array and hash elements out of totally unexpected hashes and
arrays that weren't the ones you wanted to use.

An Example
==========

   Let's see a quick example of how all this is useful.

   First, remember that `[1, 2, 3]' makes an anonymous array containing
`(1, 2, 3)', and gives you a reference to that array.

   Now think about

     @a = ( [1, 2, 3],
                    [4, 5, 6],
            [7, 8, 9]
                  );

   @a is an array with three elements, and each one is a reference to
another array.

   `$a[1]' is one of these references.  It refers to an array, the array
containing `(4, 5, 6)', and because it is a reference to an array, *USE
RULE 2* says that we can write `< $a[1]-'[2] >> to get the third element
from that array.  `< $a[1]-'[2] >> is the 6.  Similarly, `< $a[0]-'[1] >>
is the 2.  What we have here is like a two-dimensional array; you can
write `< $a[ROW]-'[COLUMN] >> to get or set the element in any row and any
column of the array.

   The notation still looks a little cumbersome, so there's one more
abbreviation:

Arrow Rule
==========

   In between two *subscripts*, the arrow is optional.

   Instead of `< $a[1]-'[2] >>, we can write `$a[1][2]'; it means the same
thing.  Instead of `< $a[0]-'[1] >>, we can write `$a[0][1]'; it means the
same thing.

   Now it really looks like two-dimensional arrays!

   You can see why the arrows are important.  Without them, we would have
had to write `${$a[1]}[2]' instead of `$a[1][2]'.  For three-dimensional
arrays, they let us write `$x[2][3][5]' instead of the unreadable
`${${$x[2]}[3]}[5]'.

Solution
========

   Here's the answer to the problem I posed earlier, of reformatting a
file of city and country names.

     1   while (<>) {
     2     chomp;
     3     my ($city, $country) = split /, /;
     4     push @{$table{$country}}, $city;
     5   }
     6
     7   foreach $country (sort keys %table) {
     8     print "$country: ";
     9     my @cities = @{$table{$country}};
        10     print join ', ', sort @cities;
        11     print ".\n";
        12	}

   The program has two pieces:  Lines 1-5 read the input and build a data
structure, and lines 7-12 analyze the data and print out the report.

   In the first part, line 4 is the important one.  We're going to have a
hash, `%table', whose keys are country names, and whose values are
(references to) arrays of city names.  After acquiring a city and country
name, the program looks up `$table{$country}', which holds (a reference
to) the list of cities seen in that country so far.  Line 4 is totally
analogous to

     push @array, $city;

   except that the name array has been replaced by the reference
`{$table{$country}}'.  The push adds a city name to the end of the
referred-to array.

   In the second part, line 9 is the important one.  Again,
`$table{$country}' is (a reference to) the list of cities in the country,
so we can recover the original list, and copy it into the array `@cities',
by using `@{$table{$country}}'.  Line 9 is totally analogous to

     @cities = @array;

   except that the name array has been replaced by the reference
`{$table{$country}}'.  The `@' tells Perl to get the entire array.

   The rest of the program is just familiar uses of chomp, split, sort,
print, and doesn't involve references at all.

   There's one fine point I skipped.  Suppose the program has just read
the first line in its input that happens to mention Greece.  Control is at
line 4, `$country' is `'Greece'', and `$city' is `'Athens''.  Since this
is the first city in Greece, `$table{$country}' is undefined--in fact
there isn't an `'Greece'' key in `%table' at all.  What does line 4 do
here?

     4	push @{$table{$country}}, $city;

   This is Perl, so it does the exact right thing.  It sees that you want
to push `Athens' onto an array that doesn't exist, so it helpfully makes a
new, empty, anonymous array for you, installs it in the table, and then
pushes `Athens' onto it.  This is called `autovivification'.

The Rest
========

   I promised to give you 90% of the benefit with 10% of the details, and
that means I left out 90% of the details.  Now that you have an overview
of the important parts, it should be easier to read the *Note Perlref:
perlref, manual page, which discusses 100% of the details.

   Some of the highlights of *Note Perlref: perlref,:

   * You can make references to anything, including scalars, functions, and
     other references.

   * In *USE RULE 1*, you can omit the curly brackets whenever the thing
     inside them is an atomic scalar variable like `$aref'.  For example,
     `@$aref' is the same as `@{$aref}', and `$$aref[1]' is the same as
     `${$aref}[1]'.  If you're just starting out, you may want to adopt
     the habit of always including the curly brackets.

   * To see if a variable contains a reference, use the `ref' function.
     It returns true if its argument is a reference.  Actually it's a
     little better than that:  It returns HASH for hash references and
     ARRAY for array references.

   * If you try to use a reference like a string, you get strings like

          ARRAY(0x80f5dec)   or    HASH(0x826afc0)

     If you ever see a string that looks like this, you'll know you
     printed out a reference by mistake.

     A side effect of this representation is that you can use eq to see if
     two references refer to the same thing.  (But you should usually use
     `==' instead because it's much faster.)

   * You can use a string as if it were a reference.  If you use the string
     `"foo"' as an array reference, it's taken to be a reference to the
     array `@foo'.  This is called a *soft reference* or *symbolic
     reference*.

   You might prefer to go on to *Note Perllol: perllol, instead of *Note
Perlref: perlref,; it discusses lists of lists and multidimensional arrays
in detail.  After that, you should move on to *Note Perldsc: perldsc,;
it's a Data Structure Cookbook that shows recipes for using and printing
out arrays of hashes, hashes of arrays, and other kinds of data.

Summary
=======

   Everyone needs compound data structures, and in Perl the way you get
them is with references.  There are four important rules for managing
references: Two for making references and two for using them.  Once you
know these rules you can do most of the important things you need to do
with references.

Credits
=======

   Author: Mark-Jason Dominus, Plover Systems (`mjd-perl-ref@plover.com')

   This article originally appeared in *The Perl Journal* (http://tpj.com)
volume 3, #2.  Reprinted with permission.

   The original title was *Understand References Today*.

Distribution Conditions
-----------------------

   Copyright 1998 The Perl Journal.

   When included as part of the Standard Version of Perl, or as part of
its complete documentation whether printed or otherwise, this work may be
distributed only under the terms of Perl's Artistic License.  Any
distribution of this file or derivatives thereof outside of that package
require that special arrangements be made with copyright holder.

   Irrespective of its distribution, all code examples in these files are
hereby placed into the public domain.  You are permitted and encouraged to
use this code in your own programs for fun or for profit as you see fit.
A simple comment in the code giving credit would be courteous but is not
required.


File: perl.info,  Node: perlrun,  Next: perlfunc,  Prev: perlre,  Up: Top

how to execute the Perl interpreter
***********************************

NAME
====

   perlrun - how to execute the Perl interpreter

SYNOPSIS
========

   *perl*	[ *-CsTuUWX* ] 	[ *-hv* ] [ -V[:*configvar*] ]
[ *-cw* ] [ -d[:*debugger*] ] [ -D[*number/list*] ]
[ *-pna* ] [ -Fpattern ] [ -l[*octal*] ] [ -0[*octal*] ]
[ -Idir ] [ -m[-]module ] [ -M[-]*'module...'* ] 	[ -P ] 	[ -S ]
[ -x[dir] ] 	[ -i[*extension*] ]
[ -e 'command' ] [ - ] [ *programfile* ] [ argument ]...

DESCRIPTION
===========

   The normal way to run a Perl program is by making it directly
executable, or else by passing the name of the source file as an argument
on the command line.  (An interactive Perl environment is also
possible-see *Note Perldebug: perldebug, for details on how to do that.)
Upon startup, Perl looks for your program in one of the following places:

  1. Specified line by line via -e switches on the command line.

  2. Contained in the file specified by the first filename on the command
     line.  (Note that systems supporting the #! notation invoke
     interpreters this way. See `Location of Perl' in this node.)

  3. Passed in implicitly via standard input.  This works only if there are
     no filename arguments-to pass arguments to a STDIN-read program you
     must explicitly specify a "-" for the program name.

        With methods 2 and 3, Perl starts parsing the input file from the
beginning, unless you've specified a -x switch, in which case it scans for
the first line starting with #! and containing the word "perl", and starts
there instead.  This is useful for running a program embedded in a larger
message.  (In this case you would indicate the end of the program using
the `__END__' token.)

   The #! line is always examined for switches as the line is being
parsed.  Thus, if you're on a machine that allows only one argument with
the #! line, or worse, doesn't even recognize the #! line, you still can
get consistent switch behavior regardless of how Perl was invoked, even if
-x was used to find the beginning of the program.

   Because historically some operating systems silently chopped off kernel
interpretation of the #! line after 32 characters, some switches may be
passed in on the command line, and some may not; you could even get a "-"
without its letter, if you're not careful.  You probably want to make sure
that all your switches fall either before or after that 32-character
boundary.  Most switches don't actually care if they're processed
redundantly, but getting a "-" instead of a complete switch could cause
Perl to try to execute standard input instead of your program.  And a
partial -I switch could also cause odd results.

   Some switches do care if they are processed twice, for instance
combinations of -l and -0.  Either put all the switches after the
32-character boundary (if applicable), or replace the use of -0digits by
`BEGIN{ $/ = "\0digits"; }'.

   Parsing of the #! switches starts wherever "perl" is mentioned in the
line.  The sequences "-*" and "- " are specifically ignored so that you
could, if you were so inclined, say

     #!/bin/sh -- # -*- perl -*- -p
     eval 'exec perl -wS $0 ${1+"$@"}'
         if $running_under_some_shell;

   to let Perl see the -p switch.

   A similar trick involves the env program, if you have it.

     #!/usr/bin/env perl

   The examples above use a relative path to the perl interpreter, getting
whatever version is first in the user's path.  If you want a specific
version of Perl, say, perl5.005_57, you should place that directly in the
#! line's path.

   If the #! line does not contain the word "perl", the program named after
the #! is executed instead of the Perl interpreter.  This is slightly
bizarre, but it helps people on machines that don't do #!, because they
can tell a program that their SHELL is `/usr/bin/perl', and Perl will then
dispatch the program to the correct interpreter for them.

   After locating your program, Perl compiles the entire program to an
internal form.  If there are any compilation errors, execution of the
program is not attempted.  (This is unlike the typical shell script, which
might run part-way through before finding a syntax error.)

   If the program is syntactically correct, it is executed.  If the program
runs off the end without hitting an exit() or die() operator, an implicit
`exit(0)' is provided to indicate successful completion.

#! and quoting on non-Unix systems
----------------------------------

   Unix's #! technique can be simulated on other systems:

OS/2
     Put

          extproc perl -S -your_switches

     as the first line in `*.cmd' file (-S due to a bug in cmd.exe's
     `extproc' handling).

MS-DOS
     Create a batch file to run your program, and codify it in
     `ALTERNATIVE_SHEBANG' (see the `dosish.h' file in the source
     distribution for more information).

Win95/NT
     The Win95/NT installation, when using the ActiveState installer for
     Perl, will modify the Registry to associate the `.pl' extension with
     the perl interpreter.  If you install Perl by other means (including
     building from the sources), you may have to modify the Registry
     yourself.  Note that this means you can no longer tell the difference
     between an executable Perl program and a Perl library file.

Macintosh
     A Macintosh perl program will have the appropriate Creator and Type,
     so that double-clicking them will invoke the perl application.

VMS
     Put

          $ perl -mysw 'f$env("procedure")' 'p1' 'p2' 'p3' 'p4' 'p5' 'p6' 'p7' 'p8' !
          $ exit++ + ++$status != 0 and $exit = $status = undef;

     at the top of your program, where *-mysw* are any command line
     switches you want to pass to Perl.  You can now invoke the program
     directly, by saying `perl program', or as a DCL procedure, by saying
     `@program' (or implicitly via `DCL$PATH' by just using the name of
     the program).

     This incantation is a bit much to remember, but Perl will display it
     for you if you say `perl "-V:startperl"'.

   Command-interpreters on non-Unix systems have rather different ideas on
quoting than Unix shells.  You'll need to learn the special characters in
your command-interpreter (*, \ and `"' are common) and how to protect
whitespace and these characters to run one-liners (see -e below).

   On some systems, you may have to change single-quotes to double ones,
which you must not do on Unix or Plan9 systems.  You might also have to
change a single % to a %%.

   For example:

     # Unix
     perl -e 'print "Hello world\n"'

     # MS-DOS, etc.
     perl -e "print \"Hello world\n\""

     # Macintosh
     print "Hello world\n"
      (then Run "Myscript" or Shift-Command-R)

     # VMS
     perl -e "print ""Hello world\n"""

   The problem is that none of this is reliable: it depends on the command
and it is entirely possible neither works.  If *4DOS* were the command
shell, this would probably work better:

     perl -e "print <Ctrl-x>"Hello world\n<Ctrl-x>""

   *CMD.EXE* in Windows NT slipped a lot of standard Unix functionality in
when nobody was looking, but just try to find documentation for its
quoting rules.

   Under the Macintosh, it depends which environment you are using.  The
MacPerl shell, or MPW, is much like Unix shells in its support for several
quoting variants, except that it makes free use of the Macintosh's
non-ASCII characters as control characters.

   There is no general solution to all of this.  It's just a mess.

Location of Perl
----------------

   It may seem obvious to say, but Perl is useful only when users can
easily find it.  When possible, it's good for both `/usr/bin/perl' and
`/usr/local/bin/perl' to be symlinks to the actual binary.  If that can't
be done, system administrators are strongly encouraged to put (symlinks
to) perl and its accompanying utilities into a directory typically found
along a user's PATH, or in some other obvious and convenient place.

   In this documentation, `#!/usr/bin/perl' on the first line of the
program will stand in for whatever method works on your system.  You are
advised to use a specific path if you care about a specific version.

     #!/usr/local/bin/perl5.00554

   or if you just want to be running at least version, place a statement
like this at the top of your program:

     use 5.005_54;

Command Switches
----------------

   As with all standard commands, a single-character switch may be
clustered with the following switch, if any.

     #!/usr/bin/perl -spi.orig	# same as -s -p -i.orig

   Switches include:

-0[digits]
     specifies the input record separator ($/) as an octal number.  If
     there are no digits, the null character is the separator.  Other
     switches may precede or follow the digits.  For example, if you have
     a version of find which can print filenames terminated by the null
     character, you can say this:

          find . -name '*.orig' -print0 | perl -n0e unlink

     The special value 00 will cause Perl to slurp files in paragraph mode.
     The value 0777 will cause Perl to slurp files whole because there is
     no legal character with that value.

-a
     turns on autosplit mode when used with a -n or -p.  An implicit split
     command to the @F array is done as the first thing inside the
     implicit while loop produced by the -n or -p.

          perl -ane 'print pop(@F), "\n";'

     is equivalent to

          while (<>) {
          	@F = split(' ');
          	print pop(@F), "\n";
          }

     An alternate delimiter may be specified using -F.

-C
     enables Perl to use the native wide character APIs on the target
     system.  The magic variable `${^WIDE_SYSTEM_CALLS}' reflects the
     state of this switch.  See `"${^WIDE_SYSTEM_CALLS}"', *Note Perlvar:
     perlvar,.

     This feature is currently only implemented on the Win32 platform.

-c
     causes Perl to check the syntax of the program and then exit without
     executing it.  Actually, it *will* execute BEGIN, CHECK, and use
     blocks, because these are considered as occurring outside the
     execution of your program.  `INIT' and END blocks, however, will be
     skipped.

-d
     runs the program under the Perl debugger.  See *Note Perldebug:
     perldebug,.

*-d:*foo
     runs the program under the control of a debugging, profiling, or
     tracing module installed as Devel::foo. E.g., *-d:DProf* executes the
     program using the Devel::DProf profiler.  See *Note Perldebug:
     perldebug,.

-Dletters
-Dnumber
     sets debugging flags.  To watch how it executes your program, use
     *-Dtls*.  (This works only if debugging is compiled into your Perl.)
     Another nice value is *-Dx*, which lists your compiled syntax tree.
     And *-Dr* displays compiled regular expressions. As an alternative,
     specify a number instead of list of letters (e.g., *-D14* is
     equivalent to *-Dtls*):

          1  p  Tokenizing and parsing
          2  s  Stack snapshots
          4  l  Context (loop) stack processing
          8  t  Trace execution
                 16  o  Method and overloading resolution
                 32  c  String/numeric conversions
                 64  P  Print preprocessor command for -P
                128  m  Memory allocation
                256  f  Format processing
                512  r  Regular expression parsing and execution
               1024  x  Syntax tree dump
               2048  u  Tainting checks
               4096  L  Memory leaks (needs -DLEAKTEST when compiling Perl)
               8192  H  Hash dump -- usurps values()
              16384  X  Scratchpad allocation
              32768  D  Cleaning up
              65536  S  Thread synchronization

     All these flags require *-DDEBUGGING* when you compile the Perl
     executable.  See the INSTALL file in the Perl source distribution for
     how to do this.  This flag is automatically set if you include -g
     option when Configure asks you about optimizer/debugger flags.

     If you're just trying to get a print out of each line of Perl code as
     it executes, the way that `sh -x' provides for shell scripts, you
     can't use Perl's -D switch.  Instead do this

          # Bourne shell syntax
          $ PERLDB_OPTS="NonStop=1 AutoTrace=1 frame=2" perl -dS program

          # csh syntax
          % (setenv PERLDB_OPTS "NonStop=1 AutoTrace=1 frame=2"; perl -dS program)

     See *Note Perldebug: perldebug, for details and variations.

-e *commandline*
     may be used to enter one line of program.  If -e is given, Perl will
     not look for a filename in the argument list.  Multiple -e commands
     may be given to build up a multi-line script.  Make sure to use
     semicolons where you would in a normal program.

-Fpattern
     specifies the pattern to split on if -a is also in effect.  The
     pattern may be surrounded by `//', "", or ", otherwise it will be put
     in single quotes.

-h
     prints a summary of the options.

-i[*extension*]
     specifies that files processed by the `<>' construct are to be edited
     in-place.  It does this by renaming the input file, opening the
     output file by the original name, and selecting that output file as
     the default for print() statements.  The extension, if supplied, is
     used to modify the name of the old file to make a backup copy,
     following these rules:

     If no extension is supplied, no backup is made and the current file is
     overwritten.

     If the extension doesn't contain a *, then it is appended to the end
     of the current filename as a suffix.  If the extension does contain
     one or more * characters, then each * is replaced with the current
     filename.  In Perl terms, you could think of this as:

          ($backup = $extension) =~ s/\*/$file_name/g;

     This allows you to add a prefix to the backup file, instead of (or in
     addition to) a suffix:

          $ perl -pi 'orig_*' -e 's/bar/baz/' fileA	# backup to 'orig_fileA'

     Or even to place backup copies of the original files into another
     directory (provided the directory already exists):

          $ perl -pi 'old/*.orig' -e 's/bar/baz/' fileA # backup to 'old/fileA.orig'

     These sets of one-liners are equivalent:

          $ perl -pi -e 's/bar/baz/' fileA		# overwrite current file
          $ perl -pi '*' -e 's/bar/baz/' fileA	# overwrite current file

          $ perl -pi '.orig' -e 's/bar/baz/' fileA	# backup to 'fileA.orig'
          $ perl -pi '*.orig' -e 's/bar/baz/' fileA	# backup to 'fileA.orig'

     From the shell, saying

          $ perl -p -i.orig -e "s/foo/bar/; ... "

     is the same as using the program:

          #!/usr/bin/perl -pi.orig
          s/foo/bar/;

     which is equivalent to

          #!/usr/bin/perl
          $extension = '.orig';
          LINE: while (<>) {
          	if ($ARGV ne $oldargv) {
          	    if ($extension !~ /\*/) {
          		$backup = $ARGV . $extension;
          	    }
          	    else {
          		($backup = $extension) =~ s/\*/$ARGV/g;
          	    }
          	    rename($ARGV, $backup);
          	    open(ARGVOUT, ">$ARGV");
          	    select(ARGVOUT);
          	    $oldargv = $ARGV;
          	}
          	s/foo/bar/;
          }
          continue {
          	print;	# this prints to original filename
          }
          select(STDOUT);

     except that the -i form doesn't need to compare $ARGV to $oldargv to
     know when the filename has changed.  It does, however, use ARGVOUT for
     the selected filehandle.  Note that STDOUT is restored as the default
     output filehandle after the loop.

     As shown above, Perl creates the backup file whether or not any output
     is actually changed.  So this is just a fancy way to copy files:

          $ perl -p -i '/some/file/path/*' -e 1 file1 file2 file3...
          or
          $ perl -p -i '.orig' -e 1 file1 file2 file3...

     You can use eof without parentheses to locate the end of each input
     file, in case you want to append to each file, or reset line numbering
     (see example in `eof', *Note Perlfunc: perlfunc,).

     If, for a given file, Perl is unable to create the backup file as
     specified in the extension then it will skip that file and continue on
     with the next one (if it exists).

     For a discussion of issues surrounding file permissions and -i, see
     `Why does Perl let me delete read-only files?  Why does -i clobber
     protected files?  Isn't this a bug in Perl?', *Note Perlfaq5:
     perlfaq5,.

     You cannot use -i to create directories or to strip extensions from
     files.

     Perl does not expand `~' in filenames, which is good, since some
     folks use it for their backup files:

          $ perl -pi~ -e 's/foo/bar/' file1 file2 file3...

     Finally, the -i switch does not impede execution when no files are
     given on the command line.  In this case, no backup is made (the
     original file cannot, of course, be determined) and processing
     proceeds from STDIN to STDOUT as might be expected.

-Idirectory
     Directories specified by -I are prepended to the search path for
     modules (`@INC'), and also tells the C preprocessor where to search
     for include files.  The C preprocessor is invoked with -P; by default
     it searches /usr/include and /usr/lib/perl.

-l[*octnum*]
     enables automatic line-ending processing.  It has two separate
     effects.  First, it automatically chomps $/ (the input record
     separator) when used with -n or -p.  Second, it assigns $\ (the
     output record separator) to have the value of *octnum* so that any
     print statements will have that separator added back on.  If *octnum*
     is omitted, sets $\ to the current value of $/.  For instance, to
     trim lines to 80 columns:

          perl -lpe 'substr($_, 80) = ""'

     Note that the assignment `$\ = $/' is done when the switch is
     processed, so the input record separator can be different than the
     output record separator if the -l switch is followed by a -0 switch:

          gnufind / -print0 | perl -ln0e 'print "found $_" if -p'

     This sets $\ to newline and then sets $/ to the null character.

-m[-]module
-M[-]module
-M[-]*'module ...'*
*-[mM]*[-]*module=arg[,arg]...*
     -mmodule executes use module `();' before executing your program.

     -Mmodule executes use module `;' before executing your program.  You
     can use quotes to add extra code after the module name, e.g.,
     `'-Mmodule qw(foo bar)''.

     If the first character after the -M or -m is a dash (-) then the
     'use' is replaced with 'no'.

     A little builtin syntactic sugar means you can also say
     *-mmodule=foo,bar* or *-Mmodule=foo,bar* as a shortcut for `'-Mmodule
     qw(foo bar)''.  This avoids the need to use quotes when importing
     symbols.  The actual code generated by *-Mmodule=foo,bar* is `use
     module split(/,/,q{foo,bar})'.  Note that the = form removes the
     distinction between -m and -M.

-n
     causes Perl to assume the following loop around your program, which
     makes it iterate over filename arguments somewhat like *sed -n* or
     *awk*:

          LINE:
            while (<>) {
          	...		# your program goes here
            }

     Note that the lines are not printed by default.  See -p to have lines
     printed.  If a file named by an argument cannot be opened for some
     reason, Perl warns you about it and moves on to the next file.

     Here is an efficient way to delete all files older than a week:

          find . -mtime +7 -print | perl -nle unlink

     This is faster than using the *-exec* switch of find because you don't
     have to start a process on every filename found.  It does suffer from
     the bug of mishandling newlines in pathnames, which you can fix if you

     BEGIN and END blocks may be used to capture control before or after
     the implicit program loop, just as in *awk*.

-p
     causes Perl to assume the following loop around your program, which
     makes it iterate over filename arguments somewhat like *sed*:

          LINE:
            while (<>) {
          	...		# your program goes here
            } continue {
          	print or die "-p destination: $!\n";
            }

     If a file named by an argument cannot be opened for some reason, Perl
     warns you about it, and moves on to the next file.  Note that the
     lines are printed automatically.  An error occurring during printing
     is treated as fatal.  To suppress printing use the -n switch.  A -p
     overrides a -n switch.

     BEGIN and END blocks may be used to capture control before or after
     the implicit loop, just as in *awk*.

-P
     causes your program to be run through the C preprocessor before
     compilation by Perl.  (Because both comments and *cpp* directives
     begin with the # character, you should avoid starting comments with
     any words recognized by the C preprocessor such as "if", "else", or
     "define".)

-s
     enables rudimentary switch parsing for switches on the command line
     after the program name but before any filename arguments (or before a
     -).  Any switch found there is removed from @ARGV and sets the
     corresponding variable in the Perl program.  The following program
     prints "1" if the program is invoked with a *-xyz* switch, and "abc"
     if it is invoked with *-xyz=abc*.

          #!/usr/bin/perl -s
          if ($xyz) { print "$xyz\n" }

-S
     makes Perl use the PATH environment variable to search for the
     program (unless the name of the program contains directory
     separators).

     On some platforms, this also makes Perl append suffixes to the
     filename while searching for it.  For example, on Win32 platforms,
     the ".bat" and ".cmd" suffixes are appended if a lookup for the
     original name fails, and if the name does not already end in one of
     those suffixes.  If your Perl was compiled with DEBUGGING turned on,
     using the -Dp switch to Perl shows how the search progresses.

     Typically this is used to emulate #! startup on platforms that don't
     support #!.  This example works on many platforms that have a shell
     compatible with Bourne shell:

          #!/usr/bin/perl
          eval 'exec /usr/bin/perl -wS $0 ${1+"$@"}'
          	    if $running_under_some_shell;

     The system ignores the first line and feeds the program to `/bin/sh',
     which proceeds to try to execute the Perl program as a shell script.
     The shell executes the second line as a normal shell command, and thus
     starts up the Perl interpreter.  On some systems $0 doesn't always
     contain the full pathname, so the -S tells Perl to search for the
     program if necessary.  After Perl locates the program, it parses the
     lines and ignores them because the variable $running_under_some_shell
     is never true.  If the program will be interpreted by csh, you will
     need to replace `${1+"$@"}' with $*, even though that doesn't
     understand embedded spaces (and such) in the argument list.  To start
     up sh rather than csh, some systems may have to replace the #! line
     with a line containing just a colon, which will be politely ignored
     by Perl.  Other systems can't control that, and need a totally
     devious construct that will work under any of *csh*, *sh*, or Perl,
     such as the following:

          eval '(exit $?0)' && eval 'exec perl -wS $0 ${1+"$@"}'
          & eval 'exec /usr/bin/perl -wS $0 $argv:q'
          	if $running_under_some_shell;

     If the filename supplied contains directory separators (i.e., is an
     absolute or relative pathname), and if that file is not found,
     platforms that append file extensions will do so and try to look for
     the file with those extensions added, one by one.

     On DOS-like platforms, if the program does not contain directory
     separators, it will first be searched for in the current directory
     before being searched for on the PATH.  On Unix platforms, the
     program will be searched for strictly on the PATH.

-T
     forces "taint" checks to be turned on so you can test them.
     Ordinarily these checks are done only when running setuid or setgid.
     It's a good idea to turn them on explicitly for programs that run on
     behalf of someone else whom you might not necessarily trust, such as
     CGI programs or any internet servers you might write in Perl.  See
     *Note Perlsec: perlsec, for details.  For security reasons, this
     option must be seen by Perl quite early; usually this means it must
     appear early on the command line or in the #! line for systems which
     support that construct.

-u
     This obsolete switch causes Perl to dump core after compiling your
     program.  You can then in theory take this core dump and turn it into
     an executable file by using the *undump* program (not supplied).
     This speeds startup at the expense of some disk space (which you can
     minimize by stripping the executable).  (Still, a "hello world"
     executable comes out to about 200K on my machine.)  If you want to
     execute a portion of your program before dumping, use the dump()
     operator instead.  Note: availability of *undump* is platform
     specific and may not be available for a specific port of Perl.

     This switch has been superseded in favor of the new Perl code
     generator backends to the compiler.  See *Note B: (pm.info)B, and
     *Note B/Bytecode: (pm.info)B/Bytecode, for details.

-U
     allows Perl to do unsafe operations.  Currently the only "unsafe"
     operations are the unlinking of directories while running as
     superuser, and running setuid programs with fatal taint checks turned
     into warnings.  Note that the -w switch (or the $^W variable) must be
     used along with this option to actually generate the taint-check
     warnings.

-v
     prints the version and patchlevel of your perl executable.

-V
     prints summary of the major perl configuration values and the current
     values of @INC.

*-V:*name
     Prints to STDOUT the value of the named configuration variable.  For
     example,

          $ perl -V:man.dir

     will provide strong clues about what your MANPATH variable should be
     set to in order to access the Perl documentation.

-w
     prints warnings about dubious constructs, such as variable names that
     are mentioned only once and scalar variables that are used before
     being set, redefined subroutines, references to undefined filehandles
     or filehandles opened read-only that you are attempting to write on,
     values used as a number that doesn't look like numbers, using an
     array as though it were a scalar, if your subroutines recurse more
     than 100 deep, and innumerable other things.

     This switch really just enables the internal `^$W' variable.  You can
     disable or promote into fatal errors specific warnings using
     `__WARN__' hooks, as described in *Note Perlvar: perlvar, and `warn',
     *Note Perlfunc: perlfunc,.  See also `warn', *Note Perldiag:
     perldiag, and `warn', *Note Perltrap: perltrap,.  A new, fine-grained
     warning facility is also available if you want to manipulate entire
     classes of warnings; see `warn', *Note Warnings: (pm.info)warnings,
     or `warn', *Note Perllexwarn: perllexwarn,.

-W
     Enables all warnings regardless of `no warnings' or $^W.  See *Note
     Perllexwarn: perllexwarn,.

-X
     Disables all warnings regardless of `use warnings' or $^W.  See *Note
     Perllexwarn: perllexwarn,.

-x directory
     tells Perl that the program is embedded in a larger chunk of unrelated
     ASCII text, such as in a mail message.  Leading garbage will be
     discarded until the first line that starts with #! and contains the
     string "perl".  Any meaningful switches on that line will be applied.
     If a directory name is specified, Perl will switch to that directory
     before running the program.  The -x switch controls only the disposal
     of leading garbage.  The program must be terminated with `__END__' if
     there is trailing garbage to be ignored (the program can process any
     or all of the trailing garbage via the DATA filehandle if desired).

ENVIRONMENT
===========

HOME
     Used if chdir has no argument.

LOGDIR
     Used if chdir has no argument and HOME is not set.

PATH
     Used in executing subprocesses, and in finding the program if -S is
     used.

PERL5LIB
     A colon-separated list of directories in which to look for Perl
     library files before looking in the standard library and the current
     directory.  Any architecture-specific directories under the specified
     locations are automatically included if they exist.  If PERL5LIB is
     not defined, PERLLIB is used.

     When running taint checks (either because the program was running
     setuid or setgid, or the -T switch was used), neither variable is
     used.  The program should instead say:

          use lib "/my/directory";

PERL5OPT
     Command-line options (switches).  Switches in this variable are taken
     as if they were on every Perl command line.  Only the *-[DIMUdmw]*
     switches are allowed.  When running taint checks (because the program
     was running setuid or setgid, or the -T switch was used), this
     variable is ignored.  If PERL5OPT begins with -T, tainting will be
     enabled, and any subsequent options ignored.

PERLLIB
     A colon-separated list of directories in which to look for Perl
     library files before looking in the standard library and the current
     directory.  If PERL5LIB is defined, PERLLIB is not used.

PERL5DB
     The command used to load the debugger code.  The default is:

          BEGIN { require 'perl5db.pl' }

PERL5SHELL (specific to the Win32 port)
     May be set to an alternative shell that perl must use internally for
     executing "backtick" commands or system().  Default is `cmd.exe /x/c'
     on WindowsNT and `command.com /c' on Windows95.  The value is
     considered to be space-separated.  Precede any character that needs
     to be protected (like a space or backslash) with a backslash.

     Note that Perl doesn't use COMSPEC for this purpose because COMSPEC
     has a high degree of variability among users, leading to portability
     concerns.  Besides, perl can use a shell that may not be fit for
     interactive use, and setting COMSPEC to such a shell may interfere
     with the proper functioning of other programs (which usually look in
     COMSPEC to find a shell fit for interactive use).

PERL_DEBUG_MSTATS
     Relevant only if perl is compiled with the malloc included with the
     perl distribution (that is, if `perl -V:d_mymalloc' is 'define').  If
     set, this causes memory statistics to be dumped after execution.  If
     set to an integer greater than one, also causes memory statistics to
     be dumped after compilation.

PERL_DESTRUCT_LEVEL
     Relevant only if your perl executable was built with *-DDEBUGGING*,
     this controls the behavior of global destruction of objects and other
     references.

   Perl also has environment variables that control how Perl handles data
specific to particular natural languages.  See *Note Perllocale:
perllocale,.

   Apart from these, Perl uses no other environment variables, except to
make them available to the program being executed, and to child processes.
However, programs running setuid would do well to execute the following
lines before doing anything else, just to keep people honest:

     $ENV{PATH}  = '/bin:/usr/bin';    # or whatever you need
     $ENV{SHELL} = '/bin/sh' if exists $ENV{SHELL};
     delete @ENV{qw(IFS CDPATH ENV BASH_ENV)};


File: perl.info,  Node: perlsec,  Next: perltrap,  Prev: perlnumber,  Up: Top

Perl security
*************

NAME
====

   perlsec - Perl security

DESCRIPTION
===========

   Perl is designed to make it easy to program securely even when running
with extra privileges, like setuid or setgid programs.  Unlike most
command line shells, which are based on multiple substitution passes on
each line of the script, Perl uses a more conventional evaluation scheme
with fewer hidden snags.  Additionally, because the language has more
builtin functionality, it can rely less upon external (and possibly
untrustworthy) programs to accomplish its purposes.

   Perl automatically enables a set of special security checks, called
*taint mode*, when it detects its program running with differing real and
effective user or group IDs.  The setuid bit in Unix permissions is mode
04000, the setgid bit mode 02000; either or both may be set.  You can also
enable taint mode explicitly by using the -T command line flag. This flag
is *strongly* suggested for server programs and any program run on behalf
of someone else, such as a CGI script. Once taint mode is on, it's on for
the remainder of your script.

   While in this mode, Perl takes special precautions called *taint
checks* to prevent both obvious and subtle traps.  Some of these checks
are reasonably simple, such as verifying that path directories aren't
writable by others; careful programmers have always used checks like
these.  Other checks, however, are best supported by the language itself,
and it is these checks especially that contribute to making a set-id Perl
program more secure than the corresponding C program.

   You may not use data derived from outside your program to affect
something else outside your program-at least, not by accident.  All
command line arguments, environment variables, locale information (see
*Note Perllocale: perllocale,), results of certain system calls (readdir(),
readlink(), the variable of shmread(), the messages returned by msgrcv(),
the password, gcos and shell fields returned by the getpwxxx() calls), and
all file input are marked as "tainted".  Tainted data may not be used
directly or indirectly in any command that invokes a sub-shell, nor in any
command that modifies files, directories, or processes. (*Important
exception*: If you pass a list of arguments to either system or exec, the
elements of that list are *NOT* checked for taintedness.) Any variable set
to a value derived from tainted data will itself be tainted, even if it is
logically impossible for the tainted data to alter the variable.  Because
taintedness is associated with each scalar value, some elements of an
array can be tainted and others not.

   For example:

     $arg = shift;		# $arg is tainted
     $hid = $arg, 'bar';		# $hid is also tainted
     $line = <>;			# Tainted
     $line = <STDIN>;		# Also tainted
     open FOO, "/home/me/bar" or die $!;
     $line = <FOO>;		# Still tainted
     $path = $ENV{'PATH'};	# Tainted, but see below
     $data = 'abc';		# Not tainted

     system "echo $arg";		# Insecure
     system "/bin/echo", $arg;	# Secure (doesn't use sh)
     system "echo $hid";		# Insecure
     system "echo $data";	# Insecure until PATH set

     $path = $ENV{'PATH'};	# $path now tainted

     $ENV{'PATH'} = '/bin:/usr/bin';
     delete @ENV{'IFS', 'CDPATH', 'ENV', 'BASH_ENV'};

     $path = $ENV{'PATH'};	# $path now NOT tainted
     system "echo $data";	# Is secure now!

     open(FOO, "< $arg");	# OK - read-only file
     open(FOO, "> $arg"); 	# Not OK - trying to write

     open(FOO,"echo $arg|");	# Not OK, but...
     open(FOO,"-|")
     	or exec 'echo', $arg;	# OK

     $shout = `echo $arg`;	# Insecure, $shout now tainted

     unlink $data, $arg;		# Insecure
     umask $arg;			# Insecure

     exec "echo $arg";		# Insecure
     exec "echo", $arg;		# Secure (doesn't use the shell)
     exec "sh", '-c', $arg;	# Considered secure, alas!

     @files = <*.c>;		# insecure (uses readdir() or similar)
     @files = glob('*.c');	# insecure (uses readdir() or similar)

   If you try to do something insecure, you will get a fatal error saying
something like "Insecure dependency" or "Insecure $ENV{PATH}".  Note that
you can still write an insecure system or exec, but only by explicitly
doing something like the "considered secure" example above.

Laundering and Detecting Tainted Data
-------------------------------------

   To test whether a variable contains tainted data, and whose use would
thus trigger an "Insecure dependency" message, check your nearby CPAN
mirror for the `Taint.pm' module, which should become available around
November 1997.  Or you may be able to use the following *is_tainted()*
function.

     sub is_tainted {
     	return ! eval {
     	    join('',@_), kill 0;
     	    1;
     	};
     }

   This function makes use of the fact that the presence of tainted data
anywhere within an expression renders the entire expression tainted.  It
would be inefficient for every operator to test every argument for
taintedness.  Instead, the slightly more efficient and conservative
approach is used that if any tainted value has been accessed within the
same expression, the whole expression is considered tainted.

   But testing for taintedness gets you only so far.  Sometimes you have
just to clear your data's taintedness.  The only way to bypass the tainting
mechanism is by referencing subpatterns from a regular expression match.
Perl presumes that if you reference a substring using $1, $2, etc., that
you knew what you were doing when you wrote the pattern.  That means using
a bit of thought-don't just blindly untaint anything, or you defeat the
entire mechanism.  It's better to verify that the variable has only good
characters (for certain values of "good") rather than checking whether it
has any bad characters.  That's because it's far too easy to miss bad
characters that you never thought of.

   Here's a test to make sure that the data contains nothing but "word"
characters (alphabetics, numerics, and underscores), a hyphen, an at sign,
or a dot.

     if ($data =~ /^([-\@\w.]+)$/) {
     	$data = $1; 			# $data now untainted
     } else {
     	die "Bad data in $data"; 	# log this somewhere
     }

   This is fairly secure because `/\w+/' doesn't normally match shell
metacharacters, nor are dot, dash, or at going to mean something special
to the shell.  Use of `/.+/' would have been insecure in theory because it
lets everything through, but Perl doesn't check for that.  The lesson is
that when untainting, you must be exceedingly careful with your patterns.
Laundering data using regular expression is the *only* mechanism for
untainting dirty data, unless you use the strategy detailed below to fork
a child of lesser privilege.

   The example does not untaint $data if `use locale' is in effect,
because the characters matched by `\w' are determined by the locale.  Perl
considers that locale definitions are untrustworthy because they contain
data from outside the program.  If you are writing a locale-aware program,
and want to launder data with a regular expression containing `\w', put
`no locale' ahead of the expression in the same block.  See `SECURITY',
*Note Perllocale: perllocale, for further discussion and examples.

Switches On the "#!" Line
-------------------------

   When you make a script executable, in order to make it usable as a
command, the system will pass switches to perl from the script's #!  line.
Perl checks that any command line switches given to a setuid (or setgid)
script actually match the ones set on the #! line.  Some Unix and
Unix-like environments impose a one-switch limit on the #!  line, so you
may need to use something like `-wU' instead of `-w -U' under such
systems.  (This issue should arise only in Unix or Unix-like environments
that support #! and setuid or setgid scripts.)

Cleaning Up Your Path
---------------------

   For "Insecure `$ENV{PATH}'" messages, you need to set `$ENV{'PATH'}' to
a known value, and each directory in the path must be non-writable by
others than its owner and group.  You may be surprised to get this message
even if the pathname to your executable is fully qualified.  This is not
generated because you didn't supply a full path to the program; instead,
it's generated because you never set your PATH environment variable, or
you didn't set it to something that was safe.  Because Perl can't
guarantee that the executable in question isn't itself going to turn
around and execute some other program that is dependent on your PATH, it
makes sure you set the PATH.

   The PATH isn't the only environment variable which can cause problems.
Because some shells may use the variables IFS, CDPATH, ENV, and BASH_ENV,
Perl checks that those are either empty or untainted when starting
subprocesses. You may wish to add something like this to your setid and
taint-checking scripts.

     delete @ENV{qw(IFS CDPATH ENV BASH_ENV)};   # Make %ENV safer

   It's also possible to get into trouble with other operations that don't
care whether they use tainted values.  Make judicious use of the file
tests in dealing with any user-supplied filenames.  When possible, do
opens and such after properly dropping any special user (or group!)
privileges. Perl doesn't prevent you from opening tainted filenames for
reading, so be careful what you print out.  The tainting mechanism is
intended to prevent stupid mistakes, not to remove the need for thought.

   Perl does not call the shell to expand wild cards when you pass system
and exec explicit parameter lists instead of strings with possible shell
wildcards in them.  Unfortunately, the open, glob, and backtick functions
provide no such alternate calling convention, so more subterfuge will be
required.

   Perl provides a reasonably safe way to open a file or pipe from a setuid
or setgid program: just create a child process with reduced privilege who
does the dirty work for you.  First, fork a child using the special open
syntax that connects the parent and child by a pipe.  Now the child resets
its ID set and any other per-process attributes, like environment
variables, umasks, current working directories, back to the originals or
known safe values.  Then the child process, which no longer has any
special permissions, does the open or other system call.  Finally, the
child passes the data it managed to access back to the parent.  Because
the file or pipe was opened in the child while running under less
privilege than the parent, it's not apt to be tricked into doing something
it shouldn't.

   Here's a way to do backticks reasonably safely.  Notice how the exec is
not called with a string that the shell could expand.  This is by far the
best way to call something that might be subjected to shell escapes: just
never call the shell at all.

     use English;
     die "Can't fork: $!" unless defined $pid = open(KID, "-|");
     if ($pid) {	          # parent
     	while (<KID>) {
     	    # do something
     	}
     	close KID;
     } else {
     	my @temp = ($EUID, $EGID);
     	$EUID = $UID;
     	$EGID = $GID;    # 	initgroups() also called!
     	# Make sure privs are really gone
     	($EUID, $EGID) = @temp;
     	die "Can't drop privileges"
     		unless $UID == $EUID  && $GID eq $EGID;
     	$ENV{PATH} = "/bin:/usr/bin";
     	exec 'myprog', 'arg1', 'arg2'
     	    or die "can't exec myprog: $!";
     }

   A similar strategy would work for wildcard expansion via glob, although
you can use readdir instead.

   Taint checking is most useful when although you trust yourself not to
have written a program to give away the farm, you don't necessarily trust
those who end up using it not to try to trick it into doing something bad.
This is the kind of security checking that's useful for set-id programs
and programs launched on someone else's behalf, like CGI programs.

   This is quite different, however, from not even trusting the writer of
the code not to try to do something evil.  That's the kind of trust needed
when someone hands you a program you've never seen before and says, "Here,
run this."  For that kind of safety, check out the Safe module, included
standard in the Perl distribution.  This module allows the programmer to
set up special compartments in which all system operations are trapped and
namespace access is carefully controlled.

Security Bugs
-------------

   Beyond the obvious problems that stem from giving special privileges to
systems as flexible as scripts, on many versions of Unix, set-id scripts
are inherently insecure right from the start.  The problem is a race
condition in the kernel.  Between the time the kernel opens the file to
see which interpreter to run and when the (now-set-id) interpreter turns
around and reopens the file to interpret it, the file in question may have
changed, especially if you have symbolic links on your system.

   Fortunately, sometimes this kernel "feature" can be disabled.
Unfortunately, there are two ways to disable it.  The system can simply
outlaw scripts with any set-id bit set, which doesn't help much.
Alternately, it can simply ignore the set-id bits on scripts.  If the
latter is true, Perl can emulate the setuid and setgid mechanism when it
notices the otherwise useless setuid/gid bits on Perl scripts.  It does
this via a special executable called suidperl that is automatically
invoked for you if it's needed.

   However, if the kernel set-id script feature isn't disabled, Perl will
complain loudly that your set-id script is insecure.  You'll need to
either disable the kernel set-id script feature, or put a C wrapper around
the script.  A C wrapper is just a compiled program that does nothing
except call your Perl program.   Compiled programs are not subject to the
kernel bug that plagues set-id scripts.  Here's a simple wrapper, written
in C:

     #define REAL_PATH "/path/to/script"
     main(ac, av)
     	char **av;
     {
     	execv(REAL_PATH, av);
     }

   Compile this wrapper into a binary executable and then make it rather
than your script setuid or setgid.

   See the program wrapsuid in the `eg' directory of your Perl
distribution for a convenient way to do this automatically for all your
setuid Perl programs.  It moves setuid scripts into files with the same
name plus a leading dot, and then compiles a wrapper like the one above
for each of them.

   In recent years, vendors have begun to supply systems free of this
inherent security bug.  On such systems, when the kernel passes the name
of the set-id script to open to the interpreter, rather than using a
pathname subject to meddling, it instead passes */dev/fd/3*.  This is a
special file already opened on the script, so that there can be no race
condition for evil scripts to exploit.  On these systems, Perl should be
compiled with `-DSETUID_SCRIPTS_ARE_SECURE_NOW'.  The Configure program
that builds Perl tries to figure this out for itself, so you should never
have to specify this yourself.  Most modern releases of SysVr4 and BSD 4.4
use this approach to avoid the kernel race condition.

   Prior to release 5.003 of Perl, a bug in the code of suidperl could
introduce a security hole in systems compiled with strict POSIX compliance.

Protecting Your Programs
------------------------

   There are a number of ways to hide the source to your Perl programs,
with varying levels of "security".

   First of all, however, you *can't* take away read permission, because
the source code has to be readable in order to be compiled and
interpreted.  (That doesn't mean that a CGI script's source is readable by
people on the web, though.)  So you have to leave the permissions at the
socially friendly 0755 level.  This lets people on your local system only
see your source.

   Some people mistakenly regard this as a security problem.  If your
program does insecure things, and relies on people not knowing how to
exploit those insecurities, it is not secure.  It is often possible for
someone to determine the insecure things and exploit them without viewing
the source.  Security through obscurity, the name for hiding your bugs
instead of fixing them, is little security indeed.

   You can try using encryption via source filters (Filter::* from CPAN).
But crackers might be able to decrypt it.  You can try using the byte code
compiler and interpreter described below, but crackers might be able to
de-compile it.  You can try using the native-code compiler described
below, but crackers might be able to disassemble it.  These pose varying
degrees of difficulty to people wanting to get at your code, but none can
definitively conceal it (this is true of every language, not just Perl).

   If you're concerned about people profiting from your code, then the
bottom line is that nothing but a restrictive licence will give you legal
security.  License your software and pepper it with threatening statements
like "This is unpublished proprietary software of XYZ Corp.  Your access
to it does not give you permission to use it blah blah blah."  You should
see a lawyer to be sure your licence's wording will stand up in court.

SEE ALSO
========

   *Note Perlrun: perlrun, for its description of cleaning up environment
variables.


File: perl.info,  Node: perlstyle,  Next: perlpod,  Prev: perlport,  Up: Top

Perl style guide
****************

NAME
====

   perlstyle - Perl style guide

DESCRIPTION
===========

   Each programmer will, of course, have his or her own preferences in
regards to formatting, but there are some general guidelines that will
make your programs easier to read, understand, and maintain.

   The most important thing is to run your programs under the -w flag at
all times.  You may turn it off explicitly for particular portions of code
via the `use warnings' pragma or the $^W variable if you must.  You should
also always run under `use strict' or know the reason why not.  The `use
sigtrap' and even `use diagnostics' pragmas may also prove useful.

   Regarding aesthetics of code lay out, about the only thing Larry cares
strongly about is that the closing curly bracket of a multi-line BLOCK
should line up with the keyword that started the construct.  Beyond that,
he has other preferences that aren't so strong:

   * 4-column indent.

   * Opening curly on same line as keyword, if possible, otherwise line up.

   * Space before the opening curly of a multi-line BLOCK.

   * One-line BLOCK may be put on one line, including curlies.

   * No space before the semicolon.

   * Semicolon omitted in "short" one-line BLOCK.

   * Space around most operators.

   * Space around a "complex" subscript (inside brackets).

   * Blank lines between chunks that do different things.

   * Uncuddled elses.

   * No space between function name and its opening parenthesis.

   * Space after each comma.

   * Long lines broken after an operator (except "and" and "or").

   * Space after last parenthesis matching on current line.

   * Line up corresponding items vertically.

   * Omit redundant punctuation as long as clarity doesn't suffer.

   Larry has his reasons for each of these things, but he doesn't claim
that everyone else's mind works the same as his does.

   Here are some other more substantive style issues to think about:

   * Just because you CAN do something a particular way doesn't mean that
     you *SHOULD* do it that way.  Perl is designed to give you several
     ways to do anything, so consider picking the most readable one.  For
     instance

          open(FOO,$foo) || die "Can't open $foo: $!";

     is better than

          die "Can't open $foo: $!" unless open(FOO,$foo);

     because the second way hides the main point of the statement in a
     modifier.  On the other hand

          print "Starting analysis\n" if $verbose;

     is better than

          $verbose && print "Starting analysis\n";

     because the main point isn't whether the user typed -v or not.

     Similarly, just because an operator lets you assume default arguments
     doesn't mean that you have to make use of the defaults.  The defaults
     are there for lazy systems programmers writing one-shot programs.  If
     you want your program to be readable, consider supplying the argument.

     Along the same lines, just because you CAN omit parentheses in many
     places doesn't mean that you ought to:

          return print reverse sort num values %array;
          return print(reverse(sort num (values(%array))));

     When in doubt, parenthesize.  At the very least it will let some poor
     schmuck bounce on the % key in *vi*.

     Even if you aren't in doubt, consider the mental welfare of the person
     who has to maintain the code after you, and who will probably put
     parentheses in the wrong place.

   * Don't go through silly contortions to exit a loop at the top or the
     bottom, when Perl provides the last operator so you can exit in the
     middle.  Just "outdent" it a little to make it more visible:

          LINE:
          	for (;;) {
          	    statements;
          	  last LINE if $foo;
          	    next LINE if /^#/;
          	    statements;
          	}

   * Don't be afraid to use loop labels-they're there to enhance
     readability as well as to allow multilevel loop breaks.  See the
     previous example.

   * Avoid using grep() (or map()) or `backticks` in a void context, that
     is, when you just throw away their return values.  Those functions all
     have return values, so use them.  Otherwise use a foreach() loop or
     the system() function instead.

   * For portability, when using features that may not be implemented on
     every machine, test the construct in an eval to see if it fails.  If
     you know what version or patchlevel a particular feature was
     implemented, you can test $] ($PERL_VERSION in English) to see if it
     will be there.  The Config module will also let you interrogate values
     determined by the Configure program when Perl was installed.

   * Choose mnemonic identifiers.  If you can't remember what mnemonic
     means, you've got a problem.

   * While short identifiers like $gotit are probably ok, use underscores
     to separate words.  It is generally easier to read
     $var_names_like_this than $VarNamesLikeThis, especially for
     non-native speakers of English. It's also a simple rule that works
     consistently with VAR_NAMES_LIKE_THIS.

     Package names are sometimes an exception to this rule.  Perl
     informally reserves lowercase module names for "pragma" modules like
     integer and strict.  Other modules should begin with a capital letter
     and use mixed case, but probably without underscores due to
     limitations in primitive file systems' representations of module
     names as files that must fit into a few sparse bytes.

   * You may find it helpful to use letter case to indicate the scope or
     nature of a variable. For example:

          $ALL_CAPS_HERE   constants only (beware clashes with perl vars!)
          $Some_Caps_Here  package-wide global/static
          $no_caps_here    function scope my() or local() variables

     Function and method names seem to work best as all lowercase.  E.g.,
     $obj->as_string().

     You can use a leading underscore to indicate that a variable or
     function should not be used outside the package that defined it.

   * If you have a really hairy regular expression, use the `/x' modifier
     and put in some whitespace to make it look a little less like line
     noise.  Don't use slash as a delimiter when your regexp has slashes
     or backslashes.

   * Use the new "and" and "or" operators to avoid having to parenthesize
     list operators so much, and to reduce the incidence of punctuation
     operators like `&&' and `||'.  Call your subroutines as if they were
     functions or list operators to avoid excessive ampersands and
     parentheses.

   * Use here documents instead of repeated print() statements.

   * Line up corresponding things vertically, especially if it'd be too
     long to fit on one line anyway.

          $IDX = $ST_MTIME;
          $IDX = $ST_ATIME 	   if $opt_u;
          $IDX = $ST_CTIME 	   if $opt_c;
          $IDX = $ST_SIZE  	   if $opt_s;

          mkdir $tmpdir, 0700	or die "can't mkdir $tmpdir: $!";
          chdir($tmpdir)      or die "can't chdir $tmpdir: $!";
          mkdir 'tmp',   0777	or die "can't mkdir $tmpdir/tmp: $!";

   * Always check the return codes of system calls.  Good error messages
     should go to STDERR, include which program caused the problem, what
     the failed system call and arguments were, and (VERY IMPORTANT)
     should contain the standard system error message for what went wrong.
     Here's a simple but sufficient example:

          opendir(D, $dir)	 or die "can't opendir $dir: $!";

   * Line up your transliterations when it makes sense:

          tr [abc]
             [xyz];

   * Think about reusability.  Why waste brainpower on a one-shot when you
     might want to do something like it again?  Consider generalizing your
     code.  Consider writing a module or object class.  Consider making
     your code run cleanly with `use strict' and `use warnings' (or -w) in
     effect Consider giving away your code.  Consider changing your whole
     world view.  Consider... oh, never mind.

   * Be consistent.

   * Be nice.


File: perl.info,  Node: perlsub,  Next: perlmod,  Prev: perlvar,  Up: Top

Perl subroutines
****************

NAME
====

   perlsub - Perl subroutines

SYNOPSIS
========

   To declare subroutines:

     sub NAME;			  # A "forward" declaration.
     sub NAME(PROTO);		  #  ditto, but with prototypes
     sub NAME : ATTRS;		  #  with attributes
     sub NAME(PROTO) : ATTRS;	  #  with attributes and prototypes

     sub NAME BLOCK		  # A declaration and a definition.
     sub NAME(PROTO) BLOCK	  #  ditto, but with prototypes
     sub NAME : ATTRS BLOCK	  #  with attributes
     sub NAME(PROTO) : ATTRS BLOCK #  with prototypes and attributes

   To define an anonymous subroutine at runtime:

     $subref = sub BLOCK;		 # no proto
     $subref = sub (PROTO) BLOCK;	 # with proto
     $subref = sub : ATTRS BLOCK;	 # with attributes
     $subref = sub (PROTO) : ATTRS BLOCK; # with proto and attributes

   To import subroutines:

     use MODULE qw(NAME1 NAME2 NAME3);

   To call subroutines:

     NAME(LIST);	   # & is optional with parentheses.
     NAME LIST;	   # Parentheses optional if predeclared/imported.
     &NAME(LIST);   # Circumvent prototypes.
     &NAME;	   # Makes current @_ visible to called subroutine.

DESCRIPTION
===========

   Like many languages, Perl provides for user-defined subroutines.  These
may be located anywhere in the main program, loaded in from other files
via the do, require, or use keywords, or generated on the fly using eval
or anonymous subroutines (closures).  You can even call a function
indirectly using a variable containing its name or a CODE reference.

   The Perl model for function call and return values is simple: all
functions are passed as parameters one single flat list of scalars, and
all functions likewise return to their caller one single flat list of
scalars.  Any arrays or hashes in these call and return lists will
collapse, losing their identities-but you may always use pass-by-reference
instead to avoid this.  Both call and return lists may contain as many or
as few scalar elements as you'd like.  (Often a function without an
explicit return statement is called a subroutine, but there's really no
difference from Perl's perspective.)

   Any arguments passed in show up in the array `@_'.  Therefore, if you
called a function with two arguments, those would be stored in `$_[0]' and
`$_[1]'.  The array `@_' is a local array, but its elements are aliases
for the actual scalar parameters.  In particular, if an element `$_[0]' is
updated, the corresponding argument is updated (or an error occurs if it
is not updatable).  If an argument is an array or hash element which did
not exist when the function was called, that element is created only when
(and if) it is modified or a reference to it is taken.  (Some earlier
versions of Perl created the element whether or not the element was
assigned to.)  Assigning to the whole array `@_' removes that aliasing,
and does not update any arguments.

   The return value of a subroutine is the value of the last expression
evaluated.  More explicitly, a return statement may be used to exit the
subroutine, optionally specifying the returned value, which will be
evaluated in the appropriate context (list, scalar, or void) depending on
the context of the subroutine call.  If you specify no return value, the
subroutine returns an empty list in list context, the undefined value in
scalar context, or nothing in void context.  If you return one or more
aggregates (arrays and hashes), these will be flattened together into one
large indistinguishable list.

   Perl does not have named formal parameters.  In practice all you do is
assign to a my() list of these.  Variables that aren't declared to be
private are global variables.  For gory details on creating private
variables, see `"Private Variables via my()"' in this node and `"Temporary
Values via local()"' in this node.  To create protected environments for a
set of functions in a separate package (and probably a separate file), see
`"Packages"', *Note Perlmod: perlmod,.

   Example:

     sub max {
     	my $max = shift(@_);
     	foreach $foo (@_) {
     	    $max = $foo if $max < $foo;
     	}
     	return $max;
     }
     $bestday = max($mon,$tue,$wed,$thu,$fri);

   Example:

     # get a line, combining continuation lines
     #  that start with whitespace

     sub get_line {
     	$thisline = $lookahead;  # global variables!
     	LINE: while (defined($lookahead = <STDIN>)) {
     	    if ($lookahead =~ /^[ \t]/) {
     		$thisline .= $lookahead;
     	    }
     	    else {
     		last LINE;
     	    }
     	}
     	return $thisline;
     }

     $lookahead = <STDIN>;	# get first line
     while (defined($line = get_line())) {
     	...
     }

   Assigning to a list of private variables to name your arguments:

     sub maybeset {
     	my($key, $value) = @_;
     	$Foo{$key} = $value unless $Foo{$key};
     }

   Because the assignment copies the values, this also has the effect of
turning call-by-reference into call-by-value.  Otherwise a function is
free to do in-place modifications of `@_' and change its caller's values.

     upcase_in($v1, $v2);  # this changes $v1 and $v2
     sub upcase_in {
     	for (@_) { tr/a-z/A-Z/ }
     }

   You aren't allowed to modify constants in this way, of course.  If an
argument were actually literal and you tried to change it, you'd take a
(presumably fatal) exception.   For example, this won't work:

     upcase_in("frederick");

   It would be much safer if the `upcase_in()' function were written to
return a copy of its parameters instead of changing them in place:

     ($v3, $v4) = upcase($v1, $v2);  # this doesn't change $v1 and $v2
     sub upcase {
     	return unless defined wantarray;  # void context, do nothing
     	my @parms = @_;
     	for (@parms) { tr/a-z/A-Z/ }
       	return wantarray ? @parms : $parms[0];
     }

   Notice how this (unprototyped) function doesn't care whether it was
passed real scalars or arrays.  Perl sees all arugments as one big, long,
flat parameter list in `@_'.  This is one area where Perl's simple
argument-passing style shines.  The `upcase()' function would work
perfectly well without changing the `upcase()' definition even if we fed
it things like this:

     @newlist   = upcase(@list1, @list2);
     @newlist   = upcase( split /:/, $var );

   Do not, however, be tempted to do this:

     (@a, @b)   = upcase(@list1, @list2);

   Like the flattened incoming parameter list, the return list is also
flattened on return.  So all you have managed to do here is stored
everything in `@a' and made `@b' an empty list.  See `Pass by Reference'
in this node for alternatives.

   A subroutine may be called using an explicit & prefix.  The & is
optional in modern Perl, as are parentheses if the subroutine has been
predeclared.  The & is not optional when just naming the subroutine, such
as when it's used as an argument to defined() or undef().  Nor is it
optional when you want to do an indirect subroutine call with a subroutine
name or reference using the `&$subref()' or `&{$subref}()' constructs,
although the `< $subref-'() >> notation solves that problem.  See *Note
Perlref: perlref, for more about all that.

   Subroutines may be called recursively.  If a subroutine is called using
the & form, the argument list is optional, and if omitted, no `@_' array
is set up for the subroutine: the `@_' array at the time of the call is
visible to subroutine instead.  This is an efficiency mechanism that new
users may wish to avoid.

     &foo(1,2,3);	# pass three arguments
     foo(1,2,3);		# the same

     foo();		# pass a null list
     &foo();		# the same

     &foo;		# foo() get current args, like foo(@_) !!
     foo;		# like foo() IFF sub foo predeclared, else "foo"

   Not only does the & form make the argument list optional, it also
disables any prototype checking on arguments you do provide.  This is
partly for historical reasons, and partly for having a convenient way to
cheat if you know what you're doing.  See `Prototypes' in this node below.

   Functions whose names are in all upper case are reserved to the Perl
core, as are modules whose names are in all lower case.  A function in all
capitals is a loosely-held convention meaning it will be called indirectly
by the run-time system itself, usually due to a triggered event.
Functions that do special, pre-defined things include BEGIN, CHECK,
`INIT', END, AUTOLOAD, and DESTROY-plus all functions mentioned in *Note
Perltie: perltie,.

Private Variables via my()
--------------------------

   Synopsis:

     my $foo;	    	# declare $foo lexically local
     my (@wid, %get); 	# declare list of variables local
     my $foo = "flurp";	# declare $foo lexical, and init it
     my @oof = @bar;	# declare @oof lexical, and init it
     my $x : Foo = $y;	# similar, with an attribute applied

   WARNING: The use of attribute lists on my declarations is experimental.
This feature should not be relied upon.  It may change or disappear in
future releases of Perl.  See *Note Attributes: (pm.info)attributes,.

   The my operator declares the listed variables to be lexically confined
to the enclosing block, conditional (`if/unless/elsif/else'), loop
(`for/foreach/while/until/continue'), subroutine, eval, or
`do/require/use''d file.  If more than one value is listed, the list must
be placed in parentheses.  All listed elements must be legal lvalues.
Only alphanumeric identifiers may be lexically scoped-magical built-ins
like $/ must currently be localize with local instead.

   Unlike dynamic variables created by the local operator, lexical
variables declared with my are totally hidden from the outside world,
including any called subroutines.  This is true if it's the same
subroutine called from itself or elsewhere-every call gets its own copy.

   This doesn't mean that a my variable declared in a statically enclosing
lexical scope would be invisible.  Only dynamic scopes are cut off.   For
example, the `bumpx()' function below has access to the lexical $x
variable because both the my and the sub occurred at the same scope,
presumably file scope.

     my $x = 10;
     sub bumpx { $x++ }

   An `eval()', however, can see lexical variables of the scope it is
being evaluated in, so long as the names aren't hidden by declarations
within the `eval()' itself.  See *Note Perlref: perlref,.

   The parameter list to my() may be assigned to if desired, which allows
you to initialize your variables.  (If no initializer is given for a
particular variable, it is created with the undefined value.)  Commonly
this is used to name input parameters to a subroutine.  Examples:

     $arg = "fred";	  # "global" variable
     $n = cube_root(27);
     print "$arg thinks the root is $n\n";
      fred thinks the root is 3

     sub cube_root {
     	my $arg = shift;  # name doesn't matter
     	$arg **= 1/3;
     	return $arg;
     }

   The my is simply a modifier on something you might assign to.  So when
you do assign to variables in its argument list, my doesn't change whether
those variables are viewed as a scalar or an array.  So

     my ($foo) = <STDIN>;		# WRONG?
     my @FOO = <STDIN>;

   both supply a list context to the right-hand side, while

     my $foo = <STDIN>;

   supplies a scalar context.  But the following declares only one
variable:

     my $foo, $bar = 1;			# WRONG

   That has the same effect as

     my $foo;
     $bar = 1;

   The declared variable is not introduced (is not visible) until after
the current statement.  Thus,

     my $x = $x;

   can be used to initialize a new $x with the value of the old $x, and
the expression

     my $x = 123 and $x == 123

   is false unless the old $x happened to have the value 123.

   Lexical scopes of control structures are not bounded precisely by the
braces that delimit their controlled blocks; control expressions are part
of that scope, too.  Thus in the loop

     while (my $line = <>) {
         $line = lc $line;
     } continue {
         print $line;
     }

   the scope of $line extends from its declaration throughout the rest of
the loop construct (including the continue clause), but not beyond it.
Similarly, in the conditional

     if ((my $answer = <STDIN>) =~ /^yes$/i) {
         user_agrees();
     } elsif ($answer =~ /^no$/i) {
         user_disagrees();
     } else {
     	chomp $answer;
         die "'$answer' is neither 'yes' nor 'no'";
     }

   the scope of $answer extends from its declaration through the rest of
that conditional, including any `elsif' and else clauses, but not beyond
it.

   None of the foregoing text applies to `if/unless' or `while/until'
modifiers appended to simple statements.  Such modifiers are not control
structures and have no effect on scoping.

   The foreach loop defaults to scoping its index variable dynamically in
the manner of local.  However, if the index variable is prefixed with the
keyword my, or if there is already a lexical by that name in scope, then a
new lexical is created instead.  Thus in the loop

     for my $i (1, 2, 3) {
         some_function();
     }

   the scope of $i extends to the end of the loop, but not beyond it,
rendering the value of $i inaccessible within `some_function()'.

   Some users may wish to encourage the use of lexically scoped variables.
As an aid to catching implicit uses to package variables, which are always
global, if you say

     use strict 'vars';

   then any variable mentioned from there to the end of the enclosing
block must either refer to a lexical variable, be predeclared via our or
`use vars', or else must be fully qualified with the package name.  A
compilation error results otherwise.  An inner block may countermand this
with `no strict 'vars''.

   A my has both a compile-time and a run-time effect.  At compile time,
the compiler takes notice of it.  The principle usefulness of this is to
quiet `use strict 'vars'', but it is also essential for generation of
closures as detailed in *Note Perlref: perlref,.  Actual initialization is
delayed until run time, though, so it gets executed at the appropriate
time, such as each time through a loop, for example.

   Variables declared with my are not part of any package and are therefore
never fully qualified with the package name.  In particular, you're not
allowed to try to make a package variable (or other global) lexical:

     my $pack::var;	# ERROR!  Illegal syntax
     my $_;		# also illegal (currently)

   In fact, a dynamic variable (also known as package or global variables)
are still accessible using the fully qualified `::' notation even while a
lexical of the same name is also visible:

     package main;
     local $x = 10;
     my    $x = 20;
     print "$x and $::x\n";

   That will print out 20 and 10.

   You may declare my variables at the outermost scope of a file to hide
any such identifiers from the world outside that file.  This is similar in
spirit to C's static variables when they are used at the file level.  To
do this with a subroutine requires the use of a closure (an anonymous
function that accesses enclosing lexicals).  If you want to create a
private subroutine that cannot be called from outside that block, it can
declare a lexical variable containing an anonymous sub reference:

     my $secret_version = '1.001-beta';
     my $secret_sub = sub { print $secret_version };
     &$secret_sub();

   As long as the reference is never returned by any function within the
module, no outside module can see the subroutine, because its name is not
in any package's symbol table.  Remember that it's not *REALLY* called
`$some_pack::secret_version' or anything; it's just $secret_version,
unqualified and unqualifiable.

   This does not work with object methods, however; all object methods
have to be in the symbol table of some package to be found.  See
`"Function Templates"', *Note Perlref: perlref, for something of a
work-around to this.

Persistent Private Variables
----------------------------

   Just because a lexical variable is lexically (also called statically)
scoped to its enclosing block, eval, or do FILE, this doesn't mean that
within a function it works like a C static.  It normally works more like a
C auto, but with implicit garbage collection.

   Unlike local variables in C or C++, Perl's lexical variables don't
necessarily get recycled just because their scope has exited.  If
something more permanent is still aware of the lexical, it will stick
around.  So long as something else references a lexical, that lexical
won't be freed-which is as it should be.  You wouldn't want memory being
free until you were done using it, or kept around once you were done.
Automatic garbage collection takes care of this for you.

   This means that you can pass back or save away references to lexical
variables, whereas to return a pointer to a C auto is a grave error.  It
also gives us a way to simulate C's function statics.  Here's a mechanism
for giving a function private variables with both lexical scoping and a
static lifetime.  If you do want to create something like C's static
variables, just enclose the whole function in an extra block, and put the
static variable outside the function but in the block.

     {
     	my $secret_val = 0;
     	sub gimme_another {
     	    return ++$secret_val;
     	}
     }
     # $secret_val now becomes unreachable by the outside
     # world, but retains its value between calls to gimme_another

   If this function is being sourced in from a separate file via require
or use, then this is probably just fine.  If it's all in the main program,
you'll need to arrange for the my to be executed early, either by putting
the whole block above your main program, or more likely, placing merely a
BEGIN sub around it to make sure it gets executed before your program
starts to run:

     sub BEGIN {
     	my $secret_val = 0;
     	sub gimme_another {
     	    return ++$secret_val;
     	}
     }

   See `"Package Constructors and Destructors"', *Note Perlmod: perlmod,
about the special triggered functions, BEGIN, CHECK, `INIT' and END.

   If declared at the outermost scope (the file scope), then lexicals work
somewhat like C's file statics.  They are available to all functions in
that same file declared below them, but are inaccessible from outside that
file.  This strategy is sometimes used in modules to create private
variables that the whole module can see.

Temporary Values via local()
----------------------------

   WARNING: In general, you should be using my instead of local, because
it's faster and safer.  Exceptions to this include the global punctuation
variables, filehandles and formats, and direct manipulation of the Perl
symbol table itself.  Format variables often use local though, as do other
variables whose current value must be visible to called subroutines.

   Synopsis:

     local $foo;	    		# declare $foo dynamically local
     local (@wid, %get); 	# declare list of variables local
     local $foo = "flurp";	# declare $foo dynamic, and init it
     local @oof = @bar;		# declare @oof dynamic, and init it

     local *FH;			# localize $FH, @FH, %FH, &FH  ...
     local *merlyn = *randal;	# now $merlyn is really $randal, plus
                                 #     @merlyn is really @randal, etc
     local *merlyn = 'randal';	# SAME THING: promote 'randal' to *randal
     local *merlyn = \$randal;   # just alias $merlyn, not @merlyn etc

   A local modifies its listed variables to be "local" to the enclosing
block, eval, or `do FILE'-and to *any subroutine called from within that
block*.  A local just gives temporary values to global (meaning package)
variables.  It does not create a local variable.  This is known as dynamic
scoping.  Lexical scoping is done with my, which works more like C's auto
declarations.

   If more than one variable is given to local, they must be placed in
parentheses.  All listed elements must be legal lvalues.  This operator
works by saving the current values of those variables in its argument list
on a hidden stack and restoring them upon exiting the block, subroutine, or
eval.  This means that called subroutines can also reference the local
variable, but not the global one.  The argument list may be assigned to if
desired, which allows you to initialize your local variables.  (If no
initializer is given for a particular variable, it is created with an
undefined value.)  Commonly this is used to name the parameters to a
subroutine.  Examples:

     for $i ( 0 .. 9 ) {
     	$digits{$i} = $i;
     }
     # assume this function uses global %digits hash
     parse_num();

     # now temporarily add to %digits hash
     if ($base12) {
     	# (NOTE: not claiming this is efficient!)
     	local %digits  = (%digits, 't' => 10, 'e' => 11);
     	parse_num();  # parse_num gets this new %digits!
     }
     # old %digits restored here

   Because local is a run-time operator, it gets executed each time
through a loop.  In releases of Perl previous to 5.0, this used more stack
storage each time until the loop was exited.  Perl now reclaims the space
each time through, but it's still more efficient to declare your variables
outside the loop.

   A local is simply a modifier on an lvalue expression.  When you assign
to a localized variable, the local doesn't change whether its list is
viewed as a scalar or an array.  So

     local($foo) = <STDIN>;
     local @FOO = <STDIN>;

   both supply a list context to the right-hand side, while

     local $foo = <STDIN>;

   supplies a scalar context.

   A note about `local()' and composite types is in order.  Something like
`local(%foo)' works by temporarily placing a brand new hash in the symbol
table.  The old hash is left alone, but is hidden "behind" the new one.

   This means the old variable is completely invisible via the symbol
table (i.e. the hash entry in the `*foo' typeglob) for the duration of the
dynamic scope within which the `local()' was seen.  This has the effect of
allowing one to temporarily occlude any magic on composite types.  For
instance, this will briefly alter a tied hash to some other implementation:

     tie %ahash, 'APackage';
     [...]
     {
        local %ahash;
        tie %ahash, 'BPackage';
        [..called code will see %ahash tied to 'BPackage'..]
        {
           local %ahash;
           [..%ahash is a normal (untied) hash here..]
        }
     }
     [..%ahash back to its initial tied self again..]

   As another example, a custom implementation of %ENV might look like
this:

     {
         local %ENV;
         tie %ENV, 'MyOwnEnv';
         [..do your own fancy %ENV manipulation here..]
     }
     [..normal %ENV behavior here..]

   It's also worth taking a moment to explain what happens when you
localize a member of a composite type (i.e. an array or hash element).  In
this case, the element is localized *by name*. This means that when the
scope of the `local()' ends, the saved value will be restored to the hash
element whose key was named in the `local()', or the array element whose
index was named in the `local()'.  If that element was deleted while the
`local()' was in effect (e.g. by a delete() from a hash or a shift() of an
array), it will spring back into existence, possibly extending an array
and filling in the skipped elements with undef.  For instance, if you say

     %hash = ( 'This' => 'is', 'a' => 'test' );
     @ary  = ( 0..5 );
     {
          local($ary[5]) = 6;
          local($hash{'a'}) = 'drill';
          while (my $e = pop(@ary)) {
              print "$e . . .\n";
              last unless $e > 3;
          }
          if (@ary) {
              $hash{'only a'} = 'test';
              delete $hash{'a'};
          }
     }
     print join(' ', map { "$_ $hash{$_}" } sort keys %hash),".\n";
     print "The array has ",scalar(@ary)," elements: ",
           join(', ', map { defined $_ ? $_ : 'undef' } @ary),"\n";

   Perl will print

     6 . . .
     4 . . .
     3 . . .
     This is a test only a test.
     The array has 6 elements: 0, 1, 2, undef, undef, 5

   The behavior of local() on non-existent members of composite types is
subject to change in future.

Lvalue subroutines
------------------

   WARNING: Lvalue subroutines are still experimental and the
implementation may change in future versions of Perl.

   It is possible to return a modifiable value from a subroutine.  To do
this, you have to declare the subroutine to return an lvalue.

     my $val;
     sub canmod : lvalue {
     	$val;
     }
     sub nomod {
     	$val;
     }

     canmod() = 5;   # assigns to $val
     nomod()  = 5;   # ERROR

   The scalar/list context for the subroutine and for the right-hand side
of assignment is determined as if the subroutine call is replaced by a
scalar. For example, consider:

     data(2,3) = get_data(3,4);

   Both subroutines here are called in a scalar context, while in:

     (data(2,3)) = get_data(3,4);

   and in:

     (data(2),data(3)) = get_data(3,4);

   all the subroutines are called in a list context.

   The current implementation does not allow arrays and hashes to be
returned from lvalue subroutines directly.  You may return a reference
instead.  This restriction may be lifted in future.

Passing Symbol Table Entries (typeglobs)
----------------------------------------

   WARNING: The mechanism described in this section was originally the
only way to simulate pass-by-reference in older versions of Perl.  While
it still works fine in modern versions, the new reference mechanism is
generally easier to work with.  See below.

   Sometimes you don't want to pass the value of an array to a subroutine
but rather the name of it, so that the subroutine can modify the global
copy of it rather than working with a local copy.  In perl you can refer
to all objects of a particular name by prefixing the name with a star:
`*foo'.  This is often known as a "typeglob", because the star on the
front can be thought of as a wildcard match for all the funny prefix
characters on variables and subroutines and such.

   When evaluated, the typeglob produces a scalar value that represents
all the objects of that name, including any filehandle, format, or
subroutine.  When assigned to, it causes the name mentioned to refer to
whatever * value was assigned to it.  Example:

     sub doubleary {
     	local(*someary) = @_;
     	foreach $elem (@someary) {
     	    $elem *= 2;
     	}
     }
     doubleary(*foo);
     doubleary(*bar);

   Scalars are already passed by reference, so you can modify scalar
arguments without using this mechanism by referring explicitly to `$_[0]'
etc.  You can modify all the elements of an array by passing all the
elements as scalars, but you have to use the * mechanism (or the
equivalent reference mechanism) to push, pop, or change the size of an
array.  It will certainly be faster to pass the typeglob (or reference).

   Even if you don't want to modify an array, this mechanism is useful for
passing multiple arrays in a single LIST, because normally the LIST
mechanism will merge all the array values so that you can't extract out
the individual arrays.  For more on typeglobs, see `"Typeglobs and
Filehandles"', *Note Perldata: perldata,.

When to Still Use local()
-------------------------

   Despite the existence of my, there are still three places where the
local operator still shines.  In fact, in these three places, you must use
local instead of my.

  1. You need to give a global variable a temporary value, especially $_.
     The global variables, like `@ARGV' or the punctuation variables, must
     be localized with `local()'.  This block reads in `/etc/motd', and
     splits it up into chunks separated by lines of equal signs, which are
     placed in `@Fields'.

          {
          	local @ARGV = ("/etc/motd");
              local $/ = undef;
              local $_ = <>;
          	@Fields = split /^\s*=+\s*$/;
          }

     It particular, it's important to localize $_ in any routine that
     assigns to it.  Look out for implicit assignments in while
     conditionals.

  2. You need to create a local file or directory handle or a local
     function.  A function that needs a filehandle of its own must use
     `local()' on a complete typeglob.   This can be used to create new
     symbol table entries:

          sub ioqueue {
              local  (*READER, *WRITER);    # not my!
              pipe    (READER,  WRITER);    or die "pipe: $!";
              return (*READER, *WRITER);
          }
          ($head, $tail) = ioqueue();

     See the Symbol module for a way to create anonymous symbol table
     entries.

     Because assignment of a reference to a typeglob creates an alias, this
     can be used to create what is effectively a local function, or at
     least, a local alias.

          {
              local *grow = \&shrink; # only until this block exists
              grow();                 # really calls shrink()
          	move();			# if move() grow()s, it shrink()s too
          }
          grow();			# get the real grow() again

     See `"Function Templates"', *Note Perlref: perlref, for more about
     manipulating functions by name in this way.

  3. You want to temporarily change just one element of an array or hash.
     You can localize just one element of an aggregate.  Usually this is
     done on dynamics:

          {
          	local $SIG{INT} = 'IGNORE';
          	funct();			    # uninterruptible
          }
          # interruptibility automatically restored here

     But it also works on lexically declared aggregates.  Prior to 5.005,
     this operation could on occasion misbehave.


Pass by Reference
-----------------

   If you want to pass more than one array or hash into a function-or
return them from it-and have them maintain their integrity, then you're
going to have to use an explicit pass-by-reference.  Before you do that,
you need to understand references as detailed in *Note Perlref: perlref,.
This section may not make much sense to you otherwise.

   Here are a few simple examples.  First, let's pass in several arrays to
a function and have it pop all of then, returning a new list of all their
former last elements:

     @tailings = popmany ( \@a, \@b, \@c, \@d );

     sub popmany {
     	my $aref;
     	my @retlist = ();
     	foreach $aref ( @_ ) {
     	    push @retlist, pop @$aref;
     	}
     	return @retlist;
     }

   Here's how you might write a function that returns a list of keys
occurring in all the hashes passed to it:

     @common = inter( \%foo, \%bar, \%joe );
     sub inter {
     	my ($k, $href, %seen); # locals
     	foreach $href (@_) {
     	    while ( $k = each %$href ) {
     		$seen{$k}++;
     	    }
     	}
     	return grep { $seen{$_} == @_ } keys %seen;
     }

   So far, we're using just the normal list return mechanism.  What
happens if you want to pass or return a hash?  Well, if you're using only
one of them, or you don't mind them concatenating, then the normal calling
convention is ok, although a little expensive.

   Where people get into trouble is here:

     (@a, @b) = func(@c, @d);
     or
     (%a, %b) = func(%c, %d);

   That syntax simply won't work.  It sets just `@a' or `%a' and clears
the `@b' or `%b'.  Plus the function didn't get passed into two separate
arrays or hashes: it got one long list in `@_', as always.

   If you can arrange for everyone to deal with this through references,
it's cleaner code, although not so nice to look at.  Here's a function that
takes two array references as arguments, returning the two array elements
in order of how many elements they have in them:

     ($aref, $bref) = func(\@c, \@d);
     print "@$aref has more than @$bref\n";
     sub func {
     	my ($cref, $dref) = @_;
     	if (@$cref > @$dref) {
     	    return ($cref, $dref);
     	} else {
     	    return ($dref, $cref);
     	}
     }

   It turns out that you can actually do this also:

     (*a, *b) = func(\@c, \@d);
     print "@a has more than @b\n";
     sub func {
     	local (*c, *d) = @_;
     	if (@c > @d) {
     	    return (\@c, \@d);
     	} else {
     	    return (\@d, \@c);
     	}
     }

   Here we're using the typeglobs to do symbol table aliasing.  It's a tad
subtle, though, and also won't work if you're using my variables, because
only globals (even in disguise as locals) are in the symbol table.

   If you're passing around filehandles, you could usually just use the
bare typeglob, like `*STDOUT', but typeglobs references work, too.  For
example:

     splutter(\*STDOUT);
     sub splutter {
     	my $fh = shift;
     	print $fh "her um well a hmmm\n";
     }

     $rec = get_rec(\*STDIN);
     sub get_rec {
     	my $fh = shift;
     	return scalar <$fh>;
     }

   If you're planning on generating new filehandles, you could do this.
Notice to pass back just the bare *FH, not its reference.

     sub openit {
     	my $path = shift;
     	local *FH;
     	return open (FH, $path) ? *FH : undef;
     }

Prototypes
----------

   Perl supports a very limited kind of compile-time argument checking
using function prototyping.  If you declare

     sub mypush (\@@)

   then `mypush()' takes arguments exactly like `push()' does.  The
function declaration must be visible at compile time.  The prototype
affects only interpretation of new-style calls to the function, where
new-style is defined as not using the & character.  In other words, if you
call it like a built-in function, then it behaves like a built-in
function.  If you call it like an old-fashioned subroutine, then it
behaves like an old-fashioned subroutine.  It naturally falls out from
this rule that prototypes have no influence on subroutine references like
`\&foo' or on indirect subroutine calls like `&{$subref}' or `<
$subref-'() >>.

   Method calls are not influenced by prototypes either, because the
function to be called is indeterminate at compile time, since the exact
code called depends on inheritance.

   Because the intent of this feature is primarily to let you define
subroutines that work like built-in functions, here are prototypes for
some other functions that parse almost exactly like the corresponding
built-in.

     Declared as			Called as

     sub mylink ($$)	     mylink $old, $new
     sub myvec ($$$)	     myvec $var, $offset, 1
     sub myindex ($$;$)	     myindex &getstring, "substr"
     sub mysyswrite ($$$;$)   mysyswrite $buf, 0, length($buf) - $off, $off
     sub myreverse (@)	     myreverse $a, $b, $c
     sub myjoin ($@)	     myjoin ":", $a, $b, $c
     sub mypop (\@)	     mypop @array
     sub mysplice (\@$$@)     mysplice @array, @array, 0, @pushme
     sub mykeys (\%)	     mykeys %{$hashref}
     sub myopen (*;$)	     myopen HANDLE, $name
     sub mypipe (**)	     mypipe READHANDLE, WRITEHANDLE
     sub mygrep (&@)	     mygrep { /foo/ } $a, $b, $c
     sub myrand ($)	     myrand 42
     sub mytime ()	     mytime

   Any backslashed prototype character represents an actual argument that
absolutely must start with that character.  The value passed as part of
`@_' will be a reference to the actual argument given in the subroutine
call, obtained by applying \ to that argument.

   Unbackslashed prototype characters have special meanings.  Any
unbackslashed `@' or % eats all remaining arguments, and forces list
context.  An argument represented by `$' forces scalar context.  An &
requires an anonymous subroutine, which, if passed as the first argument,
does not require the sub keyword or a subsequent comma.

   A * allows the subroutine to accept a bareword, constant, scalar
expression, typeglob, or a reference to a typeglob in that slot.  The
value will be available to the subroutine either as a simple scalar, or
(in the latter two cases) as a reference to the typeglob.  If you wish to
always convert such arguments to a typeglob reference, use
Symbol::qualify_to_ref() as follows:

     use Symbol 'qualify_to_ref';

     sub foo (*) {
     	my $fh = qualify_to_ref(shift, caller);
     	...
     }

   A semicolon separates mandatory arguments from optional arguments.  It
is redundant before `@' or %, which gobble up everything else.

   Note how the last three examples in the table above are treated
specially by the parser.  `mygrep()' is parsed as a true list operator,
`myrand()' is parsed as a true unary operator with unary precedence the
same as `rand()', and `mytime()' is truly without arguments, just like
`time()'.  That is, if you say

     mytime +2;

   you'll get `mytime() + 2', not `mytime(2)', which is how it would be
parsed without a prototype.

   The interesting thing about & is that you can generate new syntax with
it, provided it's in the initial position:

     sub try (&@) {
     	my($try,$catch) = @_;
     	eval { &$try };
     	if ($@) {
     	    local $_ = $@;
     	    &$catch;
     	}
     }
     sub catch (&) { $_[0] }

     try {
     	die "phooey";
     } catch {
     	/phooey/ and print "unphooey\n";
     };

   That prints `"unphooey"'.  (Yes, there are still unresolved issues
having to do with visibility of `@_'.  I'm ignoring that question for the
moment.  (But note that if we make `@_' lexically scoped, those anonymous
subroutines can act like closures... (Gee, is this sounding a little
Lispish?  (Never mind.))))

   And here's a reimplementation of the Perl grep operator:

     sub mygrep (&@) {
     	my $code = shift;
     	my @result;
     	foreach $_ (@_) {
     	    push(@result, $_) if &$code;
     	}
     	@result;
     }

   Some folks would prefer full alphanumeric prototypes.  Alphanumerics
have been intentionally left out of prototypes for the express purpose of
someday in the future adding named, formal parameters.  The current
mechanism's main goal is to let module writers provide better diagnostics
for module users.  Larry feels the notation quite understandable to Perl
programmers, and that it will not intrude greatly upon the meat of the
module, nor make it harder to read.  The line noise is visually
encapsulated into a small pill that's easy to swallow.

   It's probably best to prototype new functions, not retrofit prototyping
into older ones.  That's because you must be especially careful about
silent impositions of differing list versus scalar contexts.  For example,
if you decide that a function should take just one parameter, like this:

     sub func ($) {
     	my $n = shift;
     	print "you gave me $n\n";
     }

   and someone has been calling it with an array or expression returning a
list:

     func(@foo);
     func( split /:/ );

   Then you've just supplied an automatic scalar in front of their
argument, which can be more than a bit surprising.  The old `@foo' which
used to hold one thing doesn't get passed in.  Instead, `func()' now gets
passed in a 1; that is, the number of elements in `@foo'.  And the split
gets called in scalar context so it starts scribbling on your `@_'
parameter list.  Ouch!

   This is all very powerful, of course, and should be used only in
moderation to make the world a better place.

Constant Functions
------------------

   Functions with a prototype of `()' are potential candidates for
inlining.  If the result after optimization and constant folding is either
a constant or a lexically-scoped scalar which has no other references,
then it will be used in place of function calls made without &.  Calls
made using & are never inlined.  (See `constant.pm' for an easy way to
declare most constants.)

   The following functions would all be inlined:

     sub pi ()		{ 3.14159 }		# Not exact, but close.
     sub PI ()		{ 4 * atan2 1, 1 }	# As good as it gets,
     						# and it's inlined, too!
     sub ST_DEV ()	{ 0 }
     sub ST_INO ()	{ 1 }

     sub FLAG_FOO ()	{ 1 << 8 }
     sub FLAG_BAR ()	{ 1 << 9 }
     sub FLAG_MASK ()	{ FLAG_FOO | FLAG_BAR }

     sub OPT_BAZ ()	{ not (0x1B58 & FLAG_MASK) }
     sub BAZ_VAL () {
     	if (OPT_BAZ) {
     	    return 23;
     	}
     	else {
     	    return 42;
     	}
     }

     sub N () { int(BAZ_VAL) / 3 }
     BEGIN {
     	my $prod = 1;
     	for (1..N) { $prod *= $_ }
     	sub N_FACTORIAL () { $prod }
     }

   If you redefine a subroutine that was eligible for inlining, you'll get
a mandatory warning.  (You can use this warning to tell whether or not a
particular subroutine is considered constant.)  The warning is considered
severe enough not to be optional because previously compiled invocations
of the function will still be using the old value of the function.  If you
need to be able to redefine the subroutine, you need to ensure that it
isn't inlined, either by dropping the `()' prototype (which changes
calling semantics, so beware) or by thwarting the inlining mechanism in
some other way, such as

     sub not_inlined () {
     	23 if $];
     }

Overriding Built-in Functions
-----------------------------

   Many built-in functions may be overridden, though this should be tried
only occasionally and for good reason.  Typically this might be done by a
package attempting to emulate missing built-in functionality on a non-Unix
system.

   Overriding may be done only by importing the name from a
module-ordinary predeclaration isn't good enough.  However, the `use subs'
pragma lets you, in effect, predeclare subs via the import syntax, and
these names may then override built-in ones:

     use subs 'chdir', 'chroot', 'chmod', 'chown';
     chdir $somewhere;
     sub chdir { ... }

   To unambiguously refer to the built-in form, precede the built-in name
with the special package qualifier `CORE::'.  For example, saying
`CORE::open()' always refers to the built-in open(), even if the current
package has imported some other subroutine called `&open()' from
elsewhere.  Even though it looks like a regular function call, it isn't:
you can't take a reference to it, such as the incorrect `\&CORE::open'
might appear to produce.

   Library modules should not in general export built-in names like open
or chdir as part of their default `@EXPORT' list, because these may sneak
into someone else's namespace and change the semantics unexpectedly.
Instead, if the module adds that name to `@EXPORT_OK', then it's possible
for a user to import the name explicitly, but not implicitly.  That is,
they could say

     use Module 'open';

   and it would import the open override.  But if they said

     use Module;

   they would get the default imports without overrides.

   The foregoing mechanism for overriding built-in is restricted, quite
deliberately, to the package that requests the import.  There is a second
method that is sometimes applicable when you wish to override a built-in
everywhere, without regard to namespace boundaries.  This is achieved by
importing a sub into the special namespace `CORE::GLOBAL::'.  Here is an
example that quite brazenly replaces the glob operator with something that
understands regular expressions.

     package REGlob;
     require Exporter;
     @ISA = 'Exporter';
     @EXPORT_OK = 'glob';

     sub import {
     	my $pkg = shift;
     	return unless @_;
     	my $sym = shift;
     	my $where = ($sym =~ s/^GLOBAL_// ? 'CORE::GLOBAL' : caller(0));
     	$pkg->export($where, $sym, @_);
     }

     sub glob {
     	my $pat = shift;
     	my @got;
     	local *D;
     	if (opendir D, '.') {
     	    @got = grep /$pat/, readdir D;
     	    closedir D;
     	}
     	return @got;
     }
     1;

   And here's how it could be (ab)used:

     #use REGlob 'GLOBAL_glob';	    # override glob() in ALL namespaces
     package Foo;
     use REGlob 'glob';		    # override glob() in Foo:: only
     print for <^[a-z_]+\.pm\$>;	    # show all pragmatic modules

   The initial comment shows a contrived, even dangerous example.  By
overriding glob globally, you would be forcing the new (and subversive)
behavior for the glob operator for every namespace, without the complete
cognizance or cooperation of the modules that own those namespaces.
Naturally, this should be done with extreme caution-if it must be done at
all.

   The `REGlob' example above does not implement all the support needed to
cleanly override perl's glob operator.  The built-in glob has different
behaviors depending on whether it appears in a scalar or list context, but
our `REGlob' doesn't.  Indeed, many perl built-in have such context
sensitive behaviors, and these must be adequately supported by a properly
written override.  For a fully functional example of overriding glob,
study the implementation of File::DosGlob in the standard library.

Autoloading
-----------

   If you call a subroutine that is undefined, you would ordinarily get an
immediate, fatal error complaining that the subroutine doesn't exist.
(Likewise for subroutines being used as methods, when the method doesn't
exist in any base class of the class's package.)  However, if an AUTOLOAD
subroutine is defined in the package or packages used to locate the
original subroutine, then that AUTOLOAD subroutine is called with the
arguments that would have been passed to the original subroutine.  The
fully qualified name of the original subroutine magically appears in the
global $AUTOLOAD variable of the same package as the AUTOLOAD routine.
The name is not passed as an ordinary argument because, er, well, just
because, that's why...

   Many AUTOLOAD routines load in a definition for the requested
subroutine using eval(), then execute that subroutine using a special form
of goto() that erases the stack frame of the AUTOLOAD routine without a
trace.  (See the source to the standard module documented in *Note
AutoLoader: (pm.info)AutoLoader,, for example.)  But an AUTOLOAD routine
can also just emulate the routine and never define it.   For example,
let's pretend that a function that wasn't defined should just invoke
system with those arguments.  All you'd do is:

     sub AUTOLOAD {
     	my $program = $AUTOLOAD;
     	$program =~ s/.*:://;
     	system($program, @_);
     }
     date();
     who('am', 'i');
     ls('-l');

   In fact, if you predeclare functions you want to call that way, you
don't even need parentheses:

     use subs qw(date who ls);
     date;
     who "am", "i";
     ls -l;

   A more complete example of this is the standard Shell module, which can
treat undefined subroutine calls as calls to external programs.

   Mechanisms are available to help modules writers split their modules
into autoloadable files.  See the standard AutoLoader module described in
*Note AutoLoader: (pm.info)AutoLoader, and in *Note AutoSplit:
(pm.info)AutoSplit,, the standard SelfLoader modules in *Note SelfLoader:
(pm.info)SelfLoader,, and the document on adding C functions to Perl code
in *Note Perlxs: perlxs,.

Subroutine Attributes
---------------------

   A subroutine declaration or definition may have a list of attributes
associated with it.  If such an attribute list is present, it is broken up
at space or colon boundaries and treated as though a `use attributes' had
been seen.  See *Note Attributes: (pm.info)attributes, for details about
what attributes are currently supported.  Unlike the limitation with the
obsolescent `use attrs', the `sub : ATTRLIST' syntax works to associate
the attributes with a pre-declaration, and not just with a subroutine
definition.

   The attributes must be valid as simple identifier names (without any
punctuation other than the '_' character).  They may have a parameter list
appended, which is only checked for whether its parentheses ('(',')') nest
properly.

   Examples of valid syntax (even though the attributes are unknown):

     sub fnord (&\%) : switch(10,foo(7,3))  :  expensive ;
     sub plugh () : Ugly('\(") :Bad ;
     sub xyzzy : _5x5 { ... }

   Examples of invalid syntax:

     sub fnord : switch(10,foo() ; # ()-string not balanced
     sub snoid : Ugly('(') ;	  # ()-string not balanced
     sub xyzzy : 5x5 ;		  # "5x5" not a valid identifier
     sub plugh : Y2::north ;	  # "Y2::north" not a simple identifier
     sub snurt : foo + bar ;	  # "+" not a colon or space

   The attribute list is passed as a list of constant strings to the code
which associates them with the subroutine.  In particular, the second
example of valid syntax above currently looks like this in terms of how
it's parsed and invoked:

     use attributes __PACKAGE__, \&plugh, q[Ugly('\(")], 'Bad';

   For further details on attribute lists and their manipulation, see
*Note Attributes: (pm.info)attributes,.

SEE ALSO
========

   See `"Function Templates"', *Note Perlref: perlref, for more about
references and closures.  See `"Function Templates"', *Note Perlxs:
perlxs, if you'd like to learn about calling C subroutines from Perl.  See
`"Function Templates"', *Note Perlembed: perlembed, if you'd like to learn
about calling PErl subroutines from C.  See `"Function Templates"', *Note
Perlmod: perlmod, to learn about bundling up your functions in separate
files.  See `"Function Templates"', *Note Perlmodlib: perlmodlib, to learn
what library modules come standard on your system.  See `"Function
Templates"', *Note Perltoot: perltoot, to learn how to make object method
calls.


File: perl.info,  Node: perlsyn,  Next: perlop,  Prev: perldata,  Up: Top

Perl syntax
***********

NAME
====

   perlsyn - Perl syntax

DESCRIPTION
===========

   A Perl script consists of a sequence of declarations and statements.
The sequence of statements is executed just once, unlike in *sed* and
*awk* scripts, where the sequence of statements is executed for each input
line.  While this means that you must explicitly loop over the lines of
your input file (or files), it also means you have much more control over
which files and which lines you look at.  (Actually, I'm lying-it is
possible to do an implicit loop with either the -n or -p switch.  It's
just not the mandatory default like it is in *sed* and *awk*.)

   Perl is, for the most part, a free-form language.  (The only exception
to this is format declarations, for obvious reasons.)  Text from a `"#"'
character until the end of the line is a comment, and is ignored.  If you
attempt to use `/* */' C-style comments, it will be interpreted either as
division or pattern matching, depending on the context, and C++ `//'
comments just look like a null regular expression, so don't do that.

Declarations
------------

   The only things you need to declare in Perl are report formats and
subroutines-and even undefined subroutines can be handled through
AUTOLOAD.  A variable holds the undefined value (undef) until it has been
assigned a defined value, which is anything other than undef.  When used
as a number, undef is treated as 0; when used as a string, it is treated
the empty string, ""; and when used as a reference that isn't being
assigned to, it is treated as an error.  If you enable warnings, you'll be
notified of an uninitialized value whenever you treat undef as a string or
a number.  Well, usually.  Boolean ("don't-care") contexts and operators
such as `++', -, `+=', `-=', and `.=' are always exempt from such warnings.

   A declaration can be put anywhere a statement can, but has no effect on
the execution of the primary sequence of statements-declarations all take
effect at compile time.  Typically all the declarations are put at the
beginning or the end of the script.  However, if you're using
lexically-scoped private variables created with my(), you'll have to make
sure your format or subroutine definition is within the same block scope
as the my if you expect to be able to access those private variables.

   Declaring a subroutine allows a subroutine name to be used as if it
were a list operator from that point forward in the program.  You can
declare a subroutine without defining it by saying `sub name', thus:

     sub myname;
     $me = myname $0 		or die "can't get myname";

   Note that my() functions as a list operator, not as a unary operator; so
be careful to use or instead of `||' in this case.  However, if you were
to declare the subroutine as `sub myname ($)', then `myname' would
function as a unary operator, so either or or `||' would work.

   Subroutines declarations can also be loaded up with the require
statement or both loaded and imported into your namespace with a use
statement.  See *Note Perlmod: perlmod, for details on this.

   A statement sequence may contain declarations of lexically-scoped
variables, but apart from declaring a variable name, the declaration acts
like an ordinary statement, and is elaborated within the sequence of
statements as if it were an ordinary statement.  That means it actually
has both compile-time and run-time effects.

Simple statements
-----------------

   The only kind of simple statement is an expression evaluated for its
side effects.  Every simple statement must be terminated with a semicolon,
unless it is the final statement in a block, in which case the semicolon
is optional.  (A semicolon is still encouraged there if the block takes up
more than one line, because you may eventually add another line.)  Note
that there are some operators like `eval {}' and `do {}' that look like
compound statements, but aren't (they're just TERMs in an expression), and
thus need an explicit termination if used as the last item in a statement.

   Any simple statement may optionally be followed by a *SINGLE* modifier,
just before the terminating semicolon (or block ending).  The possible
modifiers are:

     if EXPR
     unless EXPR
     while EXPR
     until EXPR
     foreach EXPR

   The if and `unless' modifiers have the expected semantics, presuming
you're a speaker of English.  The foreach modifier is an iterator:  For
each value in EXPR, it aliases $_ to the value and executes the statement.
The while and `until' modifiers have the usual "while loop" semantics
(conditional evaluated first), except when applied to a do-BLOCK (or to
the deprecated do-SUBROUTINE statement), in which case the block executes
once before the conditional is evaluated.  This is so that you can write
loops like:

     do {
     	$line = <STDIN>;
     	...
     } until $line  eq ".\n";

   See `do', *Note Perlfunc: perlfunc,.  Note also that the loop control
statements described later will *NOT* work in this construct, because
modifiers don't take loop labels.  Sorry.  You can always put another
block inside of it (for next) or around it (for last) to do that sort of
thing.  For next, just double the braces:

     do {{
     	next if $x == $y;
     	# do something here
     }} until $x++ > $z;

   For last, you have to be more elaborate:

     LOOP: {
     	    do {
     		last if $x = $y**2;
     		# do something here
     	    } while $x++ <= $z;
     }

Compound statements
-------------------

   In Perl, a sequence of statements that defines a scope is called a
block.  Sometimes a block is delimited by the file containing it (in the
case of a required file, or the program as a whole), and sometimes a block
is delimited by the extent of a string (in the case of an eval).

   But generally, a block is delimited by curly brackets, also known as
braces.  We will call this syntactic construct a BLOCK.

   The following compound statements may be used to control flow:

     if (EXPR) BLOCK
     if (EXPR) BLOCK else BLOCK
     if (EXPR) BLOCK elsif (EXPR) BLOCK ... else BLOCK
     LABEL while (EXPR) BLOCK
     LABEL while (EXPR) BLOCK continue BLOCK
     LABEL for (EXPR; EXPR; EXPR) BLOCK
     LABEL foreach VAR (LIST) BLOCK
     LABEL foreach VAR (LIST) BLOCK continue BLOCK
     LABEL BLOCK continue BLOCK

   Note that, unlike C and Pascal, these are defined in terms of BLOCKs,
not statements.  This means that the curly brackets are required-no
dangling statements allowed.  If you want to write conditionals without
curly brackets there are several other ways to do it.  The following all
do the same thing:

     if (!open(FOO)) { die "Can't open $FOO: $!"; }
     die "Can't open $FOO: $!" unless open(FOO);
     open(FOO) or die "Can't open $FOO: $!";	# FOO or bust!
     open(FOO) ? 'hi mom' : die "Can't open $FOO: $!";
     			# a bit exotic, that last one

   The if statement is straightforward.  Because BLOCKs are always bounded
by curly brackets, there is never any ambiguity about which if an else
goes with.  If you use `unless' in place of if, the sense of the test is
reversed.

   The while statement executes the block as long as the expression is
true (does not evaluate to the null string "" or 0 or `"0"').  The LABEL
is optional, and if present, consists of an identifier followed by a
colon.  The LABEL identifies the loop for the loop control statements
next, last, and redo.  If the LABEL is omitted, the loop control statement
refers to the innermost enclosing loop.  This may include dynamically
looking back your call-stack at run time to find the LABEL.  Such
desperate behavior triggers a warning if you use the `use warnings' praga
or the -w flag.  Unlike a foreach statement, a while statement never
implicitly localises any variables.

   If there is a continue BLOCK, it is always executed just before the
conditional is about to be evaluated again, just like the third part of a
for loop in C.  Thus it can be used to increment a loop variable, even
when the loop has been continued via the next statement (which is similar
to the C continue statement).

Loop Control
------------

   The next command is like the continue statement in C; it starts the
next iteration of the loop:

     LINE: while (<STDIN>) {
     	next LINE if /^#/;	# discard comments
     	...
     }

   The last command is like the break statement in C (as used in loops);
it immediately exits the loop in question.  The continue block, if any, is
not executed:

     LINE: while (<STDIN>) {
     	last LINE if /^$/;	# exit when done with header
     	...
     }

   The redo command restarts the loop block without evaluating the
conditional again.  The continue block, if any, is not executed.  This
command is normally used by programs that want to lie to themselves about
what was just input.

   For example, when processing a file like `/etc/termcap'.  If your input
lines might end in backslashes to indicate continuation, you want to skip
ahead and get the next record.

     while (<>) {
     	chomp;
     	if (s/\\$//) {
     	    $_ .= <>;
     	    redo unless eof();
     	}
     	# now process $_
     }

   which is Perl short-hand for the more explicitly written version:

     LINE: while (defined($line = <ARGV>)) {
     	chomp($line);
     	if ($line =~ s/\\$//) {
     	    $line .= <ARGV>;
     	    redo LINE unless eof(); # not eof(ARGV)!
     	}
     	# now process $line
     }

   Note that if there were a continue block on the above code, it would get
executed even on discarded lines.  This is often used to reset line
counters or `?pat?' one-time matches.

     # inspired by :1,$g/fred/s//WILMA/
     while (<>) {
     	?(fred)?    && s//WILMA $1 WILMA/;
     	?(barney)?  && s//BETTY $1 BETTY/;
     	?(homer)?   && s//MARGE $1 MARGE/;
     } continue {
     	print "$ARGV $.: $_";
     	close ARGV  if eof();		# reset $.
     	reset	    if eof();		# reset ?pat?
     }

   If the word while is replaced by the word `until', the sense of the
test is reversed, but the conditional is still tested before the first
iteration.

   The loop control statements don't work in an if or `unless', since they
aren't loops.  You can double the braces to make them such, though.

     if (/pattern/) {{
     	next if /fred/;
     	next if /barney/;
     	# so something here
     }}

   The form `while/if BLOCK BLOCK', available in Perl 4, is no longer
available.   Replace any occurrence of `if BLOCK' by `if (do BLOCK)'.

For Loops
---------

   Perl's C-style for loop works exactly like the corresponding while loop;
that means that this:

     for ($i = 1; $i < 10; $i++) {
     	...
     }

   is the same as this:

     $i = 1;
     while ($i < 10) {
     	...
     } continue {
     	$i++;
     }

   (There is one minor difference: The first form implies a lexical scope
for variables declared with my in the initialization expression.)

   Besides the normal array index looping, for can lend itself to many
other interesting applications.  Here's one that avoids the problem you
get into if you explicitly test for end-of-file on an interactive file
descriptor causing your program to appear to hang.

     $on_a_tty = -t STDIN && -t STDOUT;
     sub prompt { print "yes? " if $on_a_tty }
     for ( prompt(); <STDIN>; prompt() ) {
     	# do something
     }

Foreach Loops
-------------

   The foreach loop iterates over a normal list value and sets the
variable VAR to be each element of the list in turn.  If the variable is
preceded with the keyword my, then it is lexically scoped, and is
therefore visible only within the loop.  Otherwise, the variable is
implicitly local to the loop and regains its former value upon exiting the
loop.  If the variable was previously declared with my, it uses that
variable instead of the global one, but it's still localized to the loop.

   The foreach keyword is actually a synonym for the for keyword, so you
can use foreach for readability or for for brevity.  (Or because the
Bourne shell is more familiar to you than *csh*, so writing for comes more
naturally.)  If VAR is omitted, $_ is set to each value.  If any element
of LIST is an lvalue, you can modify it by modifying VAR inside the loop.
That's because the foreach loop index variable is an implicit alias for
each item in the list that you're looping over.

   If any part of LIST is an array, foreach will get very confused if you
add or remove elements within the loop body, for example with splice.   So
don't do that.

   foreach probably won't do what you expect if VAR is a tied or other
special variable.   Don't do that either.

   Examples:

     for (@ary) { s/foo/bar/ }

     for my $elem (@elements) {
     	$elem *= 2;
     }

     for $count (10,9,8,7,6,5,4,3,2,1,'BOOM') {
     	print $count, "\n"; sleep(1);
     }

     for (1..15) { print "Merry Christmas\n"; }

     foreach $item (split(/:[\\\n:]*/, $ENV{TERMCAP})) {
     	print "Item: $item\n";
     }

   Here's how a C programmer might code up a particular algorithm in Perl:

     for (my $i = 0; $i < @ary1; $i++) {
     	for (my $j = 0; $j < @ary2; $j++) {
     	    if ($ary1[$i] > $ary2[$j]) {
     		last; # can't go to outer :-(
     	    }
     	    $ary1[$i] += $ary2[$j];
     	}
     	# this is where that last takes me
     }

   Whereas here's how a Perl programmer more comfortable with the idiom
might do it:

     OUTER: for my $wid (@ary1) {
     INNER:   for my $jet (@ary2) {
     		next OUTER if $wid > $jet;
     		$wid += $jet;
     	     }
     	  }

   See how much easier this is?  It's cleaner, safer, and faster.  It's
cleaner because it's less noisy.  It's safer because if code gets added
between the inner and outer loops later on, the new code won't be
accidentally executed.  The next explicitly iterates the other loop rather
than merely terminating the inner one.  And it's faster because Perl
executes a foreach statement more rapidly than it would the equivalent for
loop.

Basic BLOCKs and Switch Statements
----------------------------------

   A BLOCK by itself (labeled or not) is semantically equivalent to a loop
that executes once.  Thus you can use any of the loop control statements
in it to leave or restart the block.  (Note that this is *NOT* true in
`eval{}', `sub{}', or contrary to popular belief `do{}' blocks, which do
*NOT* count as loops.)  The continue block is optional.

   The BLOCK construct is particularly nice for doing case structures.

     SWITCH: {
     	if (/^abc/) { $abc = 1; last SWITCH; }
     	if (/^def/) { $def = 1; last SWITCH; }
     	if (/^xyz/) { $xyz = 1; last SWITCH; }
     	$nothing = 1;
     }

   There is no official switch statement in Perl, because there are
already several ways to write the equivalent.  In addition to the above,
you could write

     SWITCH: {
     	$abc = 1, last SWITCH  if /^abc/;
     	$def = 1, last SWITCH  if /^def/;
     	$xyz = 1, last SWITCH  if /^xyz/;
     	$nothing = 1;
     }

   (That's actually not as strange as it looks once you realize that you
can use loop control "operators" within an expression,  That's just the
normal C comma operator.)

   or

     SWITCH: {
     	/^abc/ && do { $abc = 1; last SWITCH; };
     	/^def/ && do { $def = 1; last SWITCH; };
     	/^xyz/ && do { $xyz = 1; last SWITCH; };
     	$nothing = 1;
     }

   or formatted so it stands out more as a "proper" switch statement:

     SWITCH: {
     	/^abc/ 	    && do {
     			    $abc = 1;
     			    last SWITCH;
     		       };

     /^def/ 	    && do {
     		    $def = 1;
     		    last SWITCH;
     	       };

     /^xyz/ 	    && do {
     		    $xyz = 1;
     		    last SWITCH;
     	        };
     $nothing = 1;
         }

   or

     SWITCH: {
     	/^abc/ and $abc = 1, last SWITCH;
     	/^def/ and $def = 1, last SWITCH;
     	/^xyz/ and $xyz = 1, last SWITCH;
     	$nothing = 1;
     }

   or even, horrors,

     if (/^abc/)
     	{ $abc = 1 }
     elsif (/^def/)
     	{ $def = 1 }
     elsif (/^xyz/)
     	{ $xyz = 1 }
     else
     	{ $nothing = 1 }

   A common idiom for a switch statement is to use foreach's aliasing to
make a temporary assignment to $_ for convenient matching:

     SWITCH: for ($where) {
     		/In Card Names/     && do { push @flags, '-e'; last; };
     		/Anywhere/          && do { push @flags, '-h'; last; };
     		/In Rulings/        && do {                    last; };
     		die "unknown value for form variable where: `$where'";
     	    }

   Another interesting approach to a switch statement is arrange for a do
block to return the proper value:

     $amode = do {
     	if     ($flag & O_RDONLY) { "r" }	# XXX: isn't this 0?
     	elsif  ($flag & O_WRONLY) { ($flag & O_APPEND) ? "a" : "w" }
     	elsif  ($flag & O_RDWR)   {
     	    if ($flag & O_CREAT)  { "w+" }
     	    else                  { ($flag & O_APPEND) ? "a+" : "r+" }
     	}
     };

   Or

     print do {
         ($flags & O_WRONLY) ? "write-only"          :
         ($flags & O_RDWR)   ? "read-write"          :
                               "read-only";
     };

   Or if you are certainly that all the `&&' clauses are true, you can use
something like this, which "switches" on the value of the
`HTTP_USER_AGENT' envariable.

     #!/usr/bin/perl
     # pick out jargon file page based on browser
     $dir = 'http://www.wins.uva.nl/~mes/jargon';
     for ($ENV{HTTP_USER_AGENT}) {
     	$page  =    /Mac/            && 'm/Macintrash.html'
     		 || /Win(dows )?NT/  && 'e/evilandrude.html'
     		 || /Win|MSIE|WebTV/ && 'm/MicroslothWindows.html'
     		 || /Linux/          && 'l/Linux.html'
     		 || /HP-UX/          && 'h/HP-SUX.html'
     		 || /SunOS/          && 's/ScumOS.html'
     		 ||                     'a/AppendixB.html';
     }
     print "Location: $dir/$page\015\012\015\012";

   That kind of switch statement only works when you know the `&&' clauses
will be true.  If you don't, the previous `?:' example should be used.

   You might also consider writing a hash of subroutine references instead
of synthesizing a switch statement.

Goto
----

   Although not for the faint of heart, Perl does support a goto
statement.  There are three forms: goto-LABEL, goto-EXPR, and goto-&NAME.
A loop's LABEL is not actually a valid target for a goto; it's just the
name of the loop.

   The goto-LABEL form finds the statement labeled with LABEL and resumes
execution there.  It may not be used to go into any construct that
requires initialization, such as a subroutine or a foreach loop.  It also
can't be used to go into a construct that is optimized away.  It can be
used to go almost anywhere else within the dynamic scope, including out of
subroutines, but it's usually better to use some other construct such as
last or die.  The author of Perl has never felt the need to use this form
of goto (in Perl, that is-C is another matter).

   The goto-EXPR form expects a label name, whose scope will be resolved
dynamically.  This allows for computed gotos per FORTRAN, but isn't
necessarily recommended if you're optimizing for maintainability:

     goto(("FOO", "BAR", "GLARCH")[$i]);

   The goto-&NAME form is highly magical, and substitutes a call to the
named subroutine for the currently running subroutine.  This is used by
AUTOLOAD() subroutines that wish to load another subroutine and then
pretend that the other subroutine had been called in the first place
(except that any modifications to `@_' in the current subroutine are
propagated to the other subroutine.)  After the goto, not even `caller()'
will be able to tell that this routine was called first.

   In almost all cases like this, it's usually a far, far better idea to
use the structured control flow mechanisms of next, last, or redo instead
of resorting to a goto.  For certain applications, the catch and throw
pair of `eval{}' and die() for exception processing can also be a prudent
approach.

PODs: Embedded Documentation
----------------------------

   Perl has a mechanism for intermixing documentation with source code.
While it's expecting the beginning of a new statement, if the compiler
encounters a line that begins with an equal sign and a word, like this

     =head1 Here There Be Pods!

   Then that text and all remaining text up through and including a line
beginning with =cut will be ignored.  The format of the intervening text
is described in *Note Perlpod: perlpod,.

   This allows you to intermix your source code and your documentation
text freely, as in

     =item snazzle($)

     The snazzle() function will behave in the most spectacular
     form that you can possibly imagine, not even excepting
     cybernetic pyrotechnics.

     =cut back to the compiler, nuff of this pod stuff!

     sub snazzle($) {
     	my $thingie = shift;
     	.........
     }

   Note that pod translators should look at only paragraphs beginning with
a pod directive (it makes parsing easier), whereas the compiler actually
knows to look for pod escapes even in the middle of a paragraph.  This
means that the following secret stuff will be ignored by both the compiler
and the translators.

     $a=3;
     =secret stuff
      warn "Neither POD nor CODE!?"
     =cut back
     print "got $a\n";

   You probably shouldn't rely upon the `warn()' being podded out forever.
Not all pod translators are well-behaved in this regard, and perhaps the
compiler will become pickier.

   One may also use pod directives to quickly comment out a section of
code.

Plain Old Comments (Not!)
-------------------------

   Much like the C preprocessor, Perl can process line directives.  Using
this, one can control Perl's idea of filenames and line numbers in error
or warning messages (especially for strings that are processed with
`eval()').  The syntax for this mechanism is the same as for most C
preprocessors: it matches the regular expression
`/^#\s*line\s+(\d+)\s*(?:\s"([^"]+)")?\s*$/' with $1 being the line number
for the next line, and $2 being the optional filename (specified within
quotes).

   Here are some examples that you should be able to type into your command
shell:

     % perl
     # line 200 "bzzzt"
     # the `#' on the previous line must be the first char on line
     die 'foo';
     __END__
     foo at bzzzt line 201.

     % perl
     # line 200 "bzzzt"
     eval qq[\n#line 2001 ""\ndie 'foo']; print $@;
     __END__
     foo at - line 2001.

     % perl
     eval qq[\n#line 200 "foo bar"\ndie 'foo']; print $@;
     __END__
     foo at foo bar line 200.

     % perl
     # line 345 "goop"
     eval "\n#line " . __LINE__ . ' "' . __FILE__ ."\"\ndie 'foo'";
     print $@;
     __END__
     foo at goop line 345.


File: perl.info,  Node: perlthrtut,  Next: perllexwarn,  Prev: perlfork,  Up: Top

tutorial on threads in Perl
***************************

NAME
====

   perlthrtut - tutorial on threads in Perl

DESCRIPTION
===========

     WARNING: Threading is an experimental feature.  Both the interface
     and implementation are subject to change drastically.  In fact, this
     documentation describes the flavor of threads that was in version
     5.005.  Perl 5.6.0 and later have the beginnings of support for
     interpreter threads, which (when finished) is expected to be
     significantly different from what is described here.  The information
     contained here may therefore soon be obsolete.  Use at your own risk!

   One of the most prominent new features of Perl 5.005 is the inclusion
of threads.  Threads make a number of things a lot easier, and are a very
useful addition to your bag of programming tricks.

What Is A Thread Anyway?
========================

   A thread is a flow of control through a program with a single execution
point.

   Sounds an awful lot like a process, doesn't it? Well, it should.
Threads are one of the pieces of a process.  Every process has at least
one thread and, up until now, every process running Perl had only one
thread.  With 5.005, though, you can create extra threads.  We're going to
show you how, when, and why.

Threaded Program Models
=======================

   There are three basic ways that you can structure a threaded program.
Which model you choose depends on what you need your program to do.  For
many non-trivial threaded programs you'll need to choose different models
for different pieces of your program.

Boss/Worker
-----------

   The boss/worker model usually has one `boss' thread and one or more
`worker' threads.  The boss thread gathers or generates tasks that need to
be done, then parcels those tasks out to the appropriate worker thread.

   This model is common in GUI and server programs, where a main thread
waits for some event and then passes that event to the appropriate worker
threads for processing.  Once the event has been passed on, the boss
thread goes back to waiting for another event.

   The boss thread does relatively little work.  While tasks aren't
necessarily performed faster than with any other method, it tends to have
the best user-response times.

Work Crew
---------

   In the work crew model, several threads are created that do essentially
the same thing to different pieces of data.  It closely mirrors classical
parallel processing and vector processors, where a large array of
processors do the exact same thing to many pieces of data.

   This model is particularly useful if the system running the program
will distribute multiple threads across different processors.  It can also
be useful in ray tracing or rendering engines, where the individual
threads can pass on interim results to give the user visual feedback.

Pipeline
--------

   The pipeline model divides up a task into a series of steps, and passes
the results of one step on to the thread processing the next.  Each thread
does one thing to each piece of data and passes the results to the next
thread in line.

   This model makes the most sense if you have multiple processors so two
or more threads will be executing in parallel, though it can often make
sense in other contexts as well.  It tends to keep the individual tasks
small and simple, as well as allowing some parts of the pipeline to block
(on I/O or system calls, for example) while other parts keep going.  If
you're running different parts of the pipeline on different processors you
may also take advantage of the caches on each processor.

   This model is also handy for a form of recursive programming where,
rather than having a subroutine call itself, it instead creates another
thread.  Prime and Fibonacci generators both map well to this form of the
pipeline model. (A version of a prime number generator is presented later
on.)

Native threads
==============

   There are several different ways to implement threads on a system.  How
threads are implemented depends both on the vendor and, in some cases, the
version of the operating system.  Often the first implementation will be
relatively simple, but later versions of the OS will be more sophisticated.

   While the information in this section is useful, it's not necessary, so
you can skip it if you don't feel up to it.

   There are three basic categories of threads-user-mode threads, kernel
threads, and multiprocessor kernel threads.

   User-mode threads are threads that live entirely within a program and
its libraries.  In this model, the OS knows nothing about threads.  As far
as it's concerned, your process is just a process.

   This is the easiest way to implement threads, and the way most OSes
start.  The big disadvantage is that, since the OS knows nothing about
threads, if one thread blocks they all do.  Typical blocking activities
include most system calls, most I/O, and things like sleep().

   Kernel threads are the next step in thread evolution.  The OS knows
about kernel threads, and makes allowances for them.  The main difference
between a kernel thread and a user-mode thread is blocking.  With kernel
threads, things that block a single thread don't block other threads.
This is not the case with user-mode threads, where the kernel blocks at
the process level and not the thread level.

   This is a big step forward, and can give a threaded program quite a
performance boost over non-threaded programs.  Threads that block
performing I/O, for example, won't block threads that are doing other
things.  Each process still has only one thread running at once, though,
regardless of how many CPUs a system might have.

   Since kernel threading can interrupt a thread at any time, they will
uncover some of the implicit locking assumptions you may make in your
program.  For example, something as simple as `$a = $a + 2' can behave
unpredictably with kernel threads if $a is visible to other threads, as
another thread may have changed $a between the time it was fetched on the
right hand side and the time the new value is stored.

   Multiprocessor Kernel Threads are the final step in thread support.
With multiprocessor kernel threads on a machine with multiple CPUs, the OS
may schedule two or more threads to run simultaneously on different CPUs.

   This can give a serious performance boost to your threaded program,
since more than one thread will be executing at the same time.  As a
tradeoff, though, any of those nagging synchronization issues that might
not have shown with basic kernel threads will appear with a vengeance.

   In addition to the different levels of OS involvement in threads,
different OSes (and different thread implementations for a particular OS)
allocate CPU cycles to threads in different ways.

   Cooperative multitasking systems have running threads give up control
if one of two things happen.  If a thread calls a yield function, it gives
up control.  It also gives up control if the thread does something that
would cause it to block, such as perform I/O.  In a cooperative
multitasking implementation, one thread can starve all the others for CPU
time if it so chooses.

   Preemptive multitasking systems interrupt threads at regular intervals
while the system decides which thread should run next.  In a preemptive
multitasking system, one thread usually won't monopolize the CPU.

   On some systems, there can be cooperative and preemptive threads
running simultaneously. (Threads running with realtime priorities often
behave cooperatively, for example, while threads running at normal
priorities behave preemptively.)

What kind of threads are perl threads?
======================================

   If you have experience with other thread implementations, you might
find that things aren't quite what you expect.  It's very important to
remember when dealing with Perl threads that Perl Threads Are Not X
Threads, for all values of X.  They aren't POSIX threads, or DecThreads,
or Java's Green threads, or Win32 threads.  There are similarities, and
the broad concepts are the same, but if you start looking for
implementation details you're going to be either disappointed or confused.
Possibly both.

   This is not to say that Perl threads are completely different from
everything that's ever come before-they're not.  Perl's threading model
owes a lot to other thread models, especially POSIX.  Just as Perl is not
C, though, Perl threads are not POSIX threads.  So if you find yourself
looking for mutexes, or thread priorities, it's time to step back a bit
and think about what you want to do and how Perl can do it.

Threadsafe Modules
==================

   The addition of threads has changed Perl's internals substantially.
There are implications for people who write modules-especially modules
with XS code or external libraries.  While most modules won't encounter
any problems, modules that aren't explicitly tagged as thread-safe should
be tested before being used in production code.

   Not all modules that you might use are thread-safe, and you should
always assume a module is unsafe unless the documentation says otherwise.
This includes modules that are distributed as part of the core.  Threads
are a beta feature, and even some of the standard modules aren't
thread-safe.

   If you're using a module that's not thread-safe for some reason, you
can protect yourself by using semaphores and lots of programming
discipline to control access to the module.  Semaphores are covered later
in the article.  Perl Threads Are Different

Thread Basics
=============

   The core Thread module provides the basic functions you need to write
threaded programs.  In the following sections we'll cover the basics,
showing you what you need to do to create a threaded program.   After
that, we'll go over some of the features of the Thread module that make
threaded programming easier.

Basic Thread Support
--------------------

   Thread support is a Perl compile-time option-it's something that's
turned on or off when Perl is built at your site, rather than when your
programs are compiled. If your Perl wasn't compiled with thread support
enabled, then any attempt to use threads will fail.

   Remember that the threading support in 5.005 is in beta release, and
should be treated as such.   You should expect that it may not function
entirely properly, and the thread interface may well change some before it
is a fully supported, production release.  The beta version shouldn't be
used for mission-critical projects.  Having said that, threaded Perl is
pretty nifty, and worth a look.

   Your programs can use the Config module to check whether threads are
enabled. If your program can't run without them, you can say something
like:

     $Config{usethreads} or die "Recompile Perl with threads to run this program.";

   A possibly-threaded program using a possibly-threaded module might have
code like this:

     use Config;
     use MyMod;

     if ($Config{usethreads}) {
         # We have threads
         require MyMod_threaded;
         import MyMod_threaded;
     } else {
         require MyMod_unthreaded;
         import MyMod_unthreaded;
     }

   Since code that runs both with and without threads is usually pretty
messy, it's best to isolate the thread-specific code in its own module.
In our example above, that's what MyMod_threaded is, and it's only
imported if we're running on a threaded Perl.

Creating Threads
----------------

   The Thread package provides the tools you need to create new threads.
Like any other module, you need to tell Perl you want to use it; use
Thread imports all the pieces you need to create basic threads.

   The simplest, straightforward way to create a thread is with new():

     use Thread;

     $thr = new Thread \&sub1;

     sub sub1 {
         print "In the thread\n";
     }

   The new() method takes a reference to a subroutine and creates a new
thread, which starts executing in the referenced subroutine.  Control then
passes both to the subroutine and the caller.

   If you need to, your program can pass parameters to the subroutine as
part of the thread startup.  Just include the list of parameters as part
of the `Thread::new' call, like this:

     use Thread;
     $Param3 = "foo";
     $thr = new Thread \&sub1, "Param 1", "Param 2", $Param3;
     $thr = new Thread \&sub1, @ParamList;
     $thr = new Thread \&sub1, qw(Param1 Param2 $Param3);

     sub sub1 {
         my @InboundParameters = @_;
         print "In the thread\n";
         print "got parameters >", join("<>", @InboundParameters), "<\n";
     }

   The subroutine runs like a normal Perl subroutine, and the call to new
Thread returns whatever the subroutine returns.

   The last example illustrates another feature of threads.  You can spawn
off several threads using the same subroutine.  Each thread executes the
same subroutine, but in a separate thread with a separate environment and
potentially separate arguments.

   The other way to spawn a new thread is with async(), which is a way to
spin off a chunk of code like eval(), but into its own thread:

     use Thread qw(async);

     $LineCount = 0;

     $thr = async {
         while(<>) {$LineCount++}
         print "Got $LineCount lines\n";
     };

     print "Waiting for the linecount to end\n";
     $thr->join;
     print "All done\n";

   You'll notice we did a use Thread qw(async) in that example.  async is
not exported by default, so if you want it, you'll either need to import
it before you use it or fully qualify it as Thread::async.  You'll also
note that there's a semicolon after the closing brace.  That's because
async() treats the following block as an anonymous subroutine, so the
semicolon is necessary.

   Like eval(), the code executes in the same context as it would if it
weren't spun off.  Since both the code inside and after the async start
executing, you need to be careful with any shared resources.  Locking and
other synchronization techniques are covered later.

Giving up control
-----------------

   There are times when you may find it useful to have a thread explicitly
give up the CPU to another thread.  Your threading package might not
support preemptive multitasking for threads, for example, or you may be
doing something compute-intensive and want to make sure that the
user-interface thread gets called frequently.  Regardless, there are times
that you might want a thread to give up the processor.

   Perl's threading package provides the yield() function that does this.
yield() is pretty straightforward, and works like this:

     use Thread qw(yield async);
     async {
         my $foo = 50;
         while ($foo--) { print "first async\n" }
         yield;
         $foo = 50;
         while ($foo--) { print "first async\n" }
     };
     async {
         my $foo = 50;
         while ($foo--) { print "second async\n" }
         yield;
         $foo = 50;
         while ($foo--) { print "second async\n" }
     };

Waiting For A Thread To Exit
----------------------------

   Since threads are also subroutines, they can return values.  To wait
for a thread to exit and extract any scalars it might return, you can use
the join() method.

     use Thread;
     $thr = new Thread \&sub1;

     @ReturnData = $thr->join;
     print "Thread returned @ReturnData";

     sub sub1 { return "Fifty-six", "foo", 2; }

   In the example above, the join() method returns as soon as the thread
ends.  In addition to waiting for a thread to finish and gathering up any
values that the thread might have returned, join() also performs any OS
cleanup necessary for the thread.  That cleanup might be important,
especially for long-running programs that spawn lots of threads.  If you
don't want the return values and don't want to wait for the thread to
finish, you should call the detach() method instead. detach() is covered
later in the article.

Errors In Threads
-----------------

   So what happens when an error occurs in a thread? Any errors that could
be caught with eval() are postponed until the thread is joined.  If your
program never joins, the errors appear when your program exits.

   Errors deferred until a join() can be caught with eval():

     use Thread qw(async);
     $thr = async {$b = 3/0};   # Divide by zero error
     $foo = eval {$thr->join};
     if ($@) {
         print "died with error $@\n";
     } else {
         print "Hey, why aren't you dead?\n";
     }

   eval() passes any results from the joined thread back unmodified, so if
you want the return value of the thread, this is your only chance to get
them.

Ignoring A Thread
-----------------

   join() does three things: it waits for a thread to exit, cleans up
after it, and returns any data the thread may have produced.  But what if
you're not interested in the thread's return values, and you don't really
care when the thread finishes? All you want is for the thread to get
cleaned up after when it's done.

   In this case, you use the detach() method.  Once a thread is detached,
it'll run until it's finished, then Perl will clean up after it
automatically.

     use Thread;
     $thr = new Thread \&sub1; # Spawn the thread

     $thr->detach; # Now we officially don't care any more

     sub sub1 {
         $a = 0;
         while (1) {
             $a++;
             print "\$a is $a\n";
             sleep 1;
         }
     }

   Once a thread is detached, it may not be joined, and any output that it
might have produced (if it was done and waiting for a join) is lost.

Threads And Data
================

   Now that we've covered the basics of threads, it's time for our next
topic: data.  Threading introduces a couple of complications to data
access that non-threaded programs never need to worry about.

Shared And Unshared Data
------------------------

   The single most important thing to remember when using threads is that
all threads potentially have access to all the data anywhere in your
program.  While this is true with a nonthreaded Perl program as well, it's
especially important to remember with a threaded program, since more than
one thread can be accessing this data at once.

   Perl's scoping rules don't change because you're using threads.  If a
subroutine (or block, in the case of async()) could see a variable if you
weren't running with threads, it can see it if you are.  This is
especially important for the subroutines that create, and makes my
variables even more important.  Remember-if your variables aren't
lexically scoped (declared with my) you're probably sharing them between
threads.

Thread Pitfall: Races
---------------------

   While threads bring a new set of useful tools, they also bring a number
of pitfalls.  One pitfall is the race condition:

     use Thread;
     $a = 1;
     $thr1 = Thread->new(\&sub1);
     $thr2 = Thread->new(\&sub2);

     sleep 10;
     print "$a\n";

     sub sub1 { $foo = $a; $a = $foo + 1; }
     sub sub2 { $bar = $a; $a = $bar + 1; }

   What do you think $a will be? The answer, unfortunately, is "it
depends." Both sub1() and sub2() access the global variable $a, once to
read and once to write.  Depending on factors ranging from your thread
implementation's scheduling algorithm to the phase of the moon, $a can be
2 or 3.

   Race conditions are caused by unsynchronized access to shared data.
Without explicit synchronization, there's no way to be sure that nothing
has happened to the shared data between the time you access it and the
time you update it.  Even this simple code fragment has the possibility of
error:

     use Thread qw(async);
     $a = 2;
     async{ $b = $a; $a = $b + 1; };
     async{ $c = $a; $a = $c + 1; };

   Two threads both access $a.  Each thread can potentially be interrupted
at any point, or be executed in any order.  At the end, $a could be 3 or
4, and both $b and $c could be 2 or 3.

   Whenever your program accesses data or resources that can be accessed
by other threads, you must take steps to coordinate access or risk data
corruption and race conditions.

Controlling access: lock()
--------------------------

   The lock() function takes a variable (or subroutine, but we'll get to
that later) and puts a lock on it.  No other thread may lock the variable
until the locking thread exits the innermost block containing the lock.
Using lock() is straightforward:

     use Thread qw(async);
     $a = 4;
     $thr1 = async {
         $foo = 12;
         {
             lock ($a); # Block until we get access to $a
             $b = $a;
             $a = $b * $foo;
         }
         print "\$foo was $foo\n";
     };
     $thr2 = async {
         $bar = 7;
         {
             lock ($a); # Block until we can get access to $a
             $c = $a;
             $a = $c * $bar;
         }
         print "\$bar was $bar\n";
     };
     $thr1->join;
     $thr2->join;
     print "\$a is $a\n";

   lock() blocks the thread until the variable being locked is available.
When lock() returns, your thread can be sure that no other thread can lock
that variable until the innermost block containing the lock exits.

   It's important to note that locks don't prevent access to the variable
in question, only lock attempts.  This is in keeping with Perl's
longstanding tradition of courteous programming, and the advisory file
locking that flock() gives you.  Locked subroutines behave differently,
however.  We'll cover that later in the article.

   You may lock arrays and hashes as well as scalars.  Locking an array,
though, will not block subsequent locks on array elements, just lock
attempts on the array itself.

   Finally, locks are recursive, which means it's okay for a thread to
lock a variable more than once.  The lock will last until the outermost
lock() on the variable goes out of scope.

Thread Pitfall: Deadlocks
-------------------------

   Locks are a handy tool to synchronize access to data.  Using them
properly is the key to safe shared data.  Unfortunately, locks aren't
without their dangers.  Consider the following code:

     use Thread qw(async yield);
     $a = 4;
     $b = "foo";
     async {
         lock($a);
         yield;
         sleep 20;
         lock ($b);
     };
     async {
         lock($b);
         yield;
         sleep 20;
         lock ($a);
     };

   This program will probably hang until you kill it.  The only way it
won't hang is if one of the two async() routines acquires both locks
first.  A guaranteed-to-hang version is more complicated, but the
principle is the same.

   The first thread spawned by async() will grab a lock on $a then, a
second or two later, try to grab a lock on $b.  Meanwhile, the second
thread grabs a lock on $b, then later tries to grab a lock on $a.  The
second lock attempt for both threads will block, each waiting for the
other to release its lock.

   This condition is called a deadlock, and it occurs whenever two or more
threads are trying to get locks on resources that the others own.  Each
thread will block, waiting for the other to release a lock on a resource.
That never happens, though, since the thread with the resource is itself
waiting for a lock to be released.

   There are a number of ways to handle this sort of problem.  The best
way is to always have all threads acquire locks in the exact same order.
If, for example, you lock variables $a, $b, and $c, always lock $a before
$b, and $b before $c.  It's also best to hold on to locks for as short a
period of time to minimize the risks of deadlock.

Queues: Passing Data Around
---------------------------

   A queue is a special thread-safe object that lets you put data in one
end and take it out the other without having to worry about
synchronization issues.  They're pretty straightforward, and look like
this:

     use Thread qw(async);
     use Thread::Queue;

     my $DataQueue = new Thread::Queue;
     $thr = async {
         while ($DataElement = $DataQueue->dequeue) {
             print "Popped $DataElement off the queue\n";
         }
     };

     $DataQueue->enqueue(12);
     $DataQueue->enqueue("A", "B", "C");
     $DataQueue->enqueue(\$thr);
     sleep 10;
     $DataQueue->enqueue(undef);

   You create the queue with new Thread::Queue.  Then you can add lists of
scalars onto the end with enqueue(), and pop scalars off the front of it
with dequeue().  A queue has no fixed size, and can grow as needed to hold
everything pushed on to it.

   If a queue is empty, dequeue() blocks until another thread enqueues
something.  This makes queues ideal for event loops and other
communications between threads.

Threads And Code
================

   In addition to providing thread-safe access to data via locks and
queues, threaded Perl also provides general-purpose semaphores for coarser
synchronization than locks provide and thread-safe access to entire
subroutines.

Semaphores: Synchronizing Data Access
-------------------------------------

   Semaphores are a kind of generic locking mechanism.  Unlike lock, which
gets a lock on a particular scalar, Perl doesn't associate any particular
thing with a semaphore so you can use them to control access to anything
you like.  In addition, semaphores can allow more than one thread to
access a resource at once, though by default semaphores only allow one
thread access at a time.

Basic semaphores
     Semaphores have two methods, down and up. down decrements the resource
     count, while up increments it.  down calls will block if the
     semaphore's current count would decrement below zero.  This program
     gives a quick demonstration:

          use Thread qw(yield);
          use Thread::Semaphore;
          my $semaphore = new Thread::Semaphore;
          $GlobalVariable = 0;

          $thr1 = new Thread \&sample_sub, 1;
          $thr2 = new Thread \&sample_sub, 2;
          $thr3 = new Thread \&sample_sub, 3;

          sub sample_sub {
              my $SubNumber = shift @_;
              my $TryCount = 10;
              my $LocalCopy;
              sleep 1;
              while ($TryCount--) {
                  $semaphore->down;
                  $LocalCopy = $GlobalVariable;
                  print "$TryCount tries left for sub $SubNumber (\$GlobalVariable is $GlobalVariable)\n";
                  yield;
                  sleep 2;
                  $LocalCopy++;
                  $GlobalVariable = $LocalCopy;
                  $semaphore->up;
              }
          }

     The three invocations of the subroutine all operate in sync.  The
     semaphore, though, makes sure that only one thread is accessing the
     global variable at once.

Advanced Semaphores
     By default, semaphores behave like locks, letting only one thread
     down() them at a time.  However, there are other uses for semaphores.

     Each semaphore has a counter attached to it. down() decrements the
     counter and up() increments the counter.  By default, semaphores are
     created with the counter set to one, down() decrements by one, and
     up() increments by one.  If down() attempts to decrement the counter
     below zero, it blocks until the counter is large enough.  Note that
     while a semaphore can be created with a starting count of zero, any
     up() or down() always changes the counter by at least one.
     $semaphore->down(0) is the same as $semaphore->down(1).

     The question, of course, is why would you do something like this? Why
     create a semaphore with a starting count that's not one, or why
     decrement/increment it by more than one? The answer is resource
     availability.  Many resources that you want to manage access for can
     be safely used by more than one thread at once.

     For example, let's take a GUI driven program.  It has a semaphore that
     it uses to synchronize access to the display, so only one thread is
     ever drawing at once.  Handy, but of course you don't want any thread
     to start drawing until things are properly set up.  In this case, you
     can create a semaphore with a counter set to zero, and up it when
     things are ready for drawing.

     Semaphores with counters greater than one are also useful for
     establishing quotas.  Say, for example, that you have a number of
     threads that can do I/O at once.  You don't want all the threads
     reading or writing at once though, since that can potentially swamp
     your I/O channels, or deplete your process' quota of filehandles.  You
     can use a semaphore initialized to the number of concurrent I/O
     requests (or open files) that you want at any one time, and have your
     threads quietly block and unblock themselves.

     Larger increments or decrements are handy in those cases where a
     thread needs to check out or return a number of resources at once.

Attributes: Restricting Access To Subroutines
---------------------------------------------

   In addition to synchronizing access to data or resources, you might
find it useful to synchronize access to subroutines.  You may be accessing
a singular machine resource (perhaps a vector processor), or find it
easier to serialize calls to a particular subroutine than to have a set of
locks and sempahores.

   One of the additions to Perl 5.005 is subroutine attributes.  The
Thread package uses these to provide several flavors of serialization.
It's important to remember that these attributes are used in the
compilation phase of your program so you can't change a subroutine's
behavior while your program is actually running.

Subroutine Locks
----------------

   The basic subroutine lock looks like this:

     sub test_sub :locked {
     }

   This ensures that only one thread will be executing this subroutine at
any one time.  Once a thread calls this subroutine, any other thread that
calls it will block until the thread in the subroutine exits it.  A more
elaborate example looks like this:

     use Thread qw(yield);

     new Thread \&thread_sub, 1;
     new Thread \&thread_sub, 2;
     new Thread \&thread_sub, 3;
     new Thread \&thread_sub, 4;

     sub sync_sub :locked {
         my $CallingThread = shift @_;
         print "In sync_sub for thread $CallingThread\n";
         yield;
         sleep 3;
         print "Leaving sync_sub for thread $CallingThread\n";
     }

     sub thread_sub {
         my $ThreadID = shift @_;
         print "Thread $ThreadID calling sync_sub\n";
         sync_sub($ThreadID);
         print "$ThreadID is done with sync_sub\n";
     }

   The locked attribute tells perl to lock sync_sub(), and if you run
this, you can see that only one thread is in it at any one time.

Methods
-------

   Locking an entire subroutine can sometimes be overkill, especially when
dealing with Perl objects.  When calling a method for an object, for
example, you want to serialize calls to a method, so that only one thread
will be in the subroutine for a particular object, but threads calling
that subroutine for a different object aren't blocked.  The method
attribute indicates whether the subroutine is really a method.

     use Thread;

     sub tester {
         my $thrnum = shift @_;
         my $bar = new Foo;
         foreach (1..10) {
             print "$thrnum calling per_object\n";
             $bar->per_object($thrnum);
             print "$thrnum out of per_object\n";
             yield;
             print "$thrnum calling one_at_a_time\n";
             $bar->one_at_a_time($thrnum);
             print "$thrnum out of one_at_a_time\n";
             yield;
         }
     }

     foreach my $thrnum (1..10) {
         new Thread \&tester, $thrnum;
     }

     package Foo;
     sub new {
         my $class = shift @_;
         return bless [@_], $class;
     }

     sub per_object :locked :method {
         my ($class, $thrnum) = @_;
         print "In per_object for thread $thrnum\n";
         yield;
         sleep 2;
         print "Exiting per_object for thread $thrnum\n";
     }

     sub one_at_a_time :locked {
         my ($class, $thrnum) = @_;
         print "In one_at_a_time for thread $thrnum\n";
         yield;
         sleep 2;
         print "Exiting one_at_a_time for thread $thrnum\n";
     }

   As you can see from the output (omitted for brevity; it's 800 lines)
all the threads can be in per_object() simultaneously, but only one thread
is ever in one_at_a_time() at once.

Locking A Subroutine
--------------------

   You can lock a subroutine as you would lock a variable.  Subroutine
locks work the same as specifying a locked attribute for the subroutine,
and block all access to the subroutine for other threads until the lock
goes out of scope.  When the subroutine isn't locked, any number of
threads can be in it at once, and getting a lock on a subroutine doesn't
affect threads already in the subroutine.  Getting a lock on a subroutine
looks like this:

     lock(\&sub_to_lock);

   Simple enough.  Unlike the locked attribute, which is a compile time
option, locking and unlocking a subroutine can be done at runtime at your
discretion.  There is some runtime penalty to using lock(\&sub) instead of
the locked attribute, so make sure you're choosing the proper method to do
the locking.

   You'd choose lock(\&sub) when writing modules and code to run on both
threaded and unthreaded Perl, especially for code that will run on 5.004
or earlier Perls.  In that case, it's useful to have subroutines that
should be serialized lock themselves if they're running threaded, like so:

     package Foo;
     use Config;
     $Running_Threaded = 0;

     BEGIN { $Running_Threaded = $Config{'usethreads'} }

     sub sub1 { lock(\&sub1) if $Running_Threaded }

   This way you can ensure single-threadedness regardless of which version
of Perl you're running.

General Thread Utility Routines
===============================

   We've covered the workhorse parts of Perl's threading package, and with
these tools you should be well on your way to writing threaded code and
packages.  There are a few useful little pieces that didn't really fit in
anyplace else.

What Thread Am I In?
--------------------

   The Thread->self method provides your program with a way to get an
object representing the thread it's currently in.  You can use this object
in the same way as the ones returned from the thread creation.

Thread IDs
----------

   tid() is a thread object method that returns the thread ID of the
thread the object represents.  Thread IDs are integers, with the main
thread in a program being 0.  Currently Perl assigns a unique tid to every
thread ever created in your program, assigning the first thread to be
created a tid of 1, and increasing the tid by 1 for each new thread that's
created.

Are These Threads The Same?
---------------------------

   The equal() method takes two thread objects and returns true if the
objects represent the same thread, and false if they don't.

What Threads Are Running?
-------------------------

   Thread->list returns a list of thread objects, one for each thread
that's currently running.  Handy for a number of things, including
cleaning up at the end of your program:

     # Loop through all the threads
     foreach $thr (Thread->list) {
         # Don't join the main thread or ourselves
         if ($thr->tid && !Thread::equal($thr, Thread->self)) {
             $thr->join;
         }
     }

   The example above is just for illustration.  It isn't strictly
necessary to join all the threads you create, since Perl detaches all the
threads before it exits.

A Complete Example
==================

   Confused yet? It's time for an example program to show some of the
things we've covered.  This program finds prime numbers using threads.

     1  #!/usr/bin/perl -w
     2  # prime-pthread, courtesy of Tom Christiansen
     3
     4  use strict;
     5
     6  use Thread;
     7  use Thread::Queue;
     8
     9  my $stream = new Thread::Queue;
     10 my $kid    = new Thread(\&check_num, $stream, 2);
     11
     12 for my $i ( 3 .. 1000 ) {
     13     $stream->enqueue($i);
     14 }
     15
     16 $stream->enqueue(undef);
     17 $kid->join();
     18
     19 sub check_num {
     20     my ($upstream, $cur_prime) = @_;
     21     my $kid;
     22     my $downstream = new Thread::Queue;
     23     while (my $num = $upstream->dequeue) {
     24         next unless $num % $cur_prime;
     25         if ($kid) {
     26            $downstream->enqueue($num);
     27          	} else {
     28            print "Found prime $num\n";
     29	              $kid = new Thread(\&check_num, $downstream, $num);
     30         }
     31     }
     32     $downstream->enqueue(undef) if $kid;
     33     $kid->join()		if $kid;
     34 }

   This program uses the pipeline model to generate prime numbers.  Each
thread in the pipeline has an input queue that feeds numbers to be
checked, a prime number that it's responsible for, and an output queue
that it funnels numbers that have failed the check into.  If the thread
has a number that's failed its check and there's no child thread, then the
thread must have found a new prime number.  In that case, a new child
thread is created for that prime and stuck on the end of the pipeline.

   This probably sounds a bit more confusing than it really is, so lets go
through this program piece by piece and see what it does.  (For those of
you who might be trying to remember exactly what a prime number is, it's a
number that's only evenly divisible by itself and 1)

   The bulk of the work is done by the check_num() subroutine, which takes
a reference to its input queue and a prime number that it's responsible
for.  After pulling in the input queue and the prime that the subroutine's
checking (line 20), we create a new queue (line 22) and reserve a scalar
for the thread that we're likely to create later (line 21).

   The while loop from lines 23 to line 31 grabs a scalar off the input
queue and checks against the prime this thread is responsible for.  Line
24 checks to see if there's a remainder when we modulo the number to be
checked against our prime.  If there is one, the number must not be evenly
divisible by our prime, so we need to either pass it on to the next thread
if we've created one (line 26) or create a new thread if we haven't.

   The new thread creation is line 29.  We pass on to it a reference to
the queue we've created, and the prime number we've found.

   Finally, once the loop terminates (because we got a 0 or undef in the
queue, which serves as a note to die), we pass on the notice to our child
and wait for it to exit if we've created a child (Lines 32 and 37).

   Meanwhile, back in the main thread, we create a queue (line 9) and the
initial child thread (line 10), and pre-seed it with the first prime: 2.
Then we queue all the numbers from 3 to 1000 for checking (lines 12-14),
then queue a die notice (line 16) and wait for the first child thread to
terminate (line 17).  Because a child won't die until its child has died,
we know that we're done once we return from the join.

   That's how it works.  It's pretty simple; as with many Perl programs,
the explanation is much longer than the program.

Conclusion
==========

   A complete thread tutorial could fill a book (and has, many times), but
this should get you well on your way.  The final authority on how Perl's
threads behave is the documention bundled with the Perl distribution, but
with what we've covered in this article, you should be well on your way to
becoming a threaded Perl expert.

Bibliography
============

   Here's a short bibliography courtesy of Jrgen Christoffel:

Introductory Texts
------------------

   Birrell, Andrew D. An Introduction to Programming with Threads. Digital
Equipment Corporation, 1989, DEC-SRC Research Report #35 online as
http://www.research.digital.com/SRC/staff/birrell/bib.html (highly
recommended)

   Robbins, Kay. A., and Steven Robbins. Practical Unix Programming: A
Guide to Concurrency, Communication, and Multithreading. Prentice-Hall,
1996.

   Lewis, Bill, and Daniel J. Berg. Multithreaded Programming with
Pthreads. Prentice Hall, 1997, ISBN 0-13-443698-9 (a well-written
introduction to threads).

   Nelson, Greg (editor). Systems Programming with Modula-3.  Prentice
Hall, 1991, ISBN 0-13-590464-1.

   Nichols, Bradford, Dick Buttlar, and Jacqueline Proulx Farrell.
Pthreads Programming. O'Reilly & Associates, 1996, ISBN 156592-115-1
(covers POSIX threads).

OS-Related References
---------------------

   Boykin, Joseph, David Kirschen, Alan Langerman, and Susan LoVerso.
Programming under Mach. Addison-Wesley, 1994, ISBN 0-201-52739-1.

   Tanenbaum, Andrew S. Distributed Operating Systems. Prentice Hall,
1995, ISBN 0-13-143934-0 (great textbook).

   Silberschatz, Abraham, and Peter B. Galvin. Operating System Concepts,
4th ed. Addison-Wesley, 1995, ISBN 0-201-59292-4

Other References
----------------

   Arnold, Ken and James Gosling. The Java Programming Language, 2nd ed.
Addison-Wesley, 1998, ISBN 0-201-31006-6.

   Le Sergent, T. and B. Berthomieu. "Incremental MultiThreaded Garbage
Collection on Virtually Shared Memory Architectures" in Memory Management:
Proc. of the International Workshop IWMM 92, St. Malo, France, September
1992, Yves Bekkers and Jacques Cohen, eds. Springer, 1992, ISBN
3540-55940-X (real-life thread applications).

Acknowledgements
================

   Thanks (in no particular order) to Chaim Frenkel, Steve Fink, Gurusamy
Sarathy, Ilya Zakharevich, Benjamin Sugars, Jrgen Christoffel, Joshua
Pritikin, and Alan Burlison, for their help in reality-checking and
polishing this article.  Big thanks to Tom Christiansen for his rewrite of
the prime number generator.

AUTHOR
======

   Dan Sugalski <sugalskd@ous.edu>

Copyrights
==========

   This article originally appeared in The Perl Journal #10, and is
copyright 1998 The Perl Journal. It appears courtesy of Jon Orwant and The
Perl Journal.  This document may be distributed under the same terms as
Perl itself.


